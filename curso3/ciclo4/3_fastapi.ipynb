{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso3/ciclo4/3_fastapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776b1608",
      "metadata": {
        "id": "776b1608"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1o4udU5qVMi_7jDi0XzSspbPC6Hw0ev9o\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f75217",
      "metadata": {
        "id": "e4f75217"
      },
      "source": [
        "# **Despliege de Modelos con FastAPI**\n",
        "---\n",
        "\n",
        "En este notebook veremos cómo podemos crear APIs de modelos personalizadas con `fastapi` y modelos de `sklearn`. Comenzamos instalando `fastapi`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23cc81f",
      "metadata": {
        "id": "c23cc81f"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a3c739",
      "metadata": {
        "id": "f2a3c739"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96999f65",
      "metadata": {
        "id": "96999f65"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3b9c46",
      "metadata": {
        "id": "0b3b9c46"
      },
      "source": [
        "## **1. Carga de Datos**\n",
        "---\n",
        "\n",
        "En este caso utilizaremos el conjunto de datos [hate speech and offensive language dataset](https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset) de Kaggle. Se trata de una colección de textos etiquetados manualmente que se utilizan para detectar el discurso de odio y el lenguaje ofensivo. Los textos se han recopilado de varias fuentes, incluidas redes sociales como Twitter, y contienen una variedad de comentarios y mensajes que han sido etiquetados como ofensivos o no ofensivos.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1juGD2mUOGJ27gVhIGS3zUCFsXA9R67qI\" width=\"80%\"></center>\n",
        "\n",
        "En general, este conjunto de datos es útil para aquellos interesados en la detección automática de discurso de odio y lenguaje ofensivo en línea, se puede utilizar para entrenar modelos de aprendizaje automático para identificar y clasificar este tipo de contenido. Además, el conjunto de datos también puede ser utilizado por investigadores interesados en analizar el uso de lenguaje ofensivo en línea y cómo afecta a las personas y comunidades.\n",
        "\n",
        "Para este ejemplo utilizaremos una muestra de 8000 documentos del corpus completo. Procedemos a cargarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d032a38",
      "metadata": {
        "id": "2d032a38"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds6-datasets/main/u4/hate.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b72aeaf",
      "metadata": {
        "id": "5b72aeaf"
      },
      "source": [
        "Este conjunto de datos tiene las siguientes dos columnas:\n",
        "\n",
        "- `text`: texto de un tweet.\n",
        "- `label`: indica si hay un discurso de odio 1 o no 0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01e1de4",
      "metadata": {
        "id": "b01e1de4"
      },
      "source": [
        "## **2. Modelamiento y Evaluación**\n",
        "---\n",
        "\n",
        "Vamos a entrenar un modelo para clasificar automáticamente discursos de odio a partir de textos. Comenzamos dividiendo el conjunto de datos en las particiones de entrenamiento y prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448fb51e",
      "metadata": {
        "id": "448fb51e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461f12c5",
      "metadata": {
        "id": "461f12c5"
      },
      "source": [
        "Primero dividimos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3245794b",
      "metadata": {
        "id": "3245794b"
      },
      "outputs": [],
      "source": [
        "corpus_train, corpus_test, labels_train, labels_test = train_test_split(\n",
        "        data.text, data.label, stratify=data.label, test_size=0.3, random_state=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a2c094",
      "metadata": {
        "id": "e9a2c094"
      },
      "source": [
        "Para la clasificación utilizaremos un modelo de bosques aleatorios junto con una representación de tipo TF-IDF, adicionalmente creamos un pipeline para tener un modelo completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b818e4a",
      "metadata": {
        "id": "9b818e4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5704c0",
      "metadata": {
        "id": "6b5704c0"
      },
      "source": [
        "Definimos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "becbc2a8",
      "metadata": {
        "id": "becbc2a8"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"extractor\", TfidfVectorizer(max_df=0.3, max_features=2000)),\n",
        "    (\"clf\", RandomForestClassifier(max_depth=5, random_state=0))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c78ef1e",
      "metadata": {
        "id": "7c78ef1e"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6382757",
      "metadata": {
        "id": "e6382757"
      },
      "outputs": [],
      "source": [
        "model.fit(corpus_train, labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8503e4c0",
      "metadata": {
        "id": "8503e4c0"
      },
      "source": [
        "Evaluamos el desempeño del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6802a52",
      "metadata": {
        "id": "d6802a52"
      },
      "outputs": [],
      "source": [
        "print(model.score(corpus_test, labels_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e903738a",
      "metadata": {
        "id": "e903738a"
      },
      "source": [
        "Finalmente, utilizaremos la herramienta `joblib` para guardar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179d6918",
      "metadata": {
        "id": "179d6918"
      },
      "outputs": [],
      "source": [
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1cbcc43",
      "metadata": {
        "id": "d1cbcc43"
      },
      "source": [
        "Guardamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3be470f",
      "metadata": {
        "id": "e3be470f"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model, \"model.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb050f7",
      "metadata": {
        "id": "3cb050f7"
      },
      "source": [
        "## **3. FastAPI**\n",
        "---\n",
        "\n",
        "FastAPI es un framework moderno y rápido para la construcción de aplicaciones web basado en Python. Es muy popular en la comunidad de Machine Learning porque ofrece una serie de características que lo hacen ideal para crear API RESTful para servicios de aprendizaje automático. En particular, FastAPI se destaca por su velocidad y eficiencia, lo que lo hace ideal para aplicaciones de aprendizaje automático que requieren un procesamiento rápido de solicitudes y respuestas. Además, FastAPI utiliza la tipificación de Python, lo que ayuda a detectar errores en tiempo de compilación y proporciona una mejor documentación y autocompletado en el editor de código.\n",
        "\n",
        "Otra razón por la que FastAPI es popular en la comunidad de Machine Learning es su facilidad de uso y su capacidad para manejar diferentes tipos de datos. FastAPI se integra fácilmente con bibliotecas populares de aprendizaje automático como `tensorflow`, `pytorch` y `sklearn`, lo que lo hace ideal para crear servicios API RESTful que utilizan modelos de aprendizaje automático. FastAPI tambien proporciona una documentación automática basada en OpenAPI y Swagger, lo que permite a los desarrolladores y usuarios de la API acceder fácilmente a la documentación detallada de la API y sus especificaciones.\n",
        "\n",
        "Para desplegar un modelo de machine learning con `fastapi` estaremos utilizando el protocolo HTTP tal y como se muestra a continuación:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1JCy0PSAFDalM0OzqH9kYu3s4iwjs3JJR\" width=\"80%\">\n",
        "\n",
        "En específico, vamos a implementar una función que permita manejar llamadas de tipo **post** (recibe y retorna datos). Para esto, comenzamos definiendo la entrada del API como una clase usando `pydantic` (permite estructurar y validar tipos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e1101f",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e5e1101f"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "class ApiInput(BaseModel):\n",
        "    text: List[str]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6514172b",
      "metadata": {
        "id": "6514172b"
      },
      "source": [
        "Ahora, definimos una clase para la salida del API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94ae068",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e94ae068"
      },
      "outputs": [],
      "source": [
        "class ApiOutput(BaseModel):\n",
        "    is_hate: List[int]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24cd2f10",
      "metadata": {
        "id": "24cd2f10"
      },
      "source": [
        "Ahora, veamos cómo es el flujo de trabajo para un API personalizada de machine learning:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Qj6Njwl2DlVCkPxTddB-Gen-piQAlL2L\" width=\"80%\">\n",
        "\n",
        "Esta se compone de los siguientes elementos:\n",
        "\n",
        "- **Cliente**: el cliente hace referencia al usuario o la aplicación que enviará datos y recibirá predicciones.\n",
        "- **Endpoint**: se trata de una url única del API que nos permite interactuar con un recurso o función determinada, en específico, la predicción de un modelo. En este caso lo manejamos por medio de `fastapi`.\n",
        "- **Registro del modelo**: se trata del almacenamiento donde quedó guardado el modelo. En este caso es un único archivo, aunque se puede manejar de una forma más precisa con herramientas como `mlflow` o `dvc`.\n",
        "- **Creación del modelo**: se trata del proceso (normalmente fuera de línea) que entrena un modelo y lo guarda en el **registro**.\n",
        "\n",
        "Veamos cómo podemos definir el **endpoint** con `fastapi`. Esto se debe generar como un script de _Python_ tal y como se muestra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971b2fff",
      "metadata": {
        "id": "971b2fff"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "from fastapi import FastAPI # importamos el API\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "import joblib # importamos la librería para cargar el modelo\n",
        "\n",
        "class ApiInput(BaseModel):\n",
        "    texts: List[str]\n",
        "\n",
        "class ApiOutput(BaseModel):\n",
        "    is_hate: List[int]\n",
        "\n",
        "app = FastAPI() # creamos el api\n",
        "model = joblib.load(\"model.joblib\") # cargamos el modelo.\n",
        "\n",
        "@app.post(\"/hate\") # creamos api que permita requests de tipo post.\n",
        "async def define_sentiment(data: ApiInput) -> ApiOutput:\n",
        "    predictions = model.predict(data.texts).flatten().tolist() # generamos la predicción\n",
        "    preds = ApiOutput(is_hate=predictions) # estructuramos la salida del API.\n",
        "    return preds # retornamos los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d33dd9aa",
      "metadata": {
        "id": "d33dd9aa"
      },
      "source": [
        "## **4. Railway**\n",
        "---\n",
        "\n",
        "Vamos a realizar el despliegue de esta API por medio de la plataforma Railway. Se trata de una plataforma en línea que ofrece servicios de alojamiento web, bases de datos y herramientas de desarrollo para crear y desplegar aplicaciones web. Es una plataforma todo en uno que proporciona un entorno de desarrollo simplificado y una infraestructura escalable para los desarrolladores.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1l0FTVsrZR4XTZj7ZRSyIajmUdwxeF5gi\" width=\"80%\">\n",
        "\n",
        "En cuanto a las aplicaciones de Machine Learning, Railway ofrece algunas características que pueden ser útiles para desplegar APIs de Machine Learning:\n",
        "\n",
        "- **Integración con GitHub**: Railway se integra perfectamente con GitHub, lo que permite desplegar aplicaciones de Machine Learning directamente desde repositorios.\n",
        "- **Fácil configuración de variables de entorno**: Railway proporciona una interfaz fácil de usar para configurar variables de entorno para la aplicación, lo que es útil para definir y administrar los parámetros de configuración de los modelos de Machine Learning.\n",
        "- **Escalabilidad automática**: Railway proporciona una infraestructura escalable y una configuración automática de recursos para asegurar que la aplicación pueda manejar un alto volumen de tráfico y se pueda escalar según sea necesario.\n",
        "\n",
        "Para comenzar a usar railway debe dirigirse a [este enlace](https://railway.app/) y acceder por medio de su correo:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KXmduYiolCjWTHq268QXxqNC0GXh96E_\" width=\"80%\">\n",
        "\n",
        "Por defecto Railway ofrece 2 dolares gratuitos, no obstante, si valida su cuenta puede obtener 5 dolares gratuitos:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FdDa4O7K79ON47xqmfqd141Dq_bDMwBx\" width=\"80%\">\n",
        "\n",
        "Para desplegar el API debemos crear un repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774420a3",
      "metadata": {
        "id": "774420a3"
      },
      "outputs": [],
      "source": [
        "!mkdir mlapi\n",
        "!mv main.py model.joblib mlapi/\n",
        "%cd mlapi/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5d19db",
      "metadata": {
        "id": "6c5d19db"
      },
      "source": [
        "Inicializamos el repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d339a609",
      "metadata": {
        "id": "d339a609"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"email\"\n",
        "!git config --global user.name \"usuario o nombre\"\n",
        "!git config --global init.defaultBranch master\n",
        "!git init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f82118",
      "metadata": {
        "id": "b6f82118"
      },
      "source": [
        "Adicionalmente, debemos crear el archivo `requirements.txt` con las dependencias del proyecto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8304490b",
      "metadata": {
        "id": "8304490b"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "scikit-learn\n",
        "fastapi\n",
        "uvicorn\n",
        "joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f94ca67",
      "metadata": {
        "id": "5f94ca67"
      },
      "source": [
        "Adicional a esto, Railway requiere la creación de un archivo de configuración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60409f1c",
      "metadata": {
        "id": "60409f1c"
      },
      "outputs": [],
      "source": [
        "%%writefile railway.json\n",
        "{\n",
        "  \"$schema\": \"https://railway.app/railway.schema.json\",\n",
        "  \"build\": {\n",
        "    \"builder\": \"NIXPACKS\"\n",
        "  },\n",
        "  \"deploy\": {\n",
        "    \"startCommand\": \"uvicorn main:app --host 0.0.0.0 --port $PORT\",\n",
        "    \"restartPolicyType\": \"ON_FAILURE\",\n",
        "    \"restartPolicyMaxRetries\": 10\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa05c461",
      "metadata": {
        "id": "aa05c461"
      },
      "source": [
        "Ahora agregamos los archivos al area de preparación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401413e9",
      "metadata": {
        "id": "401413e9"
      },
      "outputs": [],
      "source": [
        "!git add railway.json requirements.txt main.py model.joblib\n",
        "!git commit -m \"Agregamos los archivos del API.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e515c03",
      "metadata": {
        "id": "3e515c03"
      },
      "source": [
        "En GitHub, debe crear un repositorio y agregar los siguientes dos campos (puede revisar el material de la unidad 2 si no recuerda el proceso):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1943a6e3",
      "metadata": {
        "id": "1943a6e3"
      },
      "outputs": [],
      "source": [
        "token = \"\"  # Agregue su token dentro de las comillas.\n",
        "repo_url = \"\" # Agregue la url de su repositorio dentro de las comillas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e83925",
      "metadata": {
        "id": "e6e83925"
      },
      "source": [
        "Ahora, usaremos una expresión regular para reemplazar el token en esta url:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce697979",
      "metadata": {
        "id": "ce697979"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "pat = re.compile(r\"(https://)(.*)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678c7ee6",
      "metadata": {
        "id": "678c7ee6"
      },
      "source": [
        "Formateamos la URL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8ef5af",
      "metadata": {
        "id": "7f8ef5af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "match = re.match(pat, repo_url)\n",
        "url_token = \"\".join([match.group(1), token, \"@\", match.group(2)])\n",
        "os.environ[\"GITHUB\"] = url_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7717187b",
      "metadata": {
        "id": "7717187b"
      },
      "source": [
        "Finalmente, enlazamos el repositorio local con el nuevo repositorio en Github con el comando `git remote`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb02cc8",
      "metadata": {
        "id": "8fb02cc8"
      },
      "outputs": [],
      "source": [
        "!git remote add origin $GITHUB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a5fd67",
      "metadata": {
        "id": "43a5fd67"
      },
      "source": [
        "En este punto, las versiones local (Colab) y remoto (Github) son distintas, para subir los cambios podemos usar el comando `git push` especificando la rama que deseamos actualizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b6011be",
      "metadata": {
        "id": "2b6011be"
      },
      "outputs": [],
      "source": [
        "!git push origin master"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93694552",
      "metadata": {
        "id": "93694552"
      },
      "source": [
        "Ahora, desde Railway debemos crear un nuevo proyecto:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1gAXJbVB1mpmT-W18pfUfUl3u6xsD2CQ-\" width=\"80%\">\n",
        "\n",
        "El proyecto debe ser creado desde GitHub:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1XHdYwVhKmH3fnLLeEcdaBa7QOKRHP_ks\" width=\"80%\">\n",
        "\n",
        "Ahora, debe seleccionar el repositorio que acaba de actualizar:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QGyztFCLuKR7ah8dtlUNiywP97NY5REe\" width=\"80%\">\n",
        "\n",
        "Con esto, podrá ver que el API comienza a desplegar dentro de la plataforma:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WkaMtPbRFSLACYmQosSnH6sJTKuMfSKi\" width=\"80%\">\n",
        "\n",
        "Finalmente, cuando el API esté desplegado debe irse a la sección **Settings** y dar click sobre el botón **Generate Domain**, esto generará una url que debe pegar en la siguiente variable (debe validar que la url contenga `\"https://\"` al inicio, en caso contrario debe agregarlo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445522d5",
      "metadata": {
        "id": "445522d5"
      },
      "outputs": [],
      "source": [
        "model_url = \"https://mlapi-production-272c.up.railway.app\" # Agregue acá la url de railway"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3de2ac8",
      "metadata": {
        "id": "b3de2ac8"
      },
      "source": [
        "Ahora podemos validar que el API funcione correctamente, vamos a consumirlo con la librería `requests`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb542bf7",
      "metadata": {
        "id": "cb542bf7"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72586072",
      "metadata": {
        "id": "72586072"
      },
      "source": [
        "Veamos el resultado para un texto con odio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ca3894",
      "metadata": {
        "id": "03ca3894"
      },
      "outputs": [],
      "source": [
        "r = requests.post(os.path.join(model_url, \"hate\"), json={\"texts\": [\"you are so dumb and a stupid and ignorant person\"]})\n",
        "print(r.json()) # hate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb58b684",
      "metadata": {
        "id": "bb58b684"
      },
      "source": [
        "Ahora para un texto normal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3376dc80",
      "metadata": {
        "id": "3376dc80",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "r = requests.post(os.path.join(model_url, \"hate\"), json={\"texts\": [\"You are so nice and humble\"]})\n",
        "print(r.json()) # normal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17869fbd",
      "metadata": {
        "id": "17869fbd"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [MLFlow Models](https://mlflow.org/docs/latest/models.html).\n",
        "- [MLFlow Model Serving](https://towardsdatascience.com/mlflow-model-serving-bcd936d59052).\n",
        "- [Qué es un API de Rest?](https://www.redhat.com/es/topics/api/what-is-a-rest-api)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30a35fbb",
      "metadata": {
        "id": "30a35fbb"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "**Profesor**\n",
        "\n",
        "- [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "\n",
        "**Asistente docente**:\n",
        "\n",
        "- [Juan S. Lara MSc](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/)\n",
        "\n",
        "**Coordinador de virtualización:**\n",
        "\n",
        "- [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Diseño de imágenes:**\n",
        "  - [Rosa Alejandra Superlano Esquibel](https://www.linkedin.com/in/alejandra-superlano-02b74313a/).\n",
        "  - [Mario Andrés Rodríguez Triana](mailto:mrodrigueztr@unal.edu.co).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}