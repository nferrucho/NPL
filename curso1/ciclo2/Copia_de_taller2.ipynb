{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo2/Copia_de_taller2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b266b944",
      "metadata": {
        "id": "b266b944"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1AQr9H9bXDeNPchTRufU78g8z0yxHvrmC\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f967c0eb",
      "metadata": {
        "id": "f967c0eb"
      },
      "source": [
        "# **Taller 2**\n",
        "---\n",
        "\n",
        "En este taller se evaluarán las habilidades adquiridas en expresiones regulares, manejo de la librería `spacy` y preprocesamiento a partir del conjunto de datos [Spanish News Classification](https://www.kaggle.com/datasets/kevinmorgado/spanish-news-classification) de Kaggle.\n",
        "\n",
        "En este caso, usted deberá realizar algunas operaciones de búsqueda de textos con expresiones regulares y normalización de textos. Comenzamos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc281d8",
      "metadata": {
        "id": "ecc281d8"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1ec7a6",
      "metadata": {
        "id": "9b1ec7a6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from unidecode import unidecode\n",
        "from IPython.display import display\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36823488",
      "metadata": {
        "id": "36823488"
      },
      "source": [
        "Cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94804a25",
      "metadata": {
        "id": "94804a25"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "df = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u3/spanish_news.parquet\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c50d6c3",
      "metadata": {
        "id": "3c50d6c3"
      },
      "source": [
        "Este conjunto de datos contiene tres columnas:\n",
        "\n",
        "- `url`: dirección de donde se extrajeron los datos.\n",
        "- `news`: contenido textual de una noticia.\n",
        "- `Type`: tipo de noticia.\n",
        "\n",
        "Este corpus está conformado por `1217` documentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6546f1",
      "metadata": {
        "id": "2f6546f1"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c3895f1",
      "metadata": {
        "id": "3c3895f1"
      },
      "source": [
        "De la misma forma, el conjunto de datos contiene noticias de 7 categorías distintas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6438b4ef",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "6438b4ef"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(df.Type.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23c237a8",
      "metadata": {
        "id": "23c237a8"
      },
      "source": [
        "## **1. Reconocimiento de URLs**\n",
        "---\n",
        "\n",
        "En este punto deberá extraer el protocolo, dominio, y ruta de la cualquiera de las URLs que se encuentran dentro de la columna `url` del conjunto de datos.\n",
        "\n",
        "Por ejemplo, la siguiente URL:\n",
        "\n",
        "`https://www.larepublica.co/redirect/post/3201905`\n",
        "\n",
        "Tiene los siguientes elementos:\n",
        "\n",
        "- **Protocolo**: `https`\n",
        "- **Dominio**: `www.larepublica.co`\n",
        "- **Ruta**: `redirect/post/320195`\n",
        "\n",
        "Para esto, debe implementar la función `url_elements` la cual deberá retornar una expresión regular que contenga tres grupos nombrados de la siguiente forma: `protocol`, `domain` y `route`.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "Esta función no tiene parámetros.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `pat`: expresión regular compilada con los tres elementos de una URL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7948c572",
      "metadata": {
        "id": "7948c572"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que los grupos nombrados dentro de expresiones regulares en _Python_ se definen siguiendo la notación `(?P<tag>regex)` donde `tag` es el nombre del grupo y `regex` es la expresión regular que describe el grupo.\n",
        "- Se recomienda usar cuantificadores como `+` para detectar secuencias de longitud mayor a 1 en los identificadores de cada grupo.\n",
        "- Se recomienda revisar el identificador `\\w`, ya que las URL normalmente usan caracteres alfanuméricos para representar algunas partes.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbb7d27",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9bbb7d27"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA url_elements:\n",
        "\n",
        "def url_elements():\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    regex = \"\"\n",
        "    pat = re.compile(regex)\n",
        "    return pat\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9021cad2",
      "metadata": {
        "id": "9021cad2"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "pat = url_elements()\n",
        "match = re.search(pat, df.url.iloc[0])\n",
        "res = (match.group(\"protocol\"), match.group(\"domain\"), match.group(\"route\"))\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca183617",
      "metadata": {
        "id": "ca183617"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo se obtienen los elementos de la primera URL en el conjunto de datos:\n",
        "\n",
        "```python\n",
        "❱ display(res)\n",
        "('https', 'www.larepublica.co', 'redirect/post/3201905')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06759bac",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "06759bac"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "pat = url_elements()\n",
        "match = re.search(pat, df.url.iloc[100])\n",
        "res = (match.group(\"protocol\"), match.group(\"domain\"), match.group(\"route\"))\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4e5b8a3",
      "metadata": {
        "id": "c4e5b8a3"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este segundo ejemplo se obtienen los elementos de la URL número 100 en el conjunto de datos:\n",
        "\n",
        "```python\n",
        "❱ display(res)\n",
        "('https',\n",
        "'www.bbva.com',\n",
        "'es/mx/sostenibilidad/irrupcion-de-lo-femenino-en-el-cine-documental/')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a02a406",
      "metadata": {
        "id": "9a02a406"
      },
      "source": [
        "## **2. Selección de Categorías con Patrón**\n",
        "---\n",
        "\n",
        "En este punto deberá seleccionar todos los registros del _DataFrame_ donde la columna `Type` corresponda con determinado patrón de entrada.\n",
        "\n",
        "Para esto debe implementar la función `filter_type`, la cual recibirá el conjunto de datos y una expresión regular sobre la que debe filtrar.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `df`: conjunto de datos en formato `pd.DataFrame`.\n",
        "- `pat`: expresión regular sobre la que se debe filtrar.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `filtered_df`: `DataFrame` resultante del filtro por patrón de búsqueda."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edce63ad",
      "metadata": {
        "id": "edce63ad"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que las `Series` de `pandas` contienen el método `str.contains`, este método le permitirá aplicar una expresión regular directamente.\n",
        "- Puede usar el método `apply` de `pandas` para validar elemento a elemento si hay un match de la expresión regular.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe3c66a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "efe3c66a"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA filter_type:\n",
        "\n",
        "def filter_type(df, pat):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    filtered_df = pd.DataFrame({})\n",
        "    return filtered_df\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb5c6aa",
      "metadata": {
        "id": "ecb5c6aa"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "pat = re.compile(r\"^[A].*$\")\n",
        "filtered_df = filter_type(df, pat)\n",
        "display(filtered_df.Type.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed0fd33",
      "metadata": {
        "id": "3ed0fd33"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debería extraer todos los casos donde `Type` comienza por una `\"A\"` mayúscula y luego tiene cualquier secuencia de letras.\n",
        "\n",
        "```python\n",
        "❱ display(filtered_df.Type.value_counts())\n",
        "Alianzas    247\n",
        "Name: Type, dtype: int64\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee869af",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "8ee869af"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "pat = re.compile(r\"^.*on$\")\n",
        "filtered_df = filter_type(df, pat)\n",
        "display(filtered_df.Type.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c303c5a3",
      "metadata": {
        "id": "c303c5a3"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debería extraer todos los casos donde `Type` termine por la secuencia `\"on\"`.\n",
        "\n",
        "```python\n",
        "❱ display(filtered_df.Type.value_counts())\n",
        "Innovacion    195\n",
        "Reputacion     26\n",
        "Name: Type, dtype: int64\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35664d80",
      "metadata": {
        "id": "35664d80"
      },
      "source": [
        "## **3. Documentos de Spacy**\n",
        "---\n",
        "\n",
        "En este punto deberá convertir todo el corpus en una lista de documentos de `spacy`. Para ello, debe implementar la función `to_spacy` para extraer el texto de la columna `news` del `DataFrame` dado y convertirlo a objetos tipo `Doc` usando un _pipeline_ dado.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `df`: conjunto de datos.\n",
        "- `nlp`: _pipeline_ de `spacy`.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `corpus`: lista de documentos de `spacy`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32556898",
      "metadata": {
        "id": "32556898"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede usar el método `pipe` para pasar una lista de textos a un _pipeline_ y convertir masivamente varios resultados a `Doc` de `spacy`. Tenga en cuenta que debe convertir el resultado a una lista de _Python_.\n",
        "- Puede usar el objeto `nlp` como una función para convertir un texto individual a un `Doc`, de esta forma, debe iterar sobre todo el corpus.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe15a8d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "bfe15a8d"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA to_spacy:\n",
        "\n",
        "def to_spacy(df, nlp):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    corpus = []\n",
        "    return corpus\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88493b60",
      "metadata": {
        "id": "88493b60"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "import spacy\n",
        "spacy.cli.download(\"es_core_news_sm\")\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245ecb2a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "245ecb2a"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "corpus = to_spacy(df.head(20), nlp)\n",
        "display(type(corpus))\n",
        "display(type(corpus[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bd4b77",
      "metadata": {
        "id": "02bd4b77"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debe convertir los primeros 20 documentos del corpus a objetos de `spacy`.\n",
        "\n",
        "```python\n",
        "❱ display(type(corpus))\n",
        "list\n",
        "\n",
        "❱ display(type(corpus[0]))\n",
        "spacy.tokens.doc.Doc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879194e8",
      "metadata": {
        "id": "879194e8"
      },
      "source": [
        "## **4. Recuento de Stop Words**\n",
        "---\n",
        "\n",
        "En este punto, deberá implementar una función que permita contar el número de _stopwords_ por cada documento (de `spacy`). Para ello, debe implementar la función `stopword_count` para obtener los conteos de _stopwords_ a partir de una lista de documentos de `spacy`.\n",
        "\n",
        "**Parámetros**\n",
        "---\n",
        "\n",
        "- `corpus`: lista de documentos de `spacy`.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `counts`: lista de conteos de _stopwords_ por documento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04adc5bb",
      "metadata": {
        "id": "04adc5bb"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que cada `Token` en `spacy` contiene el atributo `is_stop` que determina si el elemento es una _stopword_.\n",
        "- Puede recorrer todos los tokens de un documento de `spacy` al iterar sobre el mismo, y sumar los valores de `token.is_stop`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36774065",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "36774065"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA stopword_count:\n",
        "\n",
        "def stopword_count(corpus):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    counts = []\n",
        "    return counts\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a49535a2",
      "metadata": {
        "id": "a49535a2"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "nlp = spacy.load(\n",
        "        \"es_core_news_sm\",\n",
        "        exclude=[\n",
        "            \"ner\", \"tok2vec\", \"senter\", \"morphologizer\",\n",
        "            \"parser\", \"attribute_ruler\", \"lemmatizer\"]\n",
        "        )\n",
        "corpus = to_spacy(df, nlp)\n",
        "counts = stopword_count(corpus)\n",
        "display(counts[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5251d784",
      "metadata": {
        "id": "5251d784"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debe obtener los conteos de _stopwords_ para los primeros 10 documentos del corpus.\n",
        "\n",
        "```python\n",
        "❱ display(counts[:10])\n",
        "[135, 190, 210, 248, 438, 88, 362, 58, 288, 100]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81747429",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "81747429"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "fig, ax = plt.subplots()\n",
        "sns.histplot(counts, kde=True, ax=ax)\n",
        "ax.set_xlabel(\"Número de stopwords\")\n",
        "ax.set_ylabel(\"Conteo\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aa2ecb3",
      "metadata": {
        "id": "7aa2ecb3"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debe generar un histograma de la distribución de stopwords en todos los documentos.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FYuE4Yywuu65KOJ5z_Oz8WPphdnx1toT\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c411bbd",
      "metadata": {
        "id": "1c411bbd"
      },
      "source": [
        "## **5. Extracción de Palabras por etiquetas POS**\n",
        "---\n",
        "\n",
        "En este punto, deberá implementar una función que permita extraer las palabras de un texto que tengan etiquetas de tipo POS de grano grueso dentro de una lista de posibles valores.\n",
        "\n",
        "Para ello deberá implementar la función `get_pos_words` la cual recibe una lista de documentos de `spacy` y debe retornar una lista de strings con las palabras filtradas y concatenadas por cada documento.\n",
        "\n",
        "**Parámetros**\n",
        "---\n",
        "\n",
        "- `corpus`: lista de documentos de `spacy`.\n",
        "- `pos_list`: lista de etiquetas POS a filtrar.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `filtered_pos`: lista strings con el filtro por etiquetas POS."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250543a1",
      "metadata": {
        "id": "250543a1"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede acceder a una etiqueta de tipo _POS_ con el atributo `pos_` de un `Token` de `spacy`.\n",
        "- Es importante que el resultado por cada documento sea un string y no una lista de tokens de `spacy`, puede usar el método `join` de los strings en _Python_ y el atributo `text` de los tokens de `spacy`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424dff2d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "424dff2d"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_pos_words:\n",
        "def get_pos_words(corpus, pos_list):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    filtered_pos = []\n",
        "    return filtered_pos\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c24684",
      "metadata": {
        "id": "e0c24684"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "corpus = to_spacy(df.head(2), nlp)\n",
        "filtered_pos = get_pos_words(corpus, [\"VERB\"])\n",
        "display(filtered_pos[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773688b8",
      "metadata": {
        "id": "773688b8"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debe extraer todos los verbos del segundo texto\n",
        "\n",
        "```python\n",
        "❱ display(filtered_pos[1])\n",
        "'dijo buscará apoyará endurecieron expresaron dijo tomó mantener reforzar elijan salir avanzar continuará dijo dicho exigirá revelen afectar permitirles captar revelar denegó cotizar denegada añadió reforzado lanzó dijo reforzaría cotizan dijo someterse cotizar dicho informar cotizar'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd93e168",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "bd93e168"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "filtered_pos = get_pos_words(corpus, [\"VERB\", \"NOUN\"])\n",
        "display(filtered_pos[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f3529ad",
      "metadata": {
        "id": "8f3529ad"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba debe extraer todos los verbos y sustantivos del primer documento\n",
        "\n",
        "```python\n",
        "❱ display(filtered_pos[0])\n",
        "'foro banca desarrollo director sostenibilidad clientes aseguró entender sostenibilidad asociar costos creo tener concepto negocio tener impacto imaginamos reto cambiar prioridades compitan casos tratar mantener prioridad cuanto ambición negocios reto coyuntura sostenibilidad abre oportunidades fuentes financiamiento agregó directivo argumentó encuentra juego tema rentabilidad negocios particular tema viabilidad mundo negocios mundo general conocemos riesgos transición cambio inclusión desarrollo están dejó aspecto paralelo responsabilidad tiene estar estrategias negocio manera logran impulsar proyectos incluidos aspiraciones concluyó'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d9f39b",
      "metadata": {
        "id": "77d9f39b"
      },
      "source": [
        "## **6. Preprocesamiento**\n",
        "---\n",
        "\n",
        "En este punto usted deberá implementar un flujo de preprocesamiento para textos. Las tareas que debe realizar son las siguientes:\n",
        "\n",
        "1. Filtrar stopwords.\n",
        "2. Seleccionar únicamente palabras en algunas categorías de tipo _POS_\n",
        "3. Normalizar el texto con `unidecode`.\n",
        "4. Convertir a minúsculas.\n",
        "\n",
        "Para ello debe implementar la función `preprocess` la cual recibirá un documento de `spacy` y la lista de etiquetas _POS_ para filtrar, con esto deberá retornar un string con el resultado del preprocesamiento.\n",
        "\n",
        "**Parámetros**\n",
        "---\n",
        "\n",
        "- `doc`: documento de `spacy`.\n",
        "- `pos_list`: lista de etiquetas POS a filtrar.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `preprocess_text`: texto preprocesado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609fc44b",
      "metadata": {
        "id": "609fc44b"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde filtrar stopwords con el atributo `is_stop` y filtrar etiquetas _POS_ con el atributo `pos_` de los tokens de `spacy`.\n",
        "- Con la librería `unidecode` puede normalizar el texto.\n",
        "- Puede convertir los textos en minúsculas con el atributo `lower` de un string.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b32751d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0b32751d"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA preprocess:\n",
        "def preprocess(doc, pos_list):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    preprocess_text = \"\"\n",
        "    return preprocess_text\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c1ac66",
      "metadata": {
        "id": "b2c1ac66"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "corpus = to_spacy(df.head(10), nlp)\n",
        "preprocess_text = preprocess(corpus[0], [\"VERB\", \"NOUN\"])\n",
        "display(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bfdfa3f",
      "metadata": {
        "id": "3bfdfa3f"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba muestra el primer documento preprocesado.\n",
        "\n",
        "```python\n",
        "❱ display(preprocess_text)\n",
        "'foro banca desarrollo director sostenibilidad clientes aseguro entender sostenibilidad asociar costos creo tener concepto negocio tener impacto imaginamos reto cambiar prioridades compitan casos tratar mantener prioridad cuanto ambicion negocios reto coyuntura sostenibilidad abre oportunidades fuentes financiamiento agrego directivo argumento encuentra juego tema rentabilidad negocios particular tema viabilidad mundo negocios mundo general conocemos riesgos transicion cambio inclusion desarrollo estan dejo aspecto paralelo responsabilidad tiene estar estrategias negocio manera logran impulsar proyectos incluidos aspiraciones concluyo'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "597c7461",
      "metadata": {
        "id": "597c7461"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "corpus = to_spacy(df.head(10), nlp)\n",
        "preprocess_text = preprocess(corpus[1], [\"NOUN\", \"PROPN\"])\n",
        "display(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "110c9597",
      "metadata": {
        "id": "110c9597"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "Este caso de prueba muestra el segundo documento preprocesado.\n",
        "\n",
        "```python\n",
        "❱ display(preprocess_text)\n",
        "'regulador valores china domingo cooperacion par salidas bolsa extranjero supervisores exigencias divulgacion informacion empresas preocupacion medidas pekin comision reguladora valores china csrc comunicado nota requisitos comision valores estados unidos sec empresas partes espiritu respeto comunicaciones regulacion csrc empresas bolsa politica china reforma apertura apertura mundo sitio sec viernes companias incertidumbre acciones gobierno china resultados empresa capital mercados valores emisores permiso autoridades bolsas riesgos aprobacion sec.china control emision acciones extranjero investigacion ciberseguridad gigante transporte didi global inc mes dias cotizacion nueva york gabinete julio supervision empresas extranjero regulador ciberespacio empresa datos millon usuarios revision ciberseguridad extranjero banco china empresas pago planes extranjero'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03fabd7",
      "metadata": {
        "id": "a03fabd7"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}