{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso2/ciclo1/M5U1_Introducci%C3%B3n_al_Aprendizaje_Profundo_con_Tensorflow_y_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1QqjbbEZ1w7xoawV020Jj_R46PKRi6A_e\" alt = \"Encabezado MLDS 5\" width = \"100%\">  </img>"
      ],
      "metadata": {
        "id": "fdySb3zQqyZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Introducción al aprendizaje profundo**\n",
        "----\n",
        "\n",
        "En este taller guiado haremos un acercamiento a los conceptos prácticos fundamentales para el desarrollo de modelos de **_Deep Learning_** con **_Tensorflow y Keras_**.\n",
        "\n",
        "Veremos:\n",
        "\n",
        "- Grafos computacionales\n",
        "- Elementos de _TensorFlow_:\n",
        "  - Tensores\n",
        "  - _Eager execution_\n",
        "  - _TensorBoard_\n",
        "  - Derivacion con _TensorFlow_\n",
        "  - Funciones de Optimizacion\n",
        "  - Integración con _Numpy_\n",
        "- Modelos básicos con _Keras_\n",
        "- Regresión Logística con _TensorFlow_\n",
        "- Regresión Logística con _Keras_"
      ],
      "metadata": {
        "id": "TaqfTPj70-Dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **_Tensorflow_**\n",
        "\n",
        "_Tensorflow_ es una plataforma end-to-end de uso libre para _Machine Learning_ (ML). Se compone de un ecosistema exhaustivo y flexible de herramientas, librerías y recursos de la comunidad que permite a investigadores y desarrolladores construir e implementar aplicaciones basadas en ML, especialmente enfocadas en modelos de aprendizaje profundo (_Deep Learning_).\n",
        "\n",
        "Unas de las principales ventajas de Tensorflow son:\n",
        "\n",
        "|Fácil construcción de modelos|Producción robusta de ML|Experimentación para investigación|\n",
        "|---|---|---|\n",
        "|<img src=\"https://drive.google.com/uc?export=view&id=1xbDw0lShlbrk4XKjWsQMyBqU5giW1XWk\" alt = \"Ejemplo de Tensores de distintos ordenes\" width=\"80%\"> | <img src=\"https://drive.google.com/uc?export=view&id=1AJ_pmzhYP4X6Ixrc82mjYxpKbwIrHpmG\" width=\"80%\" />|<img src=\"https://drive.google.com/uc?export=view&id=1tiqfRraa13DlTA-dJThgWg1rY0WGa3Hh\" width=\"80%\" />|\n",
        "| Facilita la implementación y el entrenamiento <br/> de modelos de ML utilizando APIs de alto nivel <br/> como *Keras* con *eager execution*, lo cual, <br/> permite una fácil construcción y depuración.| Permite entrenar e implementar fácilmente <br/> modelos en la nube, en dispositivos móviles o <br/>en un navegador sin importar el lenguaje usado.| Tiene una arquitectura simple y flexible para <br/> llevar nuevas ideas a experimentación y producción.\n",
        "|\n",
        "\n"
      ],
      "metadata": {
        "id": "jFwc5lCg50GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importar Tensorflow** <a class=\"anchor\" id=\"section1\"></a>\n",
        "---\n",
        "\n",
        "A continuación importaremos _Tensorflow_."
      ],
      "metadata": {
        "id": "XYg9pTwn6B_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0 tensorboard==2.15.0"
      ],
      "metadata": {
        "id": "5LP_dqVC-T3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "NdckWtcf5k1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y luego definiremos algunas funciones para facilitar la visualización. Usaremos estas funciones a lo largo del notebook para comprender los conceptos detrás de _Tensorflow_."
      ],
      "metadata": {
        "id": "phBgVcCX2UJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "import tensorboard\n",
        "tensorboard.__version__"
      ],
      "metadata": {
        "id": "HePMYFfz-E4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para mostrar regiones de decisión\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "def plot_data(X, y):\n",
        "    y_unique = np.unique(y)\n",
        "    colors = plt.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
        "    for this_y, color in zip(y_unique, colors):\n",
        "        this_X = X[y == this_y]\n",
        "        plt.scatter(this_X[:, 0], this_X[:, 1],  c=np.array([color]),\n",
        "                    alpha=0.5, edgecolor='k',\n",
        "                    label=\"Class %s\" % this_y)\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(\"Data\")\n",
        "\n",
        "\n",
        "def plot_decision_region(X, pred_fun):\n",
        "    min_x = np.min(X[:, 0])\n",
        "    max_x = np.max(X[:, 0])\n",
        "    min_y = np.min(X[:, 1])\n",
        "    max_y = np.max(X[:, 1])\n",
        "    min_x = min_x - (max_x - min_x) * 0.05\n",
        "    max_x = max_x + (max_x - min_x) * 0.05\n",
        "    min_y = min_y - (max_y - min_y) * 0.05\n",
        "    max_y = max_y + (max_y - min_y) * 0.05\n",
        "    x_vals = np.linspace(min_x, max_x, 50)\n",
        "    y_vals = np.linspace(min_y, max_y, 50)\n",
        "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
        "    grid_r, grid_c = XX.shape\n",
        "    vals = [[XX[i, j], YY[i, j]] for i in range(grid_r) for j in range(grid_c)]\n",
        "    preds = pred_fun(np.array(vals))\n",
        "    ZZ = np.reshape(preds, (grid_r, grid_c))\n",
        "    plt.contourf(XX, YY, ZZ, 100, cmap = plt.cm.coolwarm, vmin= -1, vmax=2)\n",
        "    plt.colorbar()\n",
        "    CS = plt.contour(XX, YY, ZZ, 100, levels = [0.1*i for i in range(1,10)])\n",
        "    plt.clabel(CS, inline=1, fontsize=10)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "\n",
        "\n",
        "# Eliminar cualquier logs de ejecuciones anteriores\n",
        "!rm -rf ./logs/\n",
        "\n",
        "# Configurando logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/func/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)"
      ],
      "metadata": {
        "id": "yR1wYGn52TfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Acelerando el entrenamiento de los Modelos de _Deep learning_**\n",
        "\n",
        "El aprendizaje profundo o _Deep Learning_ se refiere a una familia de modelos basados en **redes neuronales artificiales** que son escalables (funcionan bien con grandes cantidades de datos) y tienen gran efectividad en diferentes tareas complejas sobre datos de distintas naturalezas.  \n",
        "\n",
        "Una de las principales características de muchos de los **_frameworks_** de _Deep Learning_ actuales es su habilidad para ser escalados. Esta habilidad es esencial dado que los modelos de _Deep Learning_ :\n",
        "\n",
        "* Son modelos que tienen una gran cantidad de parámetros por aprender.\n",
        "* Se aplican sobre conjuntos de datos enormes.\n",
        "\n",
        "Estas características de los modelos de _Deep Learning_ hacen que un entrenamiento convencional usando solamente una CPU, con varios núcleos, sea extremadamente lento. Por ello se han desarrollado varias estrategias para acelerar dicho entrenamiento. Entre estas se encuentra el uso de **GPU** (_Graphic processing Unit_) o unidades de procesamiento gráfico donde miles de procesadores pueden ejecutar tareas en paralelo acelerando así el entrenamiento.\n"
      ],
      "metadata": {
        "id": "CmLslYKk5e0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Conceptos Generales en _Tensorflow_** <a class=\"anchor\" id=\"section2\"></a>\n",
        "---\n",
        "Veamos algunos conceptos básicos de _Tensorflow_:\n"
      ],
      "metadata": {
        "id": "rRi1P4q85e27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Tensores\n",
        "\n",
        "La principal estructura de datos utilizada en _Tensorflow_ son los **tensores**. Se tratan de arreglos multidimensionales que permiten guardar información, además, se pueden entender como una generalización de los escalares, que serían tensores de orden 0 (0D-tensor), vectores o tensores de orden 1 (1D-tensor) y las matrices (2D-tensor). Veamos a continuación algunos ejemplos de tensores de distintos órdenes :\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1Mw0prq_XRmLbM6LdNz0isdjp_vQAZAQa\" alt = \"Ejemplo de Tensores de distintos ordenes\" width=\"80%\" /></center>"
      ],
      "metadata": {
        "id": "9AiC01zI-LVg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOBfYoNszu59"
      },
      "outputs": [],
      "source": [
        "# Definimos un 1D-tensor (vector) constante a partir de una lista\n",
        "t = tf.constant([2, 3, 4, 5], dtype=tf.int32)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un tensor tiene **dos propiedades básicas** :\n",
        "- Su forma (_shape_).\n",
        "- Su tipo (_dtype_).\n",
        "\n",
        "El _shape_, al igual que en _Numpy_, indica el orden, el número de dimensiones y el tamaño de cada dimensión."
      ],
      "metadata": {
        "id": "Tl4XH8tq0Z1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.shape)"
      ],
      "metadata": {
        "id": "Bqunyc3n0Z-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el ejemplo anterior tenemos un tensor de orden 1, es decir una única dimensión, de tamaño 4. Por otro lado, al igual que en cualquier lenguaje de programación, los tensores tienen un tipo de representación interna : ``tf.int32``, ``tf.float32``, ``tf.string``, entre otros. Una correcta selección del tipo de datos puede hacer los códigos **más eficientes**. En el ejemplo anterior, el tipo del tensor es entero de 32 bits.\n",
        "\n",
        "- El siguiente ejemplo corresponde a un tensor de orden 2, una matriz, cuyo tipo es flotante de 32 bits :"
      ],
      "metadata": {
        "id": "bE4sQyp--Uze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un 2D-tensor (matriz) variable a partir de una lista\n",
        "t = tf.constant([[9, 5], [1, 0]], dtype=tf.float32)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "uuiPnDe0-UBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En _Tensorflow_ hay dos tipos principales de tensores :\n",
        "\n",
        "* ```tf.constant``` : Son arreglos multidimensionales inmutables, es decir, son tensores que no van a cambiar durante la ejecución.\n",
        "* ```tf.Variable``` : Se trata de tensores cuyos valores pueden cambiar durante la ejecución (por ejemplo, los parámetros de un modelo se definen como variables, ya que, estos valores se actualizan de forma iterativa).\n",
        "\n",
        "Veamos un ejemplo de variables en _Tensorflow_ :"
      ],
      "metadata": {
        "id": "m9ARpgTX-U2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un 2D-tensor (matriz) variable a partir de una lista\n",
        "t = tf.Variable([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "caHVVyW7_qmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Al tensor variable le podemos asignar un nuevo valor\n",
        "t.assign([[-2, -1], [-3, -7]])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "vnzYYw37_qxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# También podemos sumarle o restarle un valor\n",
        "t.assign_add([[1, 1], [1, 1]])\n",
        "print(t)\n",
        "t.assign_sub([[2, 2], [2, 2]])\n",
        "print(t)"
      ],
      "metadata": {
        "id": "SnDUQDBi_qzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos realizar diversas operaciones y definir funciones sobre tensores. Así mismo, _Tensorflow_ provee un *slicing* similar al de los arreglos de _Numpy_. Veamos un ejemplo :"
      ],
      "metadata": {
        "id": "N1CRSzkg_x-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un 2D-tensor A\n",
        "A=tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
        "\n",
        "# Definimos un 2D-tensor B\n",
        "B=tf.constant([[-1, -2], [-3, -4]], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "mZ7Bn02z_yqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suma\n",
        "A + B"
      ],
      "metadata": {
        "id": "bK5Cc6d6_11X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resta\n",
        "A - B"
      ],
      "metadata": {
        "id": "J6GAHH_4_14U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación por un escalar (definido en Python)\n",
        "3 * A"
      ],
      "metadata": {
        "id": "9G_qK765_16p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación elemento a elemento\n",
        "A * B"
      ],
      "metadata": {
        "id": "2cVJstbJ_19m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplicación matricial\n",
        "print(tf.matmul(A, B))"
      ],
      "metadata": {
        "id": "PvtDdlEh_-js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplos de slicing\n",
        "print(f'Tensor original:\\n {A}')\n",
        "# Seleccionamos la primera fila\n",
        "print(f'Primera fila:\\n {A[0]}')\n",
        "# Seleccionamos el primer elemento de la primera fila\n",
        "print(f'Primer elemento de la primera fila: \\n {A[0, 0]}')\n",
        "# Selecionamos la segunda columna\n",
        "print(f'Segunda columna:\\n {A[:, 1]}')\n",
        "# Invertimos las filas\n",
        "print(f'Filas invertidas:\\n {A[::-1]}')"
      ],
      "metadata": {
        "id": "0IDePZSs_-l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos aplicar diferentes funciones matemáticas a todos los elementos de un tensor :"
      ],
      "metadata": {
        "id": "1wfnHFDuAC_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logaritmo\n",
        "tf.math.log(A)"
      ],
      "metadata": {
        "id": "lVWOe55W_-op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coseno\n",
        "tf.math.cos(A)"
      ],
      "metadata": {
        "id": "ZWJygcdB1llx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otros tipos de operaciones aritméticas, funciones matemáticas y operaciones de álgebra lineal se pueden encontrar en el paquete ```tf.math``` y de álgebra lineal en el paquete ```tf.linalg```."
      ],
      "metadata": {
        "id": "esfLYCtGAIqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 _Eager execution_\n",
        "\n",
        "*Tensorflow* provee un ambiente de programación **imperativo** (*Eager execution*) para evaluar las operaciones de forma inmediata sin la necesidad de que el usuario especifique explícitamente un grafo. Es decir, el resultado de las operaciones son valores concretos en lugar de variables simbólicas dentro del grafo computacional. Además, también permite construir el grafo de forma automática en casos donde sea requerido. Esto permite comenzar más fácilmente a programar en *Tensorflow* y a depurar modelos. Adicionalmente, *Eager execution* soporta la mayoría de las funcionalidades de *Tensorflow* y también permite aceleración por GPU.\n",
        "\n",
        "*Eager execution* es una plataforma flexible para la investigación y la experimentación que provee :\n",
        "\n",
        "* **Interfaz intuitiva** : Permite desarrollar código de forma natural y usar estructuras de datos de _Python_. También permite desarrollar rápido aplicaciones en casos con modelos pequeños y con  pocos datos.\n",
        "\n",
        "* **Depuración simple** : Ejecutar las operaciones directamente. Permite revisar a detalle los modelos durante ejecución y evaluar cambios. Además, utiliza herramientas de depuración nativas en _Python_ para reportar errores de forma inmediata.\n",
        "\n",
        "* **Control natural** : Controlar las variables desde _Python_ en lugar de un control por medio de un grafo, simplifica la especificación de modelos más dinámicos.\n",
        "\n",
        "La versión 2.0 de *Tensorflow* trae por defecto *Eager execution*.\n",
        "\n",
        "**Importante: esto quiere decir que todas las operaciones matemáticas que hicimos en la sección anterior, se hicieron bajo ejecución *eager*.**"
      ],
      "metadata": {
        "id": "O0aTLdIBAM96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisamos la versión de Tensorflow\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "FBgg3cAPAGHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revisamos si eager execution está activa\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "id": "7GdDuV0xAGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por defecto, *Eager execution* ejecuta las operaciones de **forma secuencial**, es decir, no construye un grafo computacional de no ser que sea necesario para alguna operación o de ser especificado. Para que _Tensorflow_ construya el grafo debemos utilizar el decorador ```tf.function``` como se muestra a continuación :"
      ],
      "metadata": {
        "id": "jJcY0sMbAW6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una función normal en Python (ejecuta las operaciones de forma secuencial)\n",
        "def my_func1(x):\n",
        "    a = tf.constant(10, tf.float32, name= 'a')\n",
        "    b = tf.constant(-5, tf.float32, name= 'b')\n",
        "    c = tf.constant(4, tf.float32, name= 'c')\n",
        "    y = a * x * x + b * x + c\n",
        "    return y\n",
        "\n",
        "print(type(my_func1))\n",
        "print(my_func1(5))"
      ],
      "metadata": {
        "id": "rTOWtIZv_-rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una función decorada (construye internamente el grafo computacional)\n",
        "@tf.function\n",
        "def my_func2(x):\n",
        "    a = tf.constant(10, tf.float32, name= 'a')\n",
        "    b = tf.constant(-5, tf.float32, name= 'b')\n",
        "    c = tf.constant(4, tf.float32, name= 'c')\n",
        "    y = a * x * x + b * x + c\n",
        "    return y\n",
        "\n",
        "print(type(my_func2))\n",
        "print(my_func2(5))"
      ],
      "metadata": {
        "id": "2lgu6RuoAGMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14r8LaMThJRvIS7s0gpA9o0X29Rm743ZB\" alt = \"Gráfica de la función 10x^2-5^x+4\" width=\"40%\" />\n",
        "</center>\n",
        "\n",
        "Note que `my_func1` y `my_func2` corresponden a la misma función :\n",
        "\n",
        "$$f(x)=10x^2-5x+4$$\n",
        "\n",
        "Ahora veamos una comparación entre el tiempo promedio de cálculo de estas dos funciones :"
      ],
      "metadata": {
        "id": "JX7qMgkJAfF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1000\n",
        "my_func1(tf.constant([1, 2, 3, 4], dtype=tf.float32))"
      ],
      "metadata": {
        "id": "bpU3ZSej_-wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 1000\n",
        "my_func2(tf.constant([1, 2, 3, 4], dtype=tf.float32))"
      ],
      "metadata": {
        "id": "_46rbjF4_-yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Grafo Computacional y _TensorBoard_\n",
        "\n",
        "_Tensorflow_ es de gran utilidad para el _Deep Learning_ debido fundamentalmente a que permite realizar diferenciación automática y paralelización de operaciones matemáticas. _Tensorflow_ consigue esto al construir internamente un **grafo computacional** :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1YXiVhjZ5N3WrEBCM081Rhn6MhSTVlXVm\" alt = \"Ejemplo de Grafo Computacional\"  width=\"40%\" />\n",
        "</center>\n",
        "\n",
        "Este grafo define un flujo de datos basado en expresiones matemáticas. Más específicamente, _Tensorflow_ utiliza un grafo dirigido donde cada nodo representa una operación.\n",
        "\n",
        "- Una de las principales ventajas de usar un grafo computacional es que las operaciones se definen como relaciones o dependencias, lo cual permite que los cómputos sean fácilmente simplificados y paralelizados. Esto es mucho más práctico en comparación con un programa convencional donde las operaciones se ejecutan de forma secuencial.\n",
        "\n",
        "- _**TensorBoard**_ es una herramienta que proporciona las mediciones y visualizaciones necesarias durante el flujo de trabajo del _Machine Learning_. Permite realizar un seguimiento de las métricas de los experimentos, como la pérdida y la precisión, visualizar el gráfico del modelo, proyectar incrustaciones a un espacio de menor dimensión y mucho más.\n",
        "\n",
        "A continuación, usaremos _Tensorboard_ para visualizar el gráfico de una función. La visualización es interactiva, por lo que puedes expandir y colapsar nodos, acercarte, alejarte, desplazarte, etc.\n",
        "\n",
        "Generalmente TensorBoard se usa para monitorear el entrenamiento de un modelo, como lo veremos más adelante en el curso. El siguiente código monitorea la ejecución de la función `my_func2` definida anteriormente."
      ],
      "metadata": {
        "id": "dRNHGMHC9GBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.summary.trace_on() y tf.summary.trace_export().\n",
        "tf.summary.trace_on(graph=True, profiler=True, profiler_outdir=logdir)\n",
        "# Llamando a una tf.function: my_func2\n",
        "x = tf.constant(5, tf.float32)\n",
        "z = my_func2(x)\n",
        "with writer.as_default():\n",
        "  tf.summary.trace_export(\n",
        "      name=\"my_func_trace\",\n",
        "      step=0)"
      ],
      "metadata": {
        "id": "t56Ooqwb8_Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/func"
      ],
      "metadata": {
        "id": "XQnwqlm_8_UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Diferenciación\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uGkaY7xq4XubB0BmcrIQlsgtBf7P3ngo\" alt= \"Gráfico de Back Propagation\" width=\"60%\" />\n",
        "</center>\n",
        "\n",
        "Podemos calcular el gradiente de cualquier expresión con respecto a una variable que aparezca en ella. Para ello tenemos que usar un objeto `GradientTape` que lleva la cuenta de las operaciones ejecutadas dentro del contexto correspondiente, luego , utilizar ese registro y los gradientes de las operaciones para calcular el gradiente respectivo utilizando una forma general de *backpropagation* llamada **diferenciación en modo inverso** :\n"
      ],
      "metadata": {
        "id": "hSObM3ujDtSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(5.0)\n",
        "with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    y = my_func2(x)\n",
        "dy_dx = t.gradient(y, x)\n",
        "dy_dx"
      ],
      "metadata": {
        "id": "-NfSPxGzEdNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto funciona tanto para *Eager execution* como para los grafos :\n"
      ],
      "metadata": {
        "id": "MxGKt7YHE7K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(5.0)\n",
        "with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    y = my_func1(x)\n",
        "dy_dx = t.gradient(y, x)\n",
        "dy_dx"
      ],
      "metadata": {
        "id": "Dy5OomT-EdQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos utilizar el gradiente descendente para encontrar un mínimo del polinomio representado en el gráfico. Aquí tenemos que cambiar `x` para que sea una variable dado que su valor se va a actualizar para diferentes evaluaciones sucesivas del grafo."
      ],
      "metadata": {
        "id": "EIIWN6-uIExq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(5.0)\n",
        "dy_dx = 1\n",
        "while np.abs(dy_dx) > 0.01:\n",
        "    with tf.GradientTape() as t:\n",
        "        t.watch(x)\n",
        "        y = my_func1(x)\n",
        "    dy_dx = t.gradient(y, x)\n",
        "    x.assign(x - 0.01*dy_dx)\n",
        "    print(\"f(x)=\", my_func1(x).numpy(), \"df(x)/dx=\", dy_dx.numpy())"
      ],
      "metadata": {
        "id": "aS9yuIORIEM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que $3.375001$ es una muy buena aproximación al valor mínimo real que puede obtener la función `my_func1`: $3.375$.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1stkjv1_Wi-I0KhRt8DuoE5sRUR47bDUw\" alt = \"Ejemplo de gradiente Descendente\" width=\"50%\" />\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "k5T1hZ7uPumE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Optimizadores\n",
        "\n",
        "_Tensorflow_ ya tiene implementado el proceso de gradiente descendente: [`tf.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD). El gradiente descendente, o gradiente descendente estocástico (_Stochastic Gradient Descent, SGD_) es un *optimizador*, que nos permitirá optimizar (valga la redundancia) la función que definirá nuestro modelo de _Machine Learning_.\n",
        "\n",
        "A continuación, optimizáremos la misma función del caso anterior, pero usaremos directamente `tf.keras.optimizers.SGD` para el proceso iterativo. Nótese que definimos `learning_rate=0.01`, esto es, fijar la tasa de aprendizaje, o el tamaño de paso, en $0.01$ veces la magnitud del gradiente, igual a como lo hicimos en el caso anterior.\n",
        "\n",
        "\n",
        "- `loss`: La función de pérdida que se quiere optimizar.\n",
        "- `var_list`: La lista de las variables respecto a las cuales se deben calcular los gradientes.\n",
        "\n",
        "`apply_gradients` reemplaza `minimize`. Este método toma una lista de pares (gradiente, variable) y actualiza las variables según los gradientes calculados.\n",
        "\n",
        "Veamos cómo hacerlo:\n",
        "\n",
        "- Primero definimos el optimizador e inicializamos la variable `x`:\n"
      ],
      "metadata": {
        "id": "ZnCCLIj2NKqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "yNmYhE_Gzibp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Definimos la función `create_f_x`, que crea una variable de TensorFlow `x` y una función `f_x` (correspondiente a $f(x)=10x^2-5x+4$), que depende de `x` y será nuestra función a optimizar :"
      ],
      "metadata": {
        "id": "3i6x0UCTzwU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_f_x(init_val):\n",
        "    x = tf.Variable(init_val)\n",
        "    def f_x():\n",
        "        return 10 * x * x - 5 * x + 4\n",
        "    return x, f_x"
      ],
      "metadata": {
        "id": "B1TG2Goy0Eyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hacemos 40 iteraciones de gradiente descendente con la función `minimize`:"
      ],
      "metadata": {
        "id": "vk6N11Ww0H45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, f_x = create_f_x(5.0)\n",
        "for i in range(40):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = f_x()\n",
        "    gradients = tape.gradient(loss, [x])\n",
        "    sgd.apply_gradients(zip(gradients, [x]))\n",
        "    print('f(x)=', f_x().numpy())"
      ],
      "metadata": {
        "id": "A3ePYdoPSHDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De nuevo, llegamos a un valor óptimo aproximado de $3.375$. `tf.keras.optimizers.SGD` no es el único optimizador que ofrece _Tensorflow_. Entre los más populares por su eficiencia y robustez están :\n",
        "- **_Adam_** ([`tf.keras.optimizers.Adam\n",
        "`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))\n",
        "- **_RMSprop_** ([`tf.keras.optimizers.RMSprop`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop)).\n",
        "\n",
        "En general, el mejor optimizador va a depender de cada modelo, de los datos y de la  exploración que se realice. La lista completa de optimizadores disponibles la puedes encontrar en :\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers.\n",
        "\n",
        "A continuación repetiremos la optimización del caso anterior pero, usaremos `tf.keras.optimizers.RMSprop` en lugar de `SGD`, y una tasa de aprendizaje de $0.5$ en lugar de $0.01$."
      ],
      "metadata": {
        "id": "tTGAFE9qUbTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rms = tf.keras.optimizers.RMSprop(learning_rate=0.5)\n",
        "x, f_x = create_f_x(5.)\n",
        "\n",
        "for i in range(20):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = f_x()\n",
        "    gradients = tape.gradient(loss, [x])\n",
        "    rms.apply_gradients(zip(gradients, [x]))\n",
        "    print('f(x)=', f_x().numpy())"
      ],
      "metadata": {
        "id": "fGMZxRQ8W_gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note la diferencia en el número de iteraciones necesarias para llegar al valor óptimo de la función."
      ],
      "metadata": {
        "id": "HF_ULeJ5QX-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Integración de _TensorFlow_ con _Numpy_\n",
        "\n",
        "Una de las principales ventajas de _Tensorflow 2.0_ es su compatibilidad con arreglos y operaciones de _Numpy_. Esta última es la librería de álgebra lineal más usada en _Python_.\n",
        "\n",
        "- Veamos algunos ejemplos con _Numpy_ y _Tensorflow_:"
      ],
      "metadata": {
        "id": "pjC1a_rQ5est"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un arreglo en numpy, la función linspace crea una secuencia de 'num' números\n",
        "# Igualmente distanciados entre dos límites 'start' y 'stop'\n",
        "x = np.linspace(start=0, stop=1, num=10)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "KzBDv5Kp5eHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos algunas operaciones en Tensorflow, por ejemplo, sumar todos los números en el tensor\n",
        "acum = tf.reduce_sum(x)\n",
        "print(acum)"
      ],
      "metadata": {
        "id": "oXp9FfHH5eJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un tensor en Tensorflow\n",
        "x = tf.linspace(0.0,1.0,10)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Lr3flRGT5eMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos algunas operaciones en Numpy\n",
        "acum = np.sum(x)\n",
        "print(acum)"
      ],
      "metadata": {
        "id": "6-lLxPGM5eOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir arreglo de Numpy a tensor\n",
        "x = np.linspace(0,1,10)\n",
        "t = tf.constant(x)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "MWasChqi5eQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir tensor a arreglo de Numpy\n",
        "t = tf.linspace(0.0,1.0,10)\n",
        "x = t.numpy()\n",
        "print(x)"
      ],
      "metadata": {
        "id": "doFefVpT5eTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 CPU vs GPU\n",
        "\n",
        "En general la sintaxis de _Tensorflow_ es muy similar a la de _Numpy_, y dada esta funcionalidad, podemos usar arreglos de cualquiera de los dos _frameworks_ conjuntamente. Sin embargo, esto no es recomendable: es necesario tener en cuenta que _Numpy_ está diseñado para trabajar con la CPU, mientras que _Tensorflow_ permite utilizar hardware para acelerar el cómputo (e.g., unidades de procesamiento gráfico (GPU) o unidades de procesamiento tensorial (TPU)). La conversión de información entre la vRAM de la GPU y la RAM del computador es una operación costosa, y solo se debe considerarse en caso de que sea completamente necesaria.\n",
        "\n",
        "- Veamos un ejemplo de cómo seleccionar el tipo de hardware que se usará y una comparación del desempeño.\n",
        "\n",
        "**_En el siguiente código especificamos que los cálculos deben hacerse utilizando la CPU_** :\n"
      ],
      "metadata": {
        "id": "L-afRSFJ6xuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "# Ejecución en CPU\n",
        "with tf.device(\"CPU:0\"):\n",
        "    X = tf.random.uniform(shape=(1000, 1000), minval=0, maxval=1)\n",
        "    # La siguiente función evalúa si un tensor está en determinado dispositivo\n",
        "    assert X.device.endswith(\"CPU:0\")\n",
        "    tf.matmul(X, X)"
      ],
      "metadata": {
        "id": "nzemEDpf6xVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_El siguiente código especifica que el dispositivo para llevar a cabo la ejecución debe ser la GPU_** :"
      ],
      "metadata": {
        "id": "qjxKwpZj633i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "# Ejecución en GPU\n",
        "with tf.device(\"GPU:0\"):\n",
        "    X = tf.random.uniform(shape=(1000, 1000), minval=0, maxval=1)\n",
        "    # La siguiente función evalúa si un tensor está en determinado dispositivo\n",
        "    assert X.device.endswith(\"GPU:0\")\n",
        "    tf.matmul(X, X)"
      ],
      "metadata": {
        "id": "6PtJKMy563VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, veamos una comparación de la misma operación en _Numpy_ :"
      ],
      "metadata": {
        "id": "OkRZZsIW69La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "# Ejecución en CPU con numpy\n",
        "X = np.random.uniform(0, 1, size=(1000, 1000))\n",
        "X @ X"
      ],
      "metadata": {
        "id": "rXg8yXkN6xX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note la diferencia de tiempo de todas las ejeciciones anteriores. En todos los casos el cálculo es el mismo, pero **el proceso de _Numpy_ es considerablemente más demorado** que el proceso de _Tensorflow_ en GPU."
      ],
      "metadata": {
        "id": "nkw9erL3-2Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Modelo lineal en Tensorflow** <a class=\"anchor\" id=\"section3\"></a>\n",
        "---\n",
        "Veamos ejemplos de implementación de modelos básicos de *Machine Learning* usando tanto _Tensorflow_ como _Keras_. **Primero, _Tensorflow_** :"
      ],
      "metadata": {
        "id": "stqYHunYJgv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.1 Cargar datos\n",
        "\n",
        "Implementaremos un modelo de regresión logística para clasificar los siguientes datos :"
      ],
      "metadata": {
        "id": "N_xwgaLcLvUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X_train, Y_train = make_blobs(n_samples=100, centers=2, n_features=2, random_state=0)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_data(X_train, Y_train)"
      ],
      "metadata": {
        "id": "mOqwvC6dK4L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Volvemos tensores los datos de entrenamiento:\n",
        "\n",
        "X_t = tf.constant(X_train, dtype=tf.float32)\n",
        "Y_t = tf.constant(Y_train, dtype=tf.float32)\n",
        "\n",
        "# Añadimos una dimensión a las etiquetas, para que tengan shape=(100,1)\n",
        "Y_t = tf.expand_dims(Y_t, axis=-1, name=None)"
      ],
      "metadata": {
        "id": "6iC_zKJrsp4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Definir el modelo\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1C9z4WHUTm5DCENCYHp0jstnHv-BT1ezy\" alt = \"Regresión Lineal\" width=\"60%\" />\n",
        "</center>\n",
        "\n",
        "La regresión logística es un **modelo de clasificación binaria**, es decir, las etiquetas pueden tomar el valor de 0 o 1. El modelo logístico se muestra a continuación :\n",
        "\n",
        "$$\n",
        "\\tilde{y_i}=\\frac{1}{1+e^{-w_1 x_1-w_2 x_2-\\dots-w_m x_m -w_0}}=\\frac{1}{1+e^{-\\vec{w}\\cdot\\vec{x}_i}},\n",
        "$$\n",
        "\n",
        "donde $\\vec{w}=(w_1, w_2, \\dots, w_m, w_0)$ y $\\vec{x}_i=(x_1,x_2,\\dots,x_m, 1)^T$. Este es un modelo lineal que se compone de dos parámetros: los pesos ($w_1,w_2,\\dots,w_m$) y el sesgo o intercepto ($w_0$). La expresión $\\vec{x}_i$ corresponde a la representación de la muestra `i`-ésima de nuestro conjunto de datos, y $\\tilde{y_i}$ es la predicción que hace el modelo para la muestra $\\vec{x}_i$. Si tenemos en cuenta que\n",
        "\n",
        "$$\n",
        "\\text{sigmoid}(z)=\\frac{1}{1+e^{-z}}\n",
        "$$\n",
        "\n",
        "El modelo de regresión logística equivalente a la siguiente expresión :\n",
        "\n",
        "$$\n",
        "\\tilde{y_i}=\\text{sigmoid}(-\\vec{w}\\cdot\\vec{x}_i)\n",
        "$$\n",
        "\n",
        "Usando funciones de _Tensorflow_ podemos implementar la función sigmoide. Entonces podemos facilmente definir nuestra función de predicción, o modelo :"
      ],
      "metadata": {
        "id": "SUZCZTNuL-EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_reg(w, b, X):\n",
        "    return 1/(1+tf.math.exp(-(tf.matmul(X, w) + b)))"
      ],
      "metadata": {
        "id": "cK_yXLQDMxlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asignando unos valores aleatorios a los pesos $(w,b)$, por ejemplo $w=(0.5,0.5)$ y $b=-0.5$, podemos calcular algunas predicciones con el modelo no entrenado :"
      ],
      "metadata": {
        "id": "fXw1iTHHEJAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:10, :]"
      ],
      "metadata": {
        "id": "YNJeLYUZ8AQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos las predicciones sobre las primeras 10 muestras de X_train:\n",
        "log_reg(w=np.array([[0.5],[0.5]]),\n",
        "        b=-0.5,\n",
        "        X=X_train[:10, :])"
      ],
      "metadata": {
        "id": "LTPla_y8KkJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aproximemos las predicciones al entero más cercano para obtener resultados binarios :"
      ],
      "metadata": {
        "id": "OpoaSQmcFdt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reshape(-1), hace el ejercicio de reduccion"
      ],
      "metadata": {
        "id": "xRtrUKmS8i2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.rint(log_reg(w=np.array([[0.5],[0.5]]),\n",
        "        b=-0.5,\n",
        "        X=X_train[:10, :])).reshape(-1)"
      ],
      "metadata": {
        "id": "C4gXPUlWFi2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como todas las predicciones eran valores mayores a `0.5`, todas son hacia la clase `1`. Como estas predicciones se calculan con un modelo no entrenado, seguramente no van a ser muy acertadas. Compare el vector de predicciones anterior con el vector de etiquetas reales correspondiente:"
      ],
      "metadata": {
        "id": "a3o19bWpFA_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train[0:10])"
      ],
      "metadata": {
        "id": "aDoszPUVFU12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Función de pérdida\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1jRb2TAHdC78rRT29igyn-KONSNnWkEYO\" alt = \"Gráfica de Función de perdida\" width=\"80%\" />\n",
        "</center>\n",
        "\n",
        "\n",
        "La regresión logística se puede abordar como un problema de optimización con una **función de pérdida** (o *Loss Function*) conocida como **entropía cruzada binaria** (*binary cross-entropy*), la cual se muestra a continuación :\n",
        "\n",
        "$$L(\\vec{w}, y, \\tilde{y} )=-\\frac{1}{N}\\sum_{i=1}^{N}[y_i\\log(\\tilde{y}_i)+(1-y_i)\\log(1-\\tilde{y}_i)],$$\n",
        "\n",
        "donde $N$ es el número de datos de entrenamiento, $y_i$ representa el valor real de la clase (la etiqueta 0 o 1) y $\\tilde{y}_i$ el valor que predice el modelo. Esta función cuantifica el error de predicción del modelo, y por tanto se hace pequeña en la medida que el modelo haga predicciones correctas. Por ejemplo, si $y_i=0$ y $\\tilde{y}_i\\approx0$ entonces $(y_i\\log(\\tilde{y}_i)+(1-y_i)\\log(1-\\tilde{y}_i))\\approx0$, es decir, penaliza poco. Por el contrario, si $y_i=1$ y $\\tilde{y}_i\\approx0$ entonces $(y_i\\log(\\tilde{y}_i)+(1-y_i)\\log(1-\\tilde{y}_i))$ es mucho mayor a 0, es decir, penaliza bastante. Algo analogo sucede cuando $y_i=1$ y $\\tilde{y}_i\\approx1$ o $\\tilde{y}_i\\approx0$, respectivamente.\n",
        "\n",
        "\n",
        "Nuestro objetivo será ajustar los parámetros $\\vec{w}$ del modelo $\\text{sigmoid}(-\\vec{w}\\cdot\\vec{x}_i)$ para que $L(\\vec{w})$ sea lo más cercano a cero posible.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1g1EolYPXm-0HTIqhhIlN7r8z4OXb-HYK\" alt = \"Visualización de pérdidas\" width=\"80%\" />\n",
        "</center>\n",
        "\n",
        "A continuación definiremos la función `bce` para calcular el *binary cross-entropy* a partir de las etiquetas reales `y_true` y las que predice el modelo `y_pred`."
      ],
      "metadata": {
        "id": "J4heOB7pr2UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la función binary cross-entropy\n",
        "def bce(y_true, y_pred):\n",
        "    return -tf.math.reduce_mean(y_true * tf.math.log(y_pred) + (1. - y_true) * tf.math.log(1. - y_pred))"
      ],
      "metadata": {
        "id": "5ke7rAN6vM7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando `bce` podemos entonces definir la función de pérdida `loss_fun` que vamos a optimizar en el entrenamiento:"
      ],
      "metadata": {
        "id": "tm6aHZxLF_uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una función que crea las variables representando los parámetros del\n",
        "# modelo, aplica el modelo y calcula la función de pérdida\n",
        "def create_model(X_t, Y_t):\n",
        "    w = tf.Variable([[1.0],[-1.0]])\n",
        "    b = tf.Variable(0.5)\n",
        "    def loss_fun():\n",
        "        y_pred = log_reg(w, b, X_t)\n",
        "        return bce(Y_t, y_pred)\n",
        "    return w, b, loss_fun"
      ],
      "metadata": {
        "id": "8-G210VqGB05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Entrenamiento\n",
        "\n",
        "Ahora definimos las operaciones para calcular la pérdida y optimizarla usando `tf.keras.optimizers.SGD` con `learning_rate=0.5` :"
      ],
      "metadata": {
        "id": "CgEfz3yGZioh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos nuestro modelos a optimizar\n",
        "\n",
        "w, b, loss_fun = create_model(X_t, Y_t)\n",
        "\n",
        "# Stochastic Gradient Descent como optimizador:\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
        "\n",
        "# Iteramos 50 veces el proceso de optimización del gradiente descendente,\n",
        "# y guardamos el valor final de la función de pérdida en cada iteración:\n",
        "\n",
        "losses = []\n",
        "for i in range(50):\n",
        "    print('Epoch',i,end=' ')\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fun()\n",
        "    gradients = tape.gradient(loss, [w, b])\n",
        "    opt.apply_gradients(zip(gradients, [w, b]))\n",
        "    print('loss =',loss_fun().numpy())\n",
        "    losses.append(loss_fun().numpy())"
      ],
      "metadata": {
        "id": "7ljCFBgrKkMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos visualizar el comportamiento de la función de pérdida a medida que avanzan las iteraciones :"
      ],
      "metadata": {
        "id": "hnRIgBXSe5RX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,16/3))\n",
        "plt.title('Loss Function vs Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "JifLogRZKkPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal como queremos, la función de pérdida disminuye a medida que las iteraciones (o **_epochs_**) avanzan, es decir, estamos optimizando correctamente la función de pérdida de nuestro modelo, y está *aprendiendo*."
      ],
      "metadata": {
        "id": "zj8LRe6zowD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Resultados\n",
        "\n",
        "Ahora utilizamos la función `plot_decision_function`, definida al principio del notebook, para visualizar la región de decisión.  "
      ],
      "metadata": {
        "id": "ObzLm43n31fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_fun(X):\n",
        "    X = tf.constant(X, dtype=tf.float32)\n",
        "    return log_reg(w, b, X).numpy()\n",
        "\n",
        "plt.figure(figsize = (8,16/3))\n",
        "plot_decision_region(X_train, pred_fun)\n",
        "plot_data(X_train, Y_train)"
      ],
      "metadata": {
        "id": "t7Hq9b9XvrAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Modelo lineal en _Keras_** <a class=\"anchor\" id=\"section4\"></a>\n",
        "---\n",
        "Ahora haremos de nuevo una regresión logística, usando los mismos datos, pero armando el modelo en _Keras_ para notar las diferencias con _Tensorflow_:\n"
      ],
      "metadata": {
        "id": "KbEqtb-2w43t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 _Keras_\n",
        "Originalmente, _Keras_ era un *framework* de alto nivel escrito en _Python_ que utilizaba diferentes *backends* de *Deep learning* como: _Tensorflow_, _CNTK_ o _Theano_. Actualmente, es un paquete dentro de _Tensorflow 2.0_ que nos permite simplificar tanto el entrenamiento como el diseño de modelos de *Machine Learning* y redes neuronales.\n",
        "\n",
        "```tf.keras``` es usado para la creación rápida de modelos y tiene tres ventajas :\n",
        "\n",
        "* **Amigable al usuario**: _Keras_ tiene una interfaz simple y consistente que ha sido optimizada para el uso en casos típicos.\n",
        "* **Modular**: La construcción de modelos se basa en conectar bloques personalizables con pocas restricciones.\n",
        "* **Fácil extensión**: Permite implementar nuevos módulos fácilmente usando todas las funcionalidades de _Tensorflow_, lo cual, facilita la construcción de nuevos modelos o modelos del estado del arte."
      ],
      "metadata": {
        "id": "vyh2ZhvZ7ARp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Definir el modelo\n",
        "\n",
        "Veamos la implementación de este modelo en _Keras_. Primero definimos un objeto `tf.keras.models.Sequential`:"
      ],
      "metadata": {
        "id": "AimHuLLI2Frw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo\n",
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "p896XllF3BMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, usamos una capa `tf.keras.layers.Dense`, que nos permite fácilmente aplicar un operador linear a las entradas del modelo y luego aplicar una función sigmoide, entendida aquí como **función de activación**. `tf.keras.layers.Dense` es en sí misma una función que recibe una serie de argumentos para definir correctamente la capa de neuronas del modelo :\n",
        "\n",
        "*   `units`: Un número entero que define el número de neuronas de la capa.\n",
        "*   `input_shape`: Una tupla con la diménsión de los datos de entrada.\n",
        "*   `activation`: Una función de activación que se aplica a la salida de la capa.\n",
        "\n",
        "En este caso podemos usar la función sigmoide que ofrece _Tensorflow_: `tf.keras.activations.sigmoid`\n",
        "\n"
      ],
      "metadata": {
        "id": "rP1A5xx5Ge7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(\n",
        "                units=1,              # Definimos el tamaño de la dimensión de la predicción, en nuestro caso 1.\n",
        "                input_shape=(2, ),    # Definimos el tamaño de la dimensión de los datos de entrada, en nuestro caso 2.\n",
        "                activation=tf.keras.activations.sigmoid   # Definimos la función sigmoid que actua sobre w.x\n",
        "                ))"
      ],
      "metadata": {
        "id": "5NinAwzZGfvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Compilar el modelo\n",
        "\n",
        "El proceso de aprendizaje se configura con la función `compile`. Los argumentos necesarios para el entrenamiento posterior son:\n",
        "\n",
        "*   `optimizer`: Función que define el optimizador de gradiente descendente que se aplicará sobre la función de pérdida.  \n",
        "*   `loss`: Función de pérdida que define el objetivo de optimización.\n",
        "\n",
        "Aquí utilizaremos la función de pérdida de entropía cruzada `bce` que definimos anteriormente y un optimizador `tf.optimizers.SGD`. Este optimizador está definido como una función que automáticamente realiza el proceso de la función `minimize` que vimos en la sección anterior, y recibe como parámetro la tasa de aprendizaje o `learning_rate`.\n",
        "\n",
        "Además, si queremos, el proceso de aprendizaje puede obtener un seguimiento de la exactitud o *accuracy* de las predicciones del modelo. Para esto usamos otro argumento de `compile`:\n",
        "\n",
        "*   `metrics`: Una lista de métricas de desempeño que serán evaluadas durante entrenamiento y prueba.\n",
        "\n",
        "Podemos usar entonces cualquier métrica de desempeño correctamente definida. Por ejemplo, el *accuracy* o exactitud. Nosotros usaremos `tf.keras.metrics.BinaryAccuracy` que mide la exactitud en aplicaciones de clasificación binaria cuando la salida del modelo es una sola neurona. Entonces nuestra función `compile` queda así:"
      ],
      "metadata": {
        "id": "8Rgtkitl3cuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilamos el modelo\n",
        "model.compile(\n",
        "              optimizer=tf.optimizers.SGD(learning_rate=0.5), # Definimos el optimizador y la tasa de aprendizaje\n",
        "              loss=bce,                                       # Definimos la función de pérdida\n",
        "              metrics = [tf.keras.metrics.BinaryAccuracy()]   # Definimos una métrica para hacer seguimiento del desempeño durante el entrenamiento\n",
        "              )"
      ],
      "metadata": {
        "id": "6B7ypoV3zXkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La estructura del modelo se puede visualizar con `summary()`:"
      ],
      "metadata": {
        "id": "u4_RDxSb5ZZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BtPGsyKu4Rd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y también podemos obtener una vizualicación capa a capa con `tf.keras.utils.plot_model`, función que recibe como argumento a el modelo `model`:"
      ],
      "metadata": {
        "id": "0H3QKrtb-vkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "IJdrE8Me4RgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que efectivamente tenemos un modelo con tres parámetros por aprender. Inicialmente, _Keras_ genera los pesos del modelo de forma aleatoria (los cuales se estimarán durante el entrenamiento), veamos un ejemplo de esto:"
      ],
      "metadata": {
        "id": "Ja7xFWBhzWq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_fun(X):\n",
        "    X = tf.constant(X, dtype=tf.float32)\n",
        "    return model.predict(X, verbose=0)\n",
        "\n",
        "plt.figure(figsize = (8,16/3))\n",
        "plot_decision_region(X_train, pred_fun)\n",
        "plot_data(X_train, Y_train)"
      ],
      "metadata": {
        "id": "ifv8xubDzXeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que el modelo no está separando correctamente las clases. Ahora sí, vamos a entrenarlo:"
      ],
      "metadata": {
        "id": "7odtc659T0d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Entrenamiento\n",
        "\n",
        "El modelo se entrena llamando a la función `fit`. Esta función necesita los siguientes argumentos :\n",
        "\n",
        "\n",
        "*   `x`: Un array de _Numpy_ o tensor de _Tensorflow_ con los datos usados para entrenar.\n",
        "*   `y`: Un array de _Numpy_ o tensor de _Tensorflow_ con las etiquetas de los datos usados para entrenar.\n",
        "*   `epochs`: Un número entero, correspondiente al número de iteraciones completas de entrenamiento sobre el conjunto de datos `x`.\n",
        "\n",
        "\n",
        "En este punto pasamos como argumentos los datos de entrenamiento `X_t` y `Y_t` y el número de iteraciones de optimización que queremos hacer. Dese cuenta de que en este caso **no tenemos que ser explícitos** con las operaciones del cálculo del gradiente ni de la actualización de las variables."
      ],
      "metadata": {
        "id": "D7UAQP5n3hrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_t,        # Datos de entrada para entrenar\n",
        "          y=Y_t,        # Etiquetas (salida) para entrenar\n",
        "          epochs=50     # Número de iteraciones\n",
        "          )"
      ],
      "metadata": {
        "id": "wPWm_-Y4zXpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que `fit` por defecto nos va mostrando en cada iteración o *epoch* el valor de la función de pérdida *loss* y el desempeño según la métrica que especificamos en la compilación. Este seguimiento del entrenamiento se puede modificar con el parámetro `verbose` de la función `fit`."
      ],
      "metadata": {
        "id": "yR9wU0qYK5HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Resultados\n",
        "\n",
        "El modelo entrenado puede utilizarse para clasificar nuevas muestras\n",
        "utilizando `predict`. Esta función recibe como argumento los datos sobre los cuales queremos obtener una predicción:"
      ],
      "metadata": {
        "id": "JHrb8xKF3sZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(np.array([[0, 0]])))"
      ],
      "metadata": {
        "id": "bg94F7Y1486C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta es la región de decisión del modelo entrenado :"
      ],
      "metadata": {
        "id": "lLI5IaX-4_pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_fun(X):\n",
        "    X = tf.constant(X, dtype=tf.float32)\n",
        "    return model.predict(X, verbose=0)\n",
        "\n",
        "plt.figure(figsize = (8,16/3))\n",
        "plot_decision_region(X_train, pred_fun)\n",
        "plot_data(X_train, Y_train)"
      ],
      "metadata": {
        "id": "HhsY2dV0zXhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo lineal mejora mucho después de que se entrena; separa correctamente las clases.\n",
        "\n",
        "Con esto terminamos una introducción completa a los elementos necesarios para trabajar con modelos _Tensorflow_ y _Keras_.\n",
        "\n",
        "¡Muchas gracias!"
      ],
      "metadata": {
        "id": "mjoDZmDIUxmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recursos adicionales**\n",
        "---\n",
        "Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en el conocimiento de las funcionalidades de la librería *TensorFlow* y *Keras*:\n",
        "\n",
        "- [*TensorFlow - Tutorials*](https://www.tensorflow.org/tutorials)\n",
        "- [*TensorFlow - Basics*](https://www.tensorflow.org/guide/basics)\n",
        "- [*TensorFlow - Keras*](https://www.tensorflow.org/guide/keras/sequential_model)\n",
        "* _Origen de los íconos_\n",
        "    - Tensorflow. Model [SVG]. https://www.tensorflow.org/site-assets/images/marketing/home/model.svg\n",
        "    - Tensorflow. Robust [SVG]. https://www.tensorflow.org/site-assets/images/marketing/home/robust.svg\n",
        "    - Tensorflow. Research [SVG]. https://www.tensorflow.org/site-assets/images/marketing/home/research.svg"
      ],
      "metadata": {
        "id": "GhkUPQRYp-ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n",
        "* **Asistentes docentes :**\n",
        "  * [Santiago Toledo Cortés](https://sites.google.com/unal.edu.co/santiagotoledo-cortes/)\n",
        "  * [Juan Sebastián Lara](https://http://juselara.com/)\n",
        "* **Diseño de imágenes:**\n",
        "    - [Mario Andres Rodriguez Triana](https://www.linkedin.com/in/mario-andres-rodriguez-triana-394806145/).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ],
      "metadata": {
        "id": "3UN3ynxjqogH"
      }
    }
  ]
}