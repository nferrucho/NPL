{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso3/ciclo3/M6U3_Taller_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLlSr7BaKSLF"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=14reVO1X6LsjqJ3cFgoeHxxddZVGfZn3t\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEewD2N0RkMc"
      },
      "source": [
        "# **Taller 3: Ciclo de vida de ciencia de datos**\n",
        "---\n",
        "\n",
        "En este notebook evaluaremos los conceptos aprendidos sobre el ciclo de vida de ciencia de datos. En especial, entrenaremos un modelo con la librería `xgboost` con su debida optimización de hiperparámetros.\n",
        "\n",
        "Ejecute las siguientes celdas para conectarse a UNCode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAqkL4giPflw"
      },
      "outputs": [],
      "source": [
        "!pip install rlxcrypt\n",
        "!wget --no-cache -O session.pye -q https://raw.githubusercontent.com/JuezUN/INGInious/master/external%20libs/session.pye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKNgJYjHPhtr"
      },
      "outputs": [],
      "source": [
        "import rlxcrypt\n",
        "import session\n",
        "\n",
        "grader = session.LoginSequence(\"MAPEDDACML-GroupMLDS-6-2024-2@f8879e0a-fcd1-4b6b-a12f-31426dfcd762\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ocd--frFi7"
      },
      "source": [
        "Comenzamos instalando las librerías y herramientas necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMgHXLh7Zg1l"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow\n",
        "!pip install optuna optuna-dashboard mlflow xgboost\n",
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6-Jscb8Zyhb"
      },
      "source": [
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIB7qeOuVkfh"
      },
      "outputs": [],
      "source": [
        "# Librerías de utilidad para manipulación y visualización de datos.\n",
        "import os, mlflow, optuna\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "# Ignorar warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUMP_2CPqwRY"
      },
      "outputs": [],
      "source": [
        "# Versiones de las librerías usadas.\n",
        "import sklearn\n",
        "!python --version\n",
        "print('MLflow', mlflow.__version__)\n",
        "print('Optuna', optuna.__version__)\n",
        "print('Scikit-learn', sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNzX3sfq3gZ"
      },
      "source": [
        "Esta actividad se realizó con las siguientes versiones:\n",
        "*  Python 3.10.12\n",
        "*  Scikit-learn 1.4.2\n",
        "*  MLflow 2.12.1\n",
        "*  Optuna 3.6.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arWKQDholpQ9"
      },
      "source": [
        "> **La tarea es incremental, por lo tanto es recomendable resolver los puntos en orden**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovhiqwoP2quP"
      },
      "source": [
        "## **Carga de datos**\n",
        "---\n",
        "\n",
        "En este caso, utilizaremos un conjunto de datos sintético generado desde `sklearn`. Se trata de un *dataset* sintético utilizado comúnmente para tareas de clasificación binaria en aprendizaje automático. Este conjunto de datos consta de dos características continuas y una etiqueta binaria que indica a qué círculo pertenece cada punto.\n",
        "\n",
        "Específicamente, la función `make_circles` crea un conjunto de puntos distribuidos uniformemente en dos círculos concéntricos, donde la distancia entre los dos círculos es ajustable. La distribución de puntos dentro de cada círculo se controla mediante el parámetro `noise`, que agrega ruido aleatorio a la posición de cada punto.\n",
        "\n",
        "En general, este conjunto de datos se utiliza para evaluar la capacidad de los algoritmos de clasificación para separar clases no lineales en un espacio bidimensional. Debido a que los dos círculos se superponen, es imposible separar completamente las dos clases con una frontera de decisión lineal. Por lo tanto, se requieren técnicas más avanzadas, como la utilización de modelos no lineales, para clasificar adecuadamente los puntos en este conjunto de datos.\n",
        "\n",
        "Vamos a generarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7HTMw9e2-Nq"
      },
      "outputs": [],
      "source": [
        "features, labels = make_circles(\n",
        "    n_samples=1000,\n",
        "    noise=0.1,\n",
        "    factor=0.5,\n",
        "    random_state=0\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lzdfbJj3ARb"
      },
      "source": [
        "Podemos visualizar el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOpa-fZ23A7s"
      },
      "outputs": [],
      "source": [
        "## KEEPOUTPUT\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(features[:, 0], features[:, 1], c=labels, alpha=0.5, cmap=\"RdBu\")\n",
        "ax.set(xlabel=\"$x_1$\", ylabel=\"$x_2$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tTFH3JY3FEq"
      },
      "source": [
        "Adicionalmente, vamos a configurar el servidor de `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLIRrzVg3Fop"
      },
      "outputs": [],
      "source": [
        "command = \"\"\"\n",
        "mlflow server \\\n",
        "        --backend-store-uri sqlite:///tracking.db \\\n",
        "        --default-artifact-root file:mlruns \\\n",
        "        -p 5000 &\n",
        "\"\"\"\n",
        "get_ipython().system_raw(command)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-Tt4X4C3UbO"
      },
      "source": [
        "Utilizaremos `ngrok` para acceder al tablero de `mlflow`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQdLQGie3V0S"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqDo6fM3XCx"
      },
      "source": [
        "Ahora debe agregar su token de `ngrok`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YIecdOE3YcB"
      },
      "outputs": [],
      "source": [
        "token = \"\" # Agregue el token dentro de las comillas\n",
        "os.environ[\"NGROK_TOKEN\"] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix2SiRnD3gky"
      },
      "source": [
        "Nos autenticamos en ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFrH6PBg3gky"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_RhU9k3gky"
      },
      "source": [
        "Ahora, lanzamos la conexión con ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXFeP42d3gky"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.connect(5000, \"http\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EobRmA4x3gkz"
      },
      "source": [
        "Especificamos que MLFlow debe usar el servidor que estamos manejando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydaYcKZf3gkz"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"http://localhost:5000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QOEagMU3muG"
      },
      "source": [
        "Creamos un experimento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ChIm6TO3nOP"
      },
      "outputs": [],
      "source": [
        "exp = mlflow.create_experiment(name=\"circles\", artifact_location=\"mlruns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXCqFR7M3p82"
      },
      "source": [
        "Dividimos el conjunto de datos en entrenamiento y prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrC79dOD3qd9"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "        features, labels, test_size=0.3, random_state=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvlFb8xffeRb"
      },
      "source": [
        "## **1. Entrenamiento de Modelo**\n",
        "---\n",
        "\n",
        "En este punto deberá implementar una función que permita entrenar un modelo de `xgboost` dados los datos de entrenamiento y los hiperparámetros que exploráremos más adelante.\n",
        "\n",
        "Para esto debe implementar la función `train_model` la cual toma como entrada las características y etiquetas de entrenamiento, la profundidad de los árboles, el número de estimadores, y la taza de aprendizaje. La función debe retornar el modelo entrenado.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features`: matriz de características de entrenamiento.\n",
        "- `labels`: vector de etiquetas de entrenamiento.\n",
        "- `max_depth`: profundidad máxima del árbol.\n",
        "- `n_estimators`: número de estimadores.\n",
        "- `learning_rate`: taza de aprendizaje.\n",
        "- `random_state`: semilla de números aleatorios.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `model`: modelo de `xgboost` entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ADXyyYP29Jd"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA train_model:\n",
        "def train_model(\n",
        "    features,\n",
        "    labels,\n",
        "    max_depth,\n",
        "    n_estimators,\n",
        "    learning_rate,\n",
        "    random_state\n",
        "    ):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    model = ...\n",
        "    return model\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlggdiYK4Psh"
      },
      "source": [
        "Use las siguientes celdas para probar su solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4p8_UgE4dLh"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "model = train_model(\n",
        "        features=features_train,\n",
        "        labels=labels_train,\n",
        "        max_depth=2,\n",
        "        n_estimators=10,\n",
        "        learning_rate=1e-4,\n",
        "        random_state=0\n",
        "        )\n",
        "print(model.max_depth)\n",
        "print(model.n_estimators)\n",
        "print(model.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlIf9hFF4d-W"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "En este caso debería obtener los hiperparámetros del modelo:\n",
        "\n",
        "```python\n",
        "❱ print(model.max_depth)\n",
        "2\n",
        "\n",
        "❱ print(model.n_estimators)\n",
        "10\n",
        "\n",
        "❱ print(model.learning_rate)\n",
        "0.0001\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_ltBLES4gg6"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "model = train_model(\n",
        "        features=features_train,\n",
        "        labels=labels_train,\n",
        "        max_depth=2,\n",
        "        n_estimators=10,\n",
        "        learning_rate=1e-4,\n",
        "        random_state=0\n",
        "        )\n",
        "print(model.score(features_test, labels_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHcXCPxY4h8f"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "En este caso debería obtener el accuracy del modelo:\n",
        "\n",
        "```python\n",
        "❱ print(model.score(features_test, labels_test))\n",
        "0.48333333333333334\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAsG3vcvgQ29"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "* Recuerde que `XGBClassifier` funciona de una forma equivalente a `sklearn`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09aaEP4hgaRJ"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "* Valide que está usando los parámetros de la función y no las variables globales.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN9ExHNKizb4"
      },
      "source": [
        "#### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkx0OCDUmbEl"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 1_1\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayIk145NhE2H"
      },
      "source": [
        "## **2. Evaluación del modelo**\n",
        "---\n",
        "\n",
        "En este punto debe implementar una función que permita calcular el `f1_score` sobre el conjunto de evaluación a partir de un modelo entrenado.\n",
        "\n",
        "Para esto, debe implementar la función `eval_model`, la cual toma como entrada un modelo entrenado, las características y el vector de etiquetas de evaluación. Debe retornar el valor de la métrica.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `model`: modelo entrenado.\n",
        "- `features`: conjunto de datos de evaluación.\n",
        "- `labels`: etiquetas de evaluación.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `score`: f1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXOeCKPuhglE"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA eval_model:\n",
        "def eval_model(\n",
        "    model,\n",
        "    features,\n",
        "    labels,\n",
        "    ):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    score = ...\n",
        "    return score\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNZcobItiIkP"
      },
      "source": [
        "Use las siguientes celdas para probar su solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3S6Cwl1iIkQ"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "model = train_model(\n",
        "        features=features_train,\n",
        "        labels=labels_train,\n",
        "        max_depth=4,\n",
        "        n_estimators=100,\n",
        "        learning_rate=1e-3,\n",
        "        random_state=0\n",
        "        )\n",
        "score = eval_model(model, features_test, labels_test)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1sGCAmWiIkQ"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso debería obtener la métrica de desempeño para el modelo de los hiperparámetros dados.\n",
        "\n",
        "```python\n",
        "❱ print(score)\n",
        "0.0.9770491803278688\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebE1kufPiIkR"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "* Para evaluar el f1-score puede usar la función `f1_score` de `sklearn`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSalihzGiIkR"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "* Debe obtener las predicciones del modelo con el método `predict`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Rlsqs4iIkR"
      },
      "source": [
        "#### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qYWl7AqvCYh"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 2_1_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk2MmczMwM-M"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 2_1_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20b5GG19wryF"
      },
      "source": [
        "## **3. Ejecución en MLFlow**\n",
        "---\n",
        "\n",
        "Ahora, deberá crear una función que permita crear un **run** en `mlflow` para entrenar el modelo con sus correspondientes hiperparámetros bajo un experimento específico. Debe registrar el modelo, los hiperparámetros y la métrica del modelo que calcula en el punto anterior.\n",
        "\n",
        "Para ello deberá implementar la función `mlflow_run`, la cual toma como entrada las características y etiquetas de entrenamiento, la profundidad máxima del modelo, el número de estimadores, la taza de aprendizaje y el experimento de `mlflow`. Debe retornar la ejecución y el valor de la métrica del modelo.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features_train`: matriz de características de entrenamiento.\n",
        "- `labels_train`: vector de etiquetas de entrenamiento.\n",
        "- `features_test`: matriz de características de evaluación.\n",
        "- `labels_test`: vector de etiquetas de evaluación.\n",
        "- `max_depth`: profundidad máxima del árbol.\n",
        "- `n_estimators`: número de estimadores.\n",
        "- `learning_rate`: taza de aprendizaje.\n",
        "- `random_state`: semilla de números aleatorios.\n",
        "- `exp`: experimento de `mlflow`.\n",
        "- `run_name`: nombre a asignar a la ejecución.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `run`: ejecución de `mlflow`.\n",
        "- `score`: valor de la métrica en la ejecución."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F56i5Yfuwxx-"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA mlflow_run:\n",
        "def mlflow_run(\n",
        "    features_train,\n",
        "    labels_train,\n",
        "    features_test,\n",
        "    labels_test,\n",
        "    max_depth,\n",
        "    n_estimators,\n",
        "    learning_rate,\n",
        "    random_state,\n",
        "    exp,\n",
        "    run_name\n",
        "    ):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    run = ...\n",
        "    score = ...\n",
        "    return run, score\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVXKxW-cw-E2"
      },
      "source": [
        "Use las siguientes celdas para probar su solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69-mPZG8w5Pi"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "run, score = mlflow_run(\n",
        "        features_train=features_train,\n",
        "        labels_train=labels_train,\n",
        "        features_test=features_test,\n",
        "        labels_test=labels_test,\n",
        "        max_depth=4,\n",
        "        n_estimators=100,\n",
        "        learning_rate=1e-3,\n",
        "        random_state=0,\n",
        "        exp=exp,\n",
        "        run_name=\"test_case\"\n",
        "        )\n",
        "print(run.info.run_name)\n",
        "print(os.listdir(run.info.artifact_uri))\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3bu4Jyw-E3"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso debería obtener los metadatos de la ejecución y el valor de la métrica:\n",
        "\n",
        "```python\n",
        "❱ print(run.info.run_name)\n",
        "test_case\n",
        "\n",
        "❱ print(os.listdir(run.info.artifact_uri))\n",
        "['model']\n",
        "\n",
        "❱ print(score)\n",
        "0.9770491803278689\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe73YTbRw-E3"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "* Recuerde usar de forma adecuada las particiones de entrenamiento y prueba con las funciones `train_model` y `eval_model` respectivamente.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHJw8YLlw-E3"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "* Recuerde terminar la ejecución con la función `mlflow.end_run()`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz1EauAFx6NR"
      },
      "source": [
        "#### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E941b0G_x6NS"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 3_1_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_x3uk-Y5LUR"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 3_1_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhgwhBwm5xJE"
      },
      "source": [
        "## **4. Optimización de Hiperparámetros**\n",
        "---\n",
        "\n",
        "Ahora debe implementar la función objetivo para optimizar los hiper-parámetros con optuna. En específico debe variar los valores de la siguiente forma:\n",
        "\n",
        "- `max_depth`: valor entero entre 2 y 10.\n",
        "- `n_estimators`: valor entero entre 25 y 200.\n",
        "- `learning_rate`: valor continuo entre 1e-6 y 1 (variaciones logarítmicas).\n",
        "\n",
        "Todos los intentos deben estar registrados dentro de `mlflow`, para esto debe utilizar el experimento que está definido en la variable `exp`, como `run_name` debe utilizar el valor `\"optuna\"` y debe utilizar el valor 0 como `random_state`.\n",
        "\n",
        "Debe implementar la función `objective` la cual toma como entrada un trial de `optuna` y debe retornar el valor de la métrica a maximizar.\n",
        "\n",
        "**Parámetros**:\n",
        "\n",
        "- `trial`: objeto `trial` de `optuna`.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `score`: f1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuOq4dSw7B1F"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA objective:\n",
        "def objective(trial):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    score = ...\n",
        "    return score\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5VsXi5L7B1F"
      },
      "source": [
        "Use las siguientes celdas para probar su solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOPZac-X7B1G"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    storage=\"sqlite:///hp.db\",\n",
        "    study_name=\"circles\",\n",
        "    )\n",
        "study.optimize(func=objective, n_trials=30, n_jobs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPtpO2in7Uao"
      },
      "source": [
        "Si se dirige al dashboard de `mlflow`, deberá obtener varias ejecuciones bajo el nombre `optuna`. Puede filtrarlas todas al poner el filtro que se muestra en la imagen:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1j_7LYVWNADfVTW3YqUzhpcEHOaEPXXZ7\" width=\"80%\">\n",
        "\n",
        "También debe seleccionar todos los runs con el nombre `optuna` y dar click en `compare`. Esto debe generar el siguiente resultado:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CFnfmGdu0pgUbrGri-T8oNSafxQZAHSn\" width=\"80%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Fry6wP7B1G"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "* Puede utilizar el método `suggest_int` de un `Trial` para generar un hiperparámetro de tipo entero.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YaK4jSV7B1G"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "* Puede utilizar el método `suggest_float` de un `Trial` para generar un hiperparámetro continúo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP2-ECPP_OLj"
      },
      "source": [
        "## **5. Versionado de Modelo**\n",
        "---\n",
        "\n",
        "Por último, en este punto deberá generar una versión del mejor modelo con el nombre `xgboost` versión 1. Posteriormente, debe implementar una función que permita cargar el modelo:\n",
        "\n",
        "Para esto deberá implementar la función `load_model` la cual debe retornar el modelo versionado como `xgboost` versión 1:\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "La función no tiene parámetros de entrada.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `model`: modelo cargado con `mlflow`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqp6TLL9_Q7Q"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA load_model:\n",
        "def load_model():\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    model = ...\n",
        "    return model\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoJ0zGP0_o7K"
      },
      "source": [
        "Use las siguientes celdas para probar su solución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEd0FhS4_o7K"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "model = load_model()\n",
        "y_pred = model.predict(features_test)\n",
        "print(f1_score(labels_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU9Zr2MLAt4U"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "En este caso debería obtener la métrica sobre el mejor modelo en el conjunto de evaluación.\n",
        "\n",
        "```python\n",
        "❱ print(f1_score(labels_test, y_pred))\n",
        "0.9871794871794872\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNpDr2nz_o7L"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "* Recuerde versionar el modelo antes de cargarlo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EJomlPq_o7L"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "* Puede ordenar las ejecuciones de `mlflow` de acuerdo a `score` y con esto seleccionar el mejor modelo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oev60MFfBD8E"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 3</b></font>\n",
        "</summary>\n",
        "\n",
        "* Puede cargar un modelo versionado con la función `mlflow.pyfunc.load_model`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcjdqBWg_o7L"
      },
      "source": [
        "#### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npeYuO35_o7N"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 5_1\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08eh8HTknUDd"
      },
      "source": [
        "# **Evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb0DP1bWwRll"
      },
      "outputs": [],
      "source": [
        "grader.submit_task(globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwLqFy8Zzet_"
      },
      "source": [
        "# **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/).\n",
        "\n",
        "* **Asistentes docentes:** [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "  - [Rosa Alejandra Superlano Esquibel](https://www.linkedin.com/in/alejandra-superlano-02b74313a/).\n",
        "  - [Mario Andrés Rodríguez Triana](mailto:mrodrigueztr@unal.edu.co).\n",
        "\n",
        "* **Coordinador de virtualización:** [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}