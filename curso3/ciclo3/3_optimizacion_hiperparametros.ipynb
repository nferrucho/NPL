{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso3/ciclo3/3_optimizacion_hiperparametros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da7a81a",
      "metadata": {
        "id": "6da7a81a"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=14reVO1X6LsjqJ3cFgoeHxxddZVGfZn3t\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee3967b1",
      "metadata": {
        "id": "ee3967b1"
      },
      "source": [
        "# Optimización de Hiperparámetros\n",
        "---\n",
        "\n",
        "En este notebook veremos la necesidad de la optimización de hiperparámetros y algunas herramientas populares en _Python_.\n",
        "\n",
        "Comenzamos instalando e importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a3dca2",
      "metadata": {
        "id": "92a3dca2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b60c76af",
      "metadata": {
        "id": "b60c76af"
      },
      "source": [
        "## **1. Motivación**\n",
        "---\n",
        "\n",
        "La selección de hiperparámetros es crucial en el modelamiento de aprendizaje automático por varias razones:\n",
        "\n",
        "- **Mejora la calidad del modelo**: La correcta selección de hiperparámetros puede mejorar significativamente la precisión, el rendimiento y la robustez del modelo.\n",
        "- **Evita el sobreajuste**: El sobreajuste se produce cuando un modelo se ajusta demasiado a los datos de entrenamiento, dando como resultado un rendimiento pobre en datos desconocidos. La selección adecuada de hiperparámetros puede ayudar a evitar el sobreajuste y mejorar la generalización del modelo.\n",
        "- **Mejora la eficiencia**: La búsqueda de hiperparámetros puede ser costosa en términos de tiempo de computación y recursos. Sin embargo, es importante hacerla para obtener el mejor modelo posible.\n",
        "\n",
        "Es importante recordar las diferencias entre parámetros e hiperparámetros de un modelo:\n",
        "\n",
        "| Parámetros | Hiperparámetros |\n",
        "| --- | --- |\n",
        "| Requeridos para hacer predicciones | Requeridos para estimar los parámetros |\n",
        "| Se estiman con algoritmos de optimización | Se estiman con algoritmos de búsqueda |\n",
        "| Se encuentran en el entrenamiento | Deben ser ajustados manualmente |\n",
        "| Los parámetros encontrados determinan las predicciones | Los hiperparámetros determinan el entrenamiento |\n",
        "\n",
        "En _Python_ existen distintas librerías para optimización de hiperparámetros. Vamos a ver un ejemplo sobre un conjunto de datos sintético para regresión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a2bab6",
      "metadata": {
        "id": "35a2bab6"
      },
      "outputs": [],
      "source": [
        "x = np.random.uniform(\n",
        "    low=-1,\n",
        "    high=1,\n",
        "    size=(2000, 1),\n",
        "    )\n",
        "y = np.cos(5 * x) * x ** 2 + np.random.normal(\n",
        "    loc=0,\n",
        "    scale=0.05,\n",
        "    size=(2000, 1),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6427adf",
      "metadata": {
        "id": "e6427adf"
      },
      "source": [
        "Visualizamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd40791",
      "metadata": {
        "id": "9dd40791"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x, y, alpha=0.1)\n",
        "ax.set_xlabel(\"$x$\")\n",
        "ax.set_ylabel(\"$y$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3ad038",
      "metadata": {
        "id": "fc3ad038"
      },
      "source": [
        "Dividimos el conjunto de datos en entrenamiento y prueba para evaluar la generalización del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4039f3a3",
      "metadata": {
        "id": "4039f3a3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713594f1",
      "metadata": {
        "id": "713594f1"
      },
      "source": [
        "En este caso vamos a entrenar un modelo de máquina de soporte vectorial para regresión y a evaluar el desempeño por medio del $r^2$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff20b27e",
      "metadata": {
        "id": "ff20b27e"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a7d6ae",
      "metadata": {
        "id": "05a7d6ae"
      },
      "source": [
        "Veamos el desempeño del modelo de SVR con un kernel lineal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace88760",
      "metadata": {
        "id": "ace88760"
      },
      "outputs": [],
      "source": [
        "model = SVR(kernel=\"linear\").fit(x_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7606fa68",
      "metadata": {
        "id": "7606fa68"
      },
      "source": [
        "Veamos el desempeño del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ede6c2",
      "metadata": {
        "id": "85ede6c2"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print(r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c98a090",
      "metadata": {
        "id": "5c98a090"
      },
      "source": [
        "Veamos este resultado de forma gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e607409",
      "metadata": {
        "id": "5e607409"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_range = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(x_range)\n",
        "ax.scatter(x, y, alpha=0.1, label=\"data\")\n",
        "ax.plot(x_range, y_pred, label=\"predictions\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"$x$\")\n",
        "ax.set_ylabel(\"$y$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37249f58",
      "metadata": {
        "id": "37249f58"
      },
      "source": [
        "Como podemos ver, obtenemos un modelo que no se ajusta muy bien a los datos. Veamos cómo optimizar los hiperparámetros con distintas estrategias y librerías:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48b26a77",
      "metadata": {
        "id": "48b26a77"
      },
      "source": [
        "## **2. Grid Search**\n",
        "---\n",
        "\n",
        "Grid search es un enfoque de búsqueda exhaustiva de hiperparámetros en el aprendizaje automático. El objetivo de Grid Search es encontrar la combinación óptima de hiperparámetros para un modelo dado. En esta búsqueda se especifican los valores posibles para cada hiperparámetro y luego se prueban todas las combinaciones posibles de esos valores. Por ejemplo, si se tienen dos hiperparámetros, cada uno con tres posibles valores, entonces Grid Search probará 9 combinaciones diferentes en total.\n",
        "\n",
        "Para cada combinación de hiperparámetros se entrena un modelo con esos hiperparámetros y se evalúa su rendimiento en un conjunto de datos de prueba. Finalmente, se selecciona la combinación de hiperparámetros que produce el mejor rendimiento en el conjunto de prueba.\n",
        "\n",
        "Grid search es una forma sencilla y efectiva de seleccionar hiperparámetros, pero puede ser costosa en términos de tiempo de computación y recursos, especialmente cuando se tienen muchos hiperparámetros y muchos posibles valores para cada uno de ellos. Por lo tanto, a veces es recomendable usar métodos más sofisticados de búsqueda de hiperparámetros, como la búsqueda aleatoria o el optimizador bayesiano.\n",
        "\n",
        "Veamos cómo usar Grid Search en `sklearn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee318ab",
      "metadata": {
        "id": "0ee318ab"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f9ac84",
      "metadata": {
        "id": "a3f9ac84"
      },
      "source": [
        "También importamos la siguiente función para seleccionar la métrica de desempeño:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e0aa106",
      "metadata": {
        "id": "6e0aa106"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba866b9f",
      "metadata": {
        "id": "ba866b9f"
      },
      "source": [
        "Definimos las combinaciones de hiperparámetros que vamos a explorar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874ba09c",
      "metadata": {
        "id": "874ba09c"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"kernel\": [\"rbf\", \"poly\", \"linear\"],\n",
        "    \"C\": [1.0, 0.1, 0.01, 0.01],\n",
        "    \"gamma\": [1.0, 0.1, 0.01, 0.01]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d94f63",
      "metadata": {
        "id": "12d94f63"
      },
      "source": [
        "Realizamos la exploración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70255b08",
      "metadata": {
        "id": "70255b08"
      },
      "outputs": [],
      "source": [
        "gsearch = GridSearchCV(\n",
        "        estimator=SVR(),\n",
        "        param_grid=param_grid,\n",
        "        scoring=make_scorer(r2_score, greater_is_better=True)\n",
        "        ).fit(x_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0350fc32",
      "metadata": {
        "id": "0350fc32"
      },
      "source": [
        "Veamos los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff7d342",
      "metadata": {
        "id": "4ff7d342"
      },
      "outputs": [],
      "source": [
        "display(pd.DataFrame(gsearch.cv_results_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6d11791",
      "metadata": {
        "id": "d6d11791"
      },
      "source": [
        "Obtenemos el mejor modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231c6c33",
      "metadata": {
        "id": "231c6c33"
      },
      "outputs": [],
      "source": [
        "model = gsearch.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7341509f",
      "metadata": {
        "id": "7341509f"
      },
      "source": [
        "Evaluamos su desempeño en el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0633837",
      "metadata": {
        "id": "f0633837"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print(r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb784bfc",
      "metadata": {
        "id": "bb784bfc"
      },
      "source": [
        "Veamos este resultado de forma gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f21f07f",
      "metadata": {
        "id": "6f21f07f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_range = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(x_range)\n",
        "ax.scatter(x, y, alpha=0.1, label=\"data\")\n",
        "ax.plot(x_range, y_pred, label=\"predictions\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"$x$\")\n",
        "ax.set_ylabel(\"$y$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581318fa",
      "metadata": {
        "id": "581318fa"
      },
      "source": [
        "Como podemos ver, el resultado presenta un mejor ajuste sobre los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "298f3690",
      "metadata": {
        "id": "298f3690"
      },
      "source": [
        "## **3. Random Search**\n",
        "---\n",
        "\n",
        "Random Search es un enfoque para seleccionar hiperparámetros en el aprendizaje automático. En lugar de probar todas las combinaciones posibles de hiperparámetros, como en Grid Search, Random Search selecciona aleatoriamente combinaciones de hiperparámetros para entrenar y evaluar modelos.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1m8uUfuYDG76uLHPTRryQP3w9-9stKa5z\" width=\"80%\">\n",
        "\n",
        "En Random Search se especifican los valores posibles para cada hiperparámetro y luego se generan combinaciones aleatorias de esos valores. Por ejemplo, si se tienen dos hiperparámetros, cada uno con tres posibles valores, entonces Random Search generará combinaciones aleatorias de esos valores y entrenará y evaluará un modelo con cada combinación.\n",
        "\n",
        "Después de un número determinado de iteraciones, Random Search seleccionará la combinación de hiperparámetros que produjo el mejor rendimiento en el conjunto de prueba.\n",
        "\n",
        "Random Search es un enfoque más eficiente que Grid Search en términos de tiempo de computación y recursos, especialmente cuando se tienen muchos hiperparámetros y muchos posibles valores para cada uno de ellos. Además, Random Search a menudo es más efectivo que Grid Search en encontrar la combinación óptima de hiperparámetros. Sin embargo, la eficacia de Random Search depende del número de iteraciones y la distribución de valores posibles para cada hiperparámetro.\n",
        "\n",
        "Veamos cómo podemos usarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e92ff79",
      "metadata": {
        "id": "4e92ff79"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1171bfe",
      "metadata": {
        "id": "a1171bfe"
      },
      "source": [
        "Su uso es muy parecido al de Grid Search, no obstante, podemos definir distribuciones sobre hiperparámetros en lugar de valores fijos, por ejemplo usando una distribución:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3abbe35",
      "metadata": {
        "id": "c3abbe35"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import halfnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa29e57c",
      "metadata": {
        "id": "aa29e57c"
      },
      "source": [
        "Definimos las distribuciones de hiperparámetros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34119b1",
      "metadata": {
        "id": "e34119b1"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"kernel\": [\"rbf\", \"poly\", \"linear\"],\n",
        "    \"C\": halfnorm(loc=0, scale=0.5),\n",
        "    \"gamma\": halfnorm(loc=1, scale=0.5)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9304afa4",
      "metadata": {
        "id": "9304afa4"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bbf9267",
      "metadata": {
        "id": "1bbf9267"
      },
      "outputs": [],
      "source": [
        "rsearch = RandomizedSearchCV(\n",
        "        estimator=SVR(),\n",
        "        param_distributions=param_grid,\n",
        "        n_iter=30,\n",
        "        scoring=make_scorer(r2_score, greater_is_better=True)\n",
        "        ).fit(x_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4da666",
      "metadata": {
        "id": "0a4da666"
      },
      "source": [
        "Veamos los resultados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ccbd41",
      "metadata": {
        "id": "93ccbd41"
      },
      "outputs": [],
      "source": [
        "display(pd.DataFrame(rsearch.cv_results_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6efda08",
      "metadata": {
        "id": "b6efda08"
      },
      "source": [
        "Obtenemos el mejor modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7245d07c",
      "metadata": {
        "id": "7245d07c"
      },
      "outputs": [],
      "source": [
        "model = rsearch.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94701199",
      "metadata": {
        "id": "94701199"
      },
      "source": [
        "Evaluamos su desempeño en el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97112b5d",
      "metadata": {
        "id": "97112b5d"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print(r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40173781",
      "metadata": {
        "id": "40173781"
      },
      "source": [
        "Veamos este resultado de forma gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a13306",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "78a13306"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_range = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(x_range)\n",
        "ax.scatter(x, y, alpha=0.1, label=\"data\")\n",
        "ax.plot(x_range, y_pred, label=\"predictions\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"$x$\")\n",
        "ax.set_ylabel(\"$y$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6a7e58",
      "metadata": {
        "id": "fa6a7e58"
      },
      "source": [
        "## **4. Optuna**\n",
        "---\n",
        "\n",
        "`optuna` es una biblioteca de software de código abierto para la optimización de hiperparámetros en el aprendizaje automático. Optuna ofrece una interfaz fácil de usar para realizar búsquedas de hiperparámetros de manera efectiva y eficiente.\n",
        "\n",
        "`optuna` utiliza un enfoque de optimización bayesiana para seleccionar hiperparámetros. En lugar de probar todas las combinaciones posibles de hiperparámetros o seleccionarlas al azar, como en Grid Search o Random Search respectivamente, `optuna` utiliza una distribución probabilística para representar la incertidumbre sobre la optimización de hiperparámetros.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lW-f98Od3zYxbfC1VQxarzcYxl6Lf-CF\" width=\"80%\">\n",
        "\n",
        "A medida que se entrenan y evalúan modelos con diferentes combinaciones de hiperparámetros, Optuna actualiza su distribución probabilística y se concentra en las áreas más prometedoras del espacio de búsqueda de hiperparámetros. Esto permite a `optuna` explorar de manera eficiente el espacio de búsqueda y encontrar la combinación óptima de hiperparámetros con menos iteraciones que Grid Search o Random Search.\n",
        "\n",
        "Además de la optimización bayesiana, `optuna` también ofrece otras funciones útiles, como la gestión de experimentos, la integración con distintos marcos de aprendizaje automático y la visualización de resultados. Optuna también puede ser usado de forma distribuida con distintos `workers` (nodos de procesamiento) y con un almacenamiento compartido, lo que permite su uso en grandes cantidades de datos:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=13sF66PhaS5VwsJxC4NnpUcbs6gWjGjW0\" width=\"80%\">\n",
        "\n",
        "Veamos cómo instalar `optuna`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab070f4",
      "metadata": {
        "id": "8ab070f4"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c5763fd",
      "metadata": {
        "id": "6c5763fd"
      },
      "source": [
        "El uso de `optuna` es sencillo, debemos definir una función objetivo a optimizar, en este caso será el $r^2$ sobre el conjunto de test. La función debe recibir como parámetro `trial`, el cual es un objeto de `optuna` que nos permitirá extraer hiperparámetros de forma controlada y con distintos tipos de distribuciones.\n",
        "\n",
        "En este ejemplo, `suggest_float` nos permite extraer números reales en un rango dado, mientras que el parámetro `log` permite controlar si se realiza en escala logarítmica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ff91d5",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "75ff91d5"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.01, 10, log=True)\n",
        "    c = trial.suggest_float(\"C\", 0.01, 10, log=True)\n",
        "    kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"poly\", \"linear\"])\n",
        "    model = SVR(C=c, kernel=kernel, gamma=gamma).fit(x_train, y_train.ravel())\n",
        "    y_pred = model.predict(x_test)\n",
        "    score = r2_score(y_test, y_pred)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa7eeb2f",
      "metadata": {
        "id": "aa7eeb2f"
      },
      "source": [
        "Ahora importamos `optuna`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9da40c",
      "metadata": {
        "id": "6a9da40c"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c36abfa",
      "metadata": {
        "id": "5c36abfa"
      },
      "source": [
        "Para usar optuna debemos crear un estudio, para ello especificamos:\n",
        "\n",
        "- `direction`: se específica si maximizamos o minimizamos.\n",
        "- `storage`: tipo de almacenamiento para los resultados.\n",
        "- `study_name`: nombre del estudio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2366bb4a",
      "metadata": {
        "id": "2366bb4a"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    storage=\"sqlite:///hp.db\",\n",
        "    study_name=\"svm\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e7a64e",
      "metadata": {
        "id": "31e7a64e"
      },
      "source": [
        "Ejecutamos la exploración, para ello especificamos lo siguiente:\n",
        "\n",
        "- `func`: función a optimizar.\n",
        "- `n_trials`: número de modelos a entrenar.\n",
        "- `n_jobs`: número de nodos de procesamiento (-1 indica usar el máximo posible)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690ab6c9",
      "metadata": {
        "id": "690ab6c9"
      },
      "outputs": [],
      "source": [
        "study.optimize(func=objective, n_trials=100, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e283115",
      "metadata": {
        "id": "3e283115"
      },
      "source": [
        "Extraemos los mejores parámetros y el $r^2$ obtenido:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2deac639",
      "metadata": {
        "id": "2deac639"
      },
      "outputs": [],
      "source": [
        "params = study.best_params\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b183bf2",
      "metadata": {
        "id": "6b183bf2"
      },
      "outputs": [],
      "source": [
        "score = study.best_value\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b2e518",
      "metadata": {
        "id": "81b2e518"
      },
      "source": [
        "Podemos entrenar un modelo con estos parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce1a7856",
      "metadata": {
        "id": "ce1a7856"
      },
      "outputs": [],
      "source": [
        "model = SVR(**params).fit(x_train, y_train.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072ac8a3",
      "metadata": {
        "id": "072ac8a3"
      },
      "source": [
        "Evaluamos su desempeño en el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b81096",
      "metadata": {
        "id": "f1b81096"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print(r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77cd893",
      "metadata": {
        "id": "c77cd893"
      },
      "source": [
        "Veamos este resultado de forma gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee3d35d0",
      "metadata": {
        "id": "ee3d35d0"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_range = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(x_range)\n",
        "ax.scatter(x, y, alpha=0.1, label=\"data\")\n",
        "ax.plot(x_range, y_pred, label=\"predictions\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"$x$\")\n",
        "ax.set_ylabel(\"$y$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2630f3b8",
      "metadata": {
        "id": "2630f3b8"
      },
      "source": [
        "Adicionalmente, `optuna` dispone de un tablero para visualizar la exploración de hiperparámetros. Veamos cómo instalarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cbb610f",
      "metadata": {
        "id": "0cbb610f"
      },
      "outputs": [],
      "source": [
        "!pip install optuna-dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b7cd27c",
      "metadata": {
        "id": "2b7cd27c"
      },
      "source": [
        "Su uso es sencillo. Básicamente debemos lanzar el dashboard con la base de datos que fue creada durante la exploración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bfaa798",
      "metadata": {
        "id": "6bfaa798"
      },
      "outputs": [],
      "source": [
        "command = \"\"\"\n",
        "optuna-dashboard \\\n",
        "        --port 5000 \\\n",
        "        sqlite:///hp.db &\n",
        "\"\"\"\n",
        "get_ipython().system_raw(command)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd2dd4b",
      "metadata": {
        "id": "efd2dd4b"
      },
      "source": [
        "Al igual que con `mlflow`, debemos usar `ngrok` para poder acceder al tablero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b120be70",
      "metadata": {
        "id": "b120be70"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b9a911",
      "metadata": {
        "id": "f1b9a911"
      },
      "source": [
        "Ahora debe agregar su token de `ngrok`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c64f381",
      "metadata": {
        "id": "4c64f381"
      },
      "outputs": [],
      "source": [
        "token = \"\" # Agregue el token dentro de las comillas\n",
        "os.environ[\"NGROK_TOKEN\"] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db572b4",
      "metadata": {
        "id": "2db572b4"
      },
      "source": [
        "Nos autenticamos en ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986d4ae1",
      "metadata": {
        "id": "986d4ae1"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53eac698",
      "metadata": {
        "id": "53eac698"
      },
      "source": [
        "Ahora, lanzamos la conexión con ngrok:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917f7b38",
      "metadata": {
        "id": "917f7b38"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.connect(5000, \"http\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "524cb6ba",
      "metadata": {
        "id": "524cb6ba"
      },
      "source": [
        "Este tablero le dará acceso a distintas visualizaciones que permitirán observar cómo es la optimización, importancia y dependencias entre hiperparámetros."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d8cded",
      "metadata": {
        "id": "11d8cded"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [Hyperparameter Tuning in Python: a Complete Guide](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide)\n",
        "- [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "- [Random Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "- [Optuna](https://optuna.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6daaddd",
      "metadata": {
        "id": "c6daaddd"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "**Profesor**\n",
        "\n",
        "- [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "\n",
        "**Asistente docente**:\n",
        "\n",
        "- [Juan S. Lara MSc](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/)\n",
        "\n",
        "**Diseño de imágenes:**\n",
        "- [Brian Chaparro Cetina](mailto:bchaparro@unal.edu.co).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}