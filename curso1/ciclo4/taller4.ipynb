{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo4/taller4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3052a8d6",
      "metadata": {
        "id": "3052a8d6"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Q6vQcIWFPY27isBepABpJ7nroUNKox_Z\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc0899eb",
      "metadata": {
        "id": "cc0899eb"
      },
      "source": [
        "# **Taller 4**\n",
        "---\n",
        "\n",
        "En este taller se evaluarán las habilidades adquiridas en aprendizaje supervisado a partir del conjunto de datos [SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
        "\n",
        "El conjunto de datos SMS Spam Collection de UCI es un conjunto de datos de mensajes de texto que se utiliza para entrenar y evaluar modelos de clasificación de spam. El conjunto de datos consta de 5572 mensajes de texto en inglés, clasificados como spam (marcado con la etiqueta \"spam\") o no spam (marcado con la etiqueta \"ham\").\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1M9rsDDftSm947FhU2aEZmC5BX8lmVYhQ\" width=\"80%\"></center>\n",
        "\n",
        "Los mensajes de texto incluidos en el conjunto de datos son mensajes de texto cortos, típicamente no más de 160 caracteres. Los mensajes de texto son de diferentes fuentes, como correos electrónicos, mensajes de texto de teléfonos móviles y mensajes de texto de redes sociales.\n",
        "\n",
        "El conjunto de datos es anotado manualmente y se considera un conjunto de datos desbalanceado, ya que aproximadamente el 87% de los mensajes son no spam y el resto son spam. El conjunto de datos es muy utilizado para entrenar y evaluar modelos de clasificación de spam.\n",
        "\n",
        "El conjunto de datos se proporciona en un archivo de texto plano con dos columnas: una con el mensaje de texto y otra con la etiqueta \"spam\" o \"ham\". Además, se proporciona un archivo de metadatos con información sobre el conjunto de datos y su historial.\n",
        "\n",
        "Comenzaremos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e300c3c5",
      "metadata": {
        "id": "e300c3c5"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba95f27a",
      "metadata": {
        "id": "ba95f27a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6661f85a",
      "metadata": {
        "id": "6661f85a"
      },
      "source": [
        "Ahora cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d98d2697",
      "metadata": {
        "id": "d98d2697"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "data = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u4/spam.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0903a15",
      "metadata": {
        "id": "c0903a15"
      },
      "source": [
        "Como podemos ver, el conjunto tiene columnas:\n",
        "\n",
        "- `text`: texto del SMS.\n",
        "- `label`: tipo de SMS (`spam` es texto no deseado y `ham` es texto válido)\n",
        "\n",
        "Vamos a preprocesar el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918ebbf2",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "918ebbf2"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "def preprocess(text):\n",
        "    doc = nlp(text) # creamos un documento de spacy\n",
        "    no_stops = \" \".join(\n",
        "        token.text\n",
        "        for token in filter(\n",
        "            lambda token: not token.is_stop and len(token) > 3 and len(token) < 24,\n",
        "            doc,\n",
        "            )\n",
        "        ) # eliminamos stopwords y palabras por longitud\n",
        "    norm_text = unidecode(no_stops.lower()) # normalizamos el texto\n",
        "    no_chars = re.sub(r\"[^a-z ]\", \" \", norm_text) # eliminamos caracteres especiales\n",
        "    no_spaces = re.sub(r\"\\s+\", \" \", no_chars) # eliminamos espacios duplicados\n",
        "    return no_spaces.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edd4aa0",
      "metadata": {
        "id": "7edd4aa0"
      },
      "source": [
        "Aplicamos la función de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d702333b",
      "metadata": {
        "id": "d702333b"
      },
      "outputs": [],
      "source": [
        "data[\"corpus\"] = data.text.apply(preprocess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e255d09",
      "metadata": {
        "id": "2e255d09"
      },
      "source": [
        "Inspeccionemos el tamaño de este conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9159a960",
      "metadata": {
        "id": "9159a960"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74726ed4",
      "metadata": {
        "id": "74726ed4"
      },
      "source": [
        "También podemos ver la distribución de etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2b434b6",
      "metadata": {
        "id": "e2b434b6"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "fig, ax = plt.subplots()\n",
        "labels, counts = np.unique(data.label, return_counts=True)\n",
        "ax.bar(labels, counts)\n",
        "ax.set_xlabel(\"Categoría\")\n",
        "ax.set_ylabel(\"Conteo\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc1e121",
      "metadata": {
        "id": "2dc1e121"
      },
      "source": [
        "Como podemos ver, se trata de un conjunto desbalanceado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74bc87c6",
      "metadata": {
        "id": "74bc87c6"
      },
      "source": [
        "## **1. Extracción de Características**\n",
        "---\n",
        "\n",
        "En este punto deberá codificar de forma numérica el corpus. Para ello, deberá entrenar un vectorizador TF-IDF con sublinear scaling, además debe utilizar únicamente los 1000 términos más frecuentes.\n",
        "\n",
        "Para esto, deberá implementar la función `vectorizer`, la cual recibirá el corpus preprocesado y deberá retornar un arreglo de `numpy` con la representación y el vectorizador.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `corpus`: `pd.Series` con los textos del conjunto de datos.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `features`: arreglo de numpy con la representación de tipo TF-IDF.\n",
        "- `vect`: `TfidfVectorizer` entrenado con las especificaciones dadas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01276ca8",
      "metadata": {
        "id": "01276ca8"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que _sublinear scaling_ se puede controlar con el parámetro `sublinear_tf` del vectorizador.\n",
        "- Recuerde convertir la representación en un arreglo de `numpy`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5228e4ec",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5228e4ec"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA vectorizer:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorizer(corpus):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    vect = ...\n",
        "    features = ...\n",
        "    return features, vect\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3401dea0",
      "metadata": {
        "id": "3401dea0"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3144df63",
      "metadata": {
        "id": "3144df63"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el tamaño de la representación:\n",
        "\n",
        "```python\n",
        "❱ display(features.shape)\n",
        "(5572, 1000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86de13fe",
      "metadata": {
        "id": "86de13fe"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(vect.get_feature_names_out()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e307e9",
      "metadata": {
        "id": "07e307e9"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las primeras 5 palabras del vocabulario:\n",
        "\n",
        "```python\n",
        "❱ display(vect.get_feature_names_out()[:5])\n",
        "array(['abiola', 'able', 'accept', 'access', 'account'], dtype=object)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af424bc2",
      "metadata": {
        "id": "af424bc2"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(features.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa3d4505",
      "metadata": {
        "id": "aa3d4505"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener la suma de toda la matriz:\n",
        "\n",
        "```python\n",
        "❱ display(features.sum())\n",
        "9861.088671252523\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fcfb39",
      "metadata": {
        "id": "84fcfb39"
      },
      "source": [
        "## **2. Codificación de Etiquetas**\n",
        "---\n",
        "\n",
        "Para el entrenamiento de un modelo debemos codificar las etiquetas de forma numérica. En este caso se debe implementar una solución un poco más sistemática, haciendo uso de un codificador de `sklearn`.\n",
        "\n",
        "En este punto debe implementar la función `label_encode`, la cual toma como entrada la lista de etiquetas del conjunto de datos y deberá retornar una codificación numérica de las mismas y un codificador de tipo `LabelEncoder`.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `labels`: `pd.Series` con las etiquetas en formato string.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `encoded_labels`: etiquetas codificadas de forma numérica.\n",
        "- `encoder`: `LabelEncoder` entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cea9e05",
      "metadata": {
        "id": "2cea9e05"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde invocar el método `.fit` del codificador antes de retornarlo.\n",
        "- Evite usar el método `.fit_transform` para poder guardar el codificador.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a017fc9c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "a017fc9c"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA label_encode:\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def label_encode(labels):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    encoder = ...\n",
        "    encoded_labels = ...\n",
        "    return encoded_labels, encoder\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4da65e",
      "metadata": {
        "id": "0b4da65e"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "display(encoded_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c76fabf6",
      "metadata": {
        "id": "c76fabf6"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el tamaño de las etiquetas:\n",
        "\n",
        "```python\n",
        "❱ display(encoded_labels.shape)\n",
        "(5572,)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c09193f3",
      "metadata": {
        "id": "c09193f3"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "display(encoded_labels.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab9c96a",
      "metadata": {
        "id": "7ab9c96a"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este segundo ejemplo debe obtener el promedio de las etiquetas:\n",
        "\n",
        "```python\n",
        "❱ display(encoded_labels.mean())\n",
        "0.13406317300789664\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab1d727",
      "metadata": {
        "id": "6ab1d727"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "display(encoder.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55c4d1bc",
      "metadata": {
        "id": "55c4d1bc"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso debe obtener un arreglo con las posibles categorías y la posición a las que son asignadas:\n",
        "\n",
        "```python\n",
        "❱ display(encoder.classes_)\n",
        "array(['ham', 'spam'], dtype=object)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e1dbe5",
      "metadata": {
        "id": "a2e1dbe5"
      },
      "source": [
        "## **3. Validación Cruzada**\n",
        "---\n",
        "\n",
        "En este punto deberá particionar el conjunto de datos en una muestra de entrenamiento y otra para evaluación de forma estratificada.\n",
        "\n",
        "Para ello, debe implementar la función `split_data`, que tiene como entrada las características, las etiquetas, la proporción de datos de prueba y una semilla de números aleatorios para retornar los datos particionados:\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features`: arreglo de `numpy` con la representación de los textos.\n",
        "- `labels`: arreglo de `numpy` con las etiquetas codificadas.\n",
        "- `test_size`: proporción de datos para evaluación.\n",
        "- `seed`: semilla de números aleatorios:\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `features_train`: características de entrenamineto.\n",
        "- `features_test`: características de prueba.\n",
        "- `labels_train`: etiquetas de entrenamiento.\n",
        "- `labels_test`: etiquetas de evaluación."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d353d37",
      "metadata": {
        "id": "1d353d37"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde usar el parámetro `stratify` para realizar la estratificación.\n",
        "- `sklearn` maneja las semillas de números aleatorios con el parámetro `random_state`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55027394",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "55027394"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA split_data:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(features, labels, test_size, seed):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    features_train = ...\n",
        "    features_test = ...\n",
        "    labels_train = ...\n",
        "    labels_test = ...\n",
        "    return features_train, features_test, labels_train, labels_test\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b49f592",
      "metadata": {
        "id": "9b49f592"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.3, seed=42\n",
        "        )\n",
        "display(features_train.shape)\n",
        "display(features_test.shape)\n",
        "display(labels_train.shape)\n",
        "display(labels_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe98e8c9",
      "metadata": {
        "id": "fe98e8c9"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el tamaño de cada arreglo:\n",
        "\n",
        "```python\n",
        "❱ display(features_train.shape)\n",
        "(3900, 1000)\n",
        "\n",
        "❱ display(features_test.shape)\n",
        "(1672, 1000)\n",
        "\n",
        "❱ display(labels_train.shape)\n",
        "(3900,)\n",
        "\n",
        "❱ display(labels_test.shape)\n",
        "(1672,)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702a323b",
      "metadata": {
        "id": "702a323b"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.3, seed=42\n",
        "        )\n",
        "display(labels_train.mean())\n",
        "display(labels_test.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5470ee",
      "metadata": {
        "id": "da5470ee"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este segundo ejemplo debe obtener el promedio de las etiquetas en cada partición:\n",
        "\n",
        "```python\n",
        "❱ display(labels_train.mean())\n",
        "0.1341025641025641\n",
        "\n",
        "❱ display(labels_test.mean())\n",
        "0.1339712918660287\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5f35272",
      "metadata": {
        "id": "f5f35272"
      },
      "source": [
        "## **4. Modelo de Bosques Aleatorios**\n",
        "---\n",
        "\n",
        "En este punto deberá entrenar un modelo de bosques aleatorios sobre los datos de entrenamiento.\n",
        "\n",
        "Para esto, debe implementar la función `random_forest`, la cual toma como entrada los datos de entrenamiento, la profundidad máxima de los árboles y el número de estimadores, para luego retornar un modelo entrenado.\n",
        "\n",
        "**Parámetros**:\n",
        "\n",
        "- `features_train`: características de entrenamiento.\n",
        "- `labels_train`: etiquetas de entrenamiento.\n",
        "- `max_depth`: profundidad máxima de los árboles.\n",
        "- `n_estimators`: número de árboles en el bosque.\n",
        "- `seed`: semilla de números aleatorios.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `model`: modelo de bosques aleatorios entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd7c587",
      "metadata": {
        "id": "edd7c587"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde utilizar el método `fit` del modelo antes de retornarlo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba213c8",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "eba213c8"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA random_forest:\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def random_forest(features_train, labels_train, max_depth, n_estimators, seed):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    model = ...\n",
        "    return model\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d48c6920",
      "metadata": {
        "id": "d48c6920"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.3, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 5, 50, 42)\n",
        "display(model.max_depth)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55b8bad6",
      "metadata": {
        "id": "55b8bad6"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener la profundidad máxima del modelo:\n",
        "\n",
        "```python\n",
        "❱ display(model.max_depth)\n",
        "5\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b679b1",
      "metadata": {
        "id": "77b679b1"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.3, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 5, 50, 42)\n",
        "display(model.n_estimators)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf10d54a",
      "metadata": {
        "id": "bf10d54a"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este segundo ejemplo debe obtener el número de estimadores en el modelo:\n",
        "\n",
        "```python\n",
        "❱ display(model.n_estimators)\n",
        "50\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe5430c",
      "metadata": {
        "id": "2fe5430c"
      },
      "source": [
        "## **5. Evaluación**\n",
        "---\n",
        "\n",
        "En este punto deberá evaluar métricas típicas de clasificación sobre el modelo. En especial se busca que calcule el accuracy, precision, recall y f1-score para cada clase.\n",
        "\n",
        "Para esto, debe implementar la función `evaluation`, la cual toma como entrada el modelo y los datos de prueba, y debe retornar un reporte de clasificación de `sklearn`:\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `model`: modelo entrenado.\n",
        "- `features_test`: características de evaluación.\n",
        "- `labels_test`: etiquetas de evaluación.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `report`: reporte de clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a759d39d",
      "metadata": {
        "id": "a759d39d"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que la función `classification_report` retorna un string con el resultado. No se preocupe si no puede seleccionar una métrica en específico.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a10e5c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "21a10e5c"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA evaluation:\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluation(model, features_test, labels_test):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    report = ...\n",
        "    return report\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2683a3",
      "metadata": {
        "id": "df2683a3"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.3, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 5, 50, 42)\n",
        "report = evaluation(model, features_test, labels_test)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf8cbe4",
      "metadata": {
        "id": "6bf8cbe4"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener una tabla con las métricas del modelo:\n",
        "\n",
        "```python\n",
        "❱ print(report)\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      1.00      0.94      1448\n",
        "           1       1.00      0.14      0.24       224\n",
        "\n",
        "    accuracy                           0.88      1672\n",
        "   macro avg       0.94      0.57      0.59      1672\n",
        "weighted avg       0.90      0.88      0.84      1672\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f72f2002",
      "metadata": {
        "id": "f72f2002"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.4, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 7, 100, 42)\n",
        "report = evaluation(model, features_test, labels_test)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2d51e98",
      "metadata": {
        "id": "e2d51e98"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este segundo ejemplo debe obtener una tabla con las métricas del modelo:\n",
        "\n",
        "```python\n",
        "❱ print(report)\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      1.00      0.95      1930\n",
        "           1       1.00      0.27      0.42       299\n",
        "\n",
        "    accuracy                           0.90      2229\n",
        "   macro avg       0.95      0.63      0.68      2229\n",
        "weighted avg       0.91      0.90      0.88      2229\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b60b4c84",
      "metadata": {
        "id": "b60b4c84"
      },
      "source": [
        "## **6. Importancia de Términos**\n",
        "---\n",
        "\n",
        "Una de las características del modelo de bosques aleatorios es que este permite extraer importancias de cada una de las características.\n",
        "\n",
        "En este punto deberá extraer el top $N$ de términos más discriminantes de acuerdo al modelo de bosques aleatorios. Para esto, debe implementar la función `top_n_terms`, la cual recibe el vectorizador, el modelo entrenado y debe retornar una lista con los términos más relevantes.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `vect`: vectorizador TF-IDF.\n",
        "- `model`: modelo de bosques aleatorios entrenado.\n",
        "- `n`: número de palabras a extraer.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `top_words`: lista con las palabras más relevantes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc5e4261",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "bc5e4261"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede extraer el vocabulario del vectorizador con el método `get_feature_names_out`.\n",
        "- Puede extraer la importancia de cada término del vocabulario con el atributo `feature_importances_` del modelo de bosques aleatorios.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf57d10",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "1bf57d10"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA evaluation:\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def top_n_terms(vect, model, n):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    top_words = ...\n",
        "    return top_words\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38e2003",
      "metadata": {
        "id": "f38e2003"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.4, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 7, 100, 42)\n",
        "top_words = top_n_terms(vect, model, 5)\n",
        "display(top_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4ce465",
      "metadata": {
        "id": "7c4ce465"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este ejemplo debe obtener las siguientes 5 palabras:\n",
        "\n",
        "```python\n",
        "❱ display(top_words)\n",
        "['free', 'claim', 'stop', 'mobile', 'reply']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f62cee",
      "metadata": {
        "id": "53f62cee"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "encoded_labels, encoder = label_encode(data.label)\n",
        "features_train, features_test, labels_train, labels_test = split_data(\n",
        "        features, encoded_labels, test_size=0.4, seed=42\n",
        "        )\n",
        "model = random_forest(features_train, labels_train, 5, 100, 42)\n",
        "top_words = top_n_terms(vect, model, 20)\n",
        "display(top_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f5f677",
      "metadata": {
        "id": "35f5f677"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este ejemplo debe obtener las siguientes 20 palabras:\n",
        "\n",
        "```python\n",
        "❱ display(top_words)\n",
        "['free',\n",
        " 'claim',\n",
        " 'mobile',\n",
        " 'stop',\n",
        " 'nokia',\n",
        " 'urgent',\n",
        " 'prize',\n",
        " 'reply',\n",
        " 'service',\n",
        " 'text',\n",
        " 'pobox',\n",
        " 'mins',\n",
        " 'contact',\n",
        " 'www',\n",
        " 'tone',\n",
        " 'com',\n",
        " 'cash',\n",
        " 'landline',\n",
        " 'collection',\n",
        " 'guaranteed']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd0a0cd",
      "metadata": {
        "id": "7dd0a0cd"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "- _Fuente de los íconos_\n",
        "    - Flaticon. Spam free icon [PNG]. https://www.flaticon.com/free-icon/spam_1917781\n",
        "    - Flaticon. Email free icon [PNG]. https://www.flaticon.com/free-icon/email_2374449\n",
        "    - Flaticon. Email free icon [PNG]. https://www.flaticon.com/free-icon/email_896798\n",
        "    - Adobe Stock. Set Of Cute Robots [AI] - Adquirido bajo licencia. https://onx.la/61db4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea0937e",
      "metadata": {
        "id": "bea0937e"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Uniersidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}