{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo4/1_clasificacion_textos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ea67ec",
      "metadata": {
        "id": "62ea67ec"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Q6vQcIWFPY27isBepABpJ7nroUNKox_Z\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1142f27b",
      "metadata": {
        "id": "1142f27b"
      },
      "source": [
        "# **Clasificaci칩n de Textos**\n",
        "---\n",
        "\n",
        "En este notebook presentaremos los conceptos del an치lisis supervisado de textos junto con un ejemplo pr치ctico de clasificaci칩n.\n",
        "\n",
        "Comenzamos importando las librer칤as necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a28a476",
      "metadata": {
        "id": "4a28a476"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bce4692",
      "metadata": {
        "id": "5bce4692"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from unidecode import unidecode\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0489a53",
      "metadata": {
        "id": "e0489a53"
      },
      "source": [
        "## **1. An치lisis Supervisado**\n",
        "---\n",
        "\n",
        "El an치lisis supervisado de textos es una tarea donde se implementan modelos para replicar el comportamiento de un humano en una tarea espec칤fica. Actualmente esta tarea va muy de la mano con el aprendizaje supervisado en _machine learning_.\n",
        "\n",
        "Existen distintas tareas en procesamiento de lenguaje natural que se pueden abordar como un enfoque supervisado, entre ellas: clasificaci칩n de tokens, clasificaci칩n de textos, traductores, llenado de m치scaras, an치lisis de sentimientos, entre otras. En la siguiente figura podemos ver el proceso general del an치lisis supervisado de textos:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1P7wvAsHTCWAfZZeci9WKmtJWK-0u_-Ci\" width=\"100%\">\n",
        "\n",
        "Este proceso consiste en cuatro etapas:\n",
        "\n",
        "1. **Preprocesamiento**: consiste en la preparaci칩n de los textos para simplificar el entrenamiento de un modelo, generalmente esta etapa involucra tareas como normalizaci칩n, tokenizaci칩n, eliminaci칩n de stopwords, y otras tareas tal y como se present칩 en la unidad 2.\n",
        "2. **Extracci칩n de caracter칤sticas**: en este caso se extrae una representaci칩n num칠rica o caracter칤sticas con las que se pueda modelar el texto, tal y como se present칩 en la unidad 3.\n",
        "3. **Construcci칩n del modelo**: en esta etapa se entrena un modelo supervisado de _machine learning_ para cumplir una tarea en espec칤fico (por ejemplo, clasificaci칩n, regresi칩n, modelos secuencia a secuencia)\n",
        "4. **Evaluaci칩n del modelo**: en esta 칰ltima parte se eval칰a el desempe침o del modelo para evaluar la generalizaci칩n del mismo en la tarea en cuesti칩n.\n",
        "\n",
        "En NLP, el enfoque supervisado m치s com칰n es la tarea de clasificaci칩n, en especial, ya que una palabra puede ser vista como una categor칤a y un vocabulario como todas las categor칤as posibles. De esta forma funcionan modelos para reconocimiento de entidades nombradas, part-of-speech, llenado de m치scaras, autocompletadores, entre otras. Varias de estas aplicaciones las profundizaremos en los otros notebooks de esta unidad. Por el momento, nos enfocaremos en una aplicaci칩n relacionada con la clasificaci칩n de documentos: el an치lisis de sentimientos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d40818",
      "metadata": {
        "id": "e4d40818"
      },
      "source": [
        "## **2. An치lisis de Sentimientos**\n",
        "---\n",
        "\n",
        "El an치lisis de sentimientos, o miner칤a de opini칩n, es un campo del procesamiento de lenguaje natural que busca identificar y extraer opiniones de un texto dado. Su prop칩sito principal es identificar actitudes, sentimientos, evaluaciones y emociones de alg칰n orador o escritor por medio de an치lisis computacional. Por ejemplo, en la siguiente figura podemos ver un caso de an치lisis de sentimientos aplicado en la identificaci칩n del sentimiento en reviews sobre la pel칤cula [Fragmentado](https://es.wikipedia.org/wiki/Split_(pel%C3%ADcula)):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QCEsPK7ganFQ0SEt8Cn9B3gi2diQwx-F\" width=\"100%\">\n",
        "\n",
        "El an치lisis de sentimientos se utiliza en diversas aplicaciones:\n",
        "\n",
        "- **Comercio**: las empresas utilizan el an치lisis de sentimientos para desarrollar sus estrategias y entender la respuesta emocional de los usuarios ante determinado producto o marca. De igual forma, permite evaluar c칩mo la gente reacciona a determinada campa침a para comprender por qu칠 algunos productos no son comprados.\n",
        "- **Pol칤tica**: en este 치mbito se puede utilizar para dar un seguimiento a campa침as pol칤ticas, detectar las acciones y las propuestas del gobierno, evaluar la favorabilidad de un candidato en espec칤fico, predecir resultados electorales, entre otros.\n",
        "- **Acciones p칰blicas**: se usa para monitorear y analizar fen칩menos sociales, en especial, permite identificar eventos espec칤ficos que puedan estar relacionados con situaciones peligrosas o fuera de la ley.\n",
        "- **Salud**: puede usarse para estudiar e identificar trastornos cl칤nicos como depresi칩n, ansiedad, autolesiones, autismo, entre otras.\n",
        "\n",
        "Normalmente, el an치lisis de sentimientos se aborda como clasificaci칩n de documentos en una o varias categor칤as (sentimientos o emociones).\n",
        "\n",
        "Para este caso, usaremos el conjunto de datos [Twitter Sentiment Analysis](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis) de Kaggle. Comenzamos carg치ndolo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5902754",
      "metadata": {
        "id": "b5902754"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u4/twitter_sentiment.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940b2e0a",
      "metadata": {
        "id": "940b2e0a"
      },
      "source": [
        "Como podemos ver, es un corpus que contiene dos columnas:\n",
        "\n",
        "- `category`: tipo de sentimiento asociado al texto.\n",
        "- `text`: texto del documento.\n",
        "\n",
        "Se trata de textos extra칤dos de Twitter y etiquetados en 3 categor칤as:\n",
        "\n",
        "- `Negative`: sentimiento negativo.\n",
        "- `Positive`: sentimiento positivo.\n",
        "- `Neutral`: sentimiento neutral.\n",
        "\n",
        "Veamos la distribuci칩n de las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1cd790",
      "metadata": {
        "id": "2b1cd790"
      },
      "outputs": [],
      "source": [
        "counts = (\n",
        "        data\n",
        "        .category\n",
        "        .value_counts()\n",
        "        .reset_index()\n",
        "        )\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(data=counts, x=\"category\", y=\"count\", ax=ax, hue=\"category\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63424b1d",
      "metadata": {
        "id": "63424b1d"
      },
      "source": [
        "Para este ejemplo, usaremos el siguiente *pipeline* de `spacy` para tokenizaci칩n y eliminaci칩n de stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2cf542b",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "b2cf542b"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "display(nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2848102b",
      "metadata": {
        "id": "2848102b"
      },
      "source": [
        "Ahora, definimos una funci칩n de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f46535d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "7f46535d"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    doc = nlp(text) # creamos documento de spacy\n",
        "    filtered_tokens = \" \".join(\n",
        "            token.text\n",
        "            for token in doc\n",
        "            if not token.is_stop and\n",
        "            len(token) > 3 and len(token) < 24\n",
        "            ) # filtramos stopwords y palabras por longitud\n",
        "    lower_text = filtered_tokens.lower() # texto en min칰scula\n",
        "    norm_text = unidecode(lower_text) # texto normalizado\n",
        "    clean_text = re.sub(r\"[^a-z ]\", \" \", norm_text) # eliminamos caracteres especiales\n",
        "    spaces_text = re.sub(r\"\\s+\", \" \", clean_text) # eliminamos espacios repetidos\n",
        "    strip_text = spaces_text.strip() # eliminamos espacios de inicio y final\n",
        "    if not len(strip_text): # validamos si el documento tiene longitud\n",
        "        return None\n",
        "    else:\n",
        "        return strip_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b327a9e",
      "metadata": {
        "id": "8b327a9e"
      },
      "source": [
        "Aplicamos la funci칩n de preprocesamiento sobre todo el corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be545ae",
      "metadata": {
        "id": "2be545ae"
      },
      "outputs": [],
      "source": [
        "data_na = data.dropna()\n",
        "data_prep = (\n",
        "        data_na\n",
        "        .assign(text=data_na.text.apply(preprocess))\n",
        "        .dropna()\n",
        "        )\n",
        "display(data_prep.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d9ed29",
      "metadata": {
        "id": "81d9ed29"
      },
      "source": [
        "## **3. Clasificaci칩n con Bolsas de Palabras**\n",
        "---\n",
        "\n",
        "Primero veremos un ejemplo de clasificaci칩n de sentimientos usando una representaci칩n basada en bolsa de palabras como t칠cnica de extracci칩n de caracter칤sticas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43efcf2",
      "metadata": {
        "id": "b43efcf2"
      },
      "source": [
        "### **3.1. Extracci칩n de Caracter칤sticas**\n",
        "---\n",
        "\n",
        "Comenzamos importando el vectorizador de `sklearn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91202855",
      "metadata": {
        "id": "91202855"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03a46d0",
      "metadata": {
        "id": "f03a46d0"
      },
      "source": [
        "Obtenemos una representaci칩n de bolsa de palabras del corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3790d0f3",
      "metadata": {
        "id": "3790d0f3"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer(max_features=5000).fit(data_prep.text)\n",
        "display(vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a0eb44",
      "metadata": {
        "id": "75a0eb44"
      },
      "source": [
        "Podemos obtener la matriz de caracter칤sticas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2928afe",
      "metadata": {
        "id": "a2928afe"
      },
      "outputs": [],
      "source": [
        "features = vect.transform(data_prep.text).toarray()\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38764ca0",
      "metadata": {
        "id": "38764ca0"
      },
      "source": [
        "Como podemos ver, tenemos un total de 5993 documentos y un vocabulario de tama침o 5000."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de7fc946",
      "metadata": {
        "id": "de7fc946"
      },
      "source": [
        "### **3.2. Modelamiento**\n",
        "---\n",
        "\n",
        "Uno de los conceptos claves relacionados al entrenamiento de modelos supervisados es la **validaci칩n cruzada**, se trata de una estrategia para validar qu칠 tan generalizable es un modelo.\n",
        "\n",
        "En este caso usaremos una estrategia de validaci칩n cruzada conocida como K-fold cross-validation:\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1gta4-p20xuFQq3gTqKN6MeATY624M1ML\" width=\"80%\">\n",
        "\n",
        "Esto nos permite evaluar distintas configuraciones de un modelo (hiper-par치metros) y evaluar una m칠trica $K$ veces para obtener un buen estimador de alguna m칠trica de desempe침o.\n",
        "\n",
        "> **Nota**: el detalle de la metodolog칤a de validaci칩n cruzada y de los modelos se estudia con mayor profundidad en el **m칩dulo 2 de introducci칩n a machine learning**. En este notebook veremos de forma pr치ctica la metodolog칤a enfoc치ndonos m치s en su aplicaci칩n en el procesamiento de lenguaje natural.\n",
        "\n",
        "Comenzamos importando `LabelEncoder` de `sklearn` para codificar los sentimientos de una forma compatible con un modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f252c91b",
      "metadata": {
        "id": "f252c91b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f6ff5d",
      "metadata": {
        "id": "69f6ff5d"
      },
      "source": [
        "Obtenemos las etiquetas codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6bb8a53",
      "metadata": {
        "id": "c6bb8a53"
      },
      "outputs": [],
      "source": [
        "labeler = LabelEncoder().fit(data_prep.category)\n",
        "display(labeler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2691d735",
      "metadata": {
        "id": "2691d735"
      },
      "source": [
        "Ahora, codificamos las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158d2b27",
      "metadata": {
        "id": "158d2b27"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_prep.category)\n",
        "display(np.unique(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81f84d0",
      "metadata": {
        "id": "c81f84d0"
      },
      "source": [
        "Como podemos ver, las etiquetas fueron codificadas como n칰meros enteros, podemos ver la correspondencia entre cada categor칤a y cada n칰mero (dada por el orden de las categor칤as en el siguiente arreglo):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee284d4",
      "metadata": {
        "id": "dee284d4"
      },
      "outputs": [],
      "source": [
        "display(labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f42399c",
      "metadata": {
        "id": "4f42399c"
      },
      "source": [
        "Ahora importamos la funci칩n `train_test_split` para dividir el conjunto de datos en entrenamiento (ajuste del modelo) y prueba (evaluaci칩n del desempe침o sobre datos no vistos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10f7c4b",
      "metadata": {
        "id": "f10f7c4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc16480",
      "metadata": {
        "id": "cdc16480"
      },
      "source": [
        "Particionamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69c859a",
      "metadata": {
        "id": "c69c859a"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=0.4, # tama침o del conjunto de prueba\n",
        "    random_state=13, # semilla de n칰meros aleatorios\n",
        "    stratify=labels, # mantenemos distribuci칩n de etiquetas\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70040551",
      "metadata": {
        "id": "70040551"
      },
      "source": [
        "Veamos el tama침o de las matrices de entrenamiento y prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0d80c7",
      "metadata": {
        "id": "0f0d80c7"
      },
      "outputs": [],
      "source": [
        "display(features_train.shape)\n",
        "display(features_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b32fa4d",
      "metadata": {
        "id": "4b32fa4d"
      },
      "source": [
        "Ahora podemos entrenar un modelo. Es posible usar cualquier tipo de modelo de clasificaci칩n como:\n",
        "- bosques aleatorios\n",
        "- m치quinas de soporte vectorial\n",
        "- redes neuronales\n",
        "- entre otros\n",
        "\n",
        "En este caso utilizaremos un clasificador **Bayesiano ingenuo multinomial** (*multinomial Naive Bayes*), el cual es un algoritmo de aprendizaje autom치tico utilizado para clasificar documentos de texto basados en bolsas de palabras. El algoritmo funciona asumiendo que cada caracter칤stica (palabra) en el texto es independiente de las dem치s caracter칤sticas y tiene una distribuci칩n multinomial como verosimilitud, y que la probabilidad de una caracter칤stica dada una clase es proporcional a la frecuencia de esa caracter칤stica en el texto de esa clase. Utiliza la probabilidad _a priori_ de cada clase para calcular la probabilidad a posteriori de cada clase dado el texto, y finalmente, asigna la clase con la probabilidad _a posteriori_ m치s alta al texto, como se muestra en la siguiente ecuaci칩n:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FPZiKYUZ1tLieT1g7XyKAltDj90FcAig\" width=\"80%\">\n",
        "\n",
        "Es un modelo ampliamente utilizado en problemas de clasificaci칩n de texto como el an치lisis de sentimientos y la clasificaci칩n de correo no deseado. Veamos c칩mo importar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05639e7c",
      "metadata": {
        "id": "05639e7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982488fa",
      "metadata": {
        "id": "982488fa"
      },
      "source": [
        "Este modelo utiliza internamente probabilidades junto con la regla de Bayes para dar la probabilidad de que un documento pertenezca a una categor칤a. Para esto, hace uso de un hiper-par치metro `alpha` que permite controlar qu칠 tan suave se realiza la asignaci칩n de un documento en una categor칤a; se trata de un n칰mero que debe ser explorado entre 0 y el n칰mero de documentos.\n",
        "\n",
        "Definimos un rango para el hiper-par치metro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c4e42b",
      "metadata": {
        "id": "c9c4e42b"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"alpha\": 10 ** np.arange(5)}\n",
        "display(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a6922a",
      "metadata": {
        "id": "95a6922a"
      },
      "source": [
        "Ahora importamos la clase `GridSearchCV` para implementar la estrategia de K-fold cross-validation y encontrar el mejor valor de `alpha`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "767113cd",
      "metadata": {
        "id": "767113cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7d55d2",
      "metadata": {
        "id": "4b7d55d2"
      },
      "source": [
        "Realizamos el entrenamiento y la exploraci칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0610db19",
      "metadata": {
        "id": "0610db19"
      },
      "outputs": [],
      "source": [
        "gsearch = GridSearchCV(\n",
        "    MultinomialNB(),\n",
        "    param_grid=param_grid,\n",
        "    cv=3\n",
        "    ).fit(features_train, labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fed11dce",
      "metadata": {
        "id": "fed11dce"
      },
      "source": [
        "Veamos la exactitud del modelo en la clasificaci칩n de sentimientos para los distintos valores de `alpha`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302406db",
      "metadata": {
        "id": "302406db"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gsearch.cv_results_)\n",
        "display(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce46d28",
      "metadata": {
        "id": "4ce46d28"
      },
      "source": [
        "Extraemos el modelo que mejor funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bbf82e1",
      "metadata": {
        "id": "1bbf82e1"
      },
      "outputs": [],
      "source": [
        "model = gsearch.best_estimator_\n",
        "display(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357b3a88",
      "metadata": {
        "id": "357b3a88"
      },
      "source": [
        "### **3.3. Evaluaci칩n**\n",
        "---\n",
        "\n",
        "Veamos el desempe침o del modelo sobre datos no vistos (conjunto de evaluaci칩n o *test*) usando m칠tricas de desempe침o para clasificaci칩n.\n",
        "\n",
        "`sklearn` nos permite evaluar las m칠tricas m치s importantes usando la funci칩n `classification_report`. La podemos importar as칤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66582a4",
      "metadata": {
        "id": "f66582a4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2742a7a0",
      "metadata": {
        "id": "2742a7a0"
      },
      "source": [
        "Obtenemos las predicciones sobre el conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1033df3b",
      "metadata": {
        "id": "1033df3b"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(features_test)\n",
        "print(classification_report(labels_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b661fdc5",
      "metadata": {
        "id": "b661fdc5"
      },
      "source": [
        "Como podemos ver, el modelo tiene un accuracy de 0.84 en la clasificaci칩n de los 3 sentimientos.\n",
        "\n",
        "Tambi칠n podemos calcular una matriz de confusi칩n para ver errores espec칤ficos en la clasificaci칩n, para esto importamos `confusion_matrix`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532e8696",
      "metadata": {
        "id": "532e8696"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44bf811",
      "metadata": {
        "id": "c44bf811"
      },
      "source": [
        "Calculamos la matriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a4d1cf",
      "metadata": {
        "id": "e6a4d1cf"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad411de",
      "metadata": {
        "id": "cad411de"
      },
      "source": [
        "Veamos una visualizaci칩n de la matriz de confusi칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197bb106",
      "metadata": {
        "id": "197bb106"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicci칩n\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a81e269",
      "metadata": {
        "id": "3a81e269"
      },
      "source": [
        "Por 칰ltimo, veamos un ejemplo de clasificaci칩n de sentimientos para un texto arbitrario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1fc316",
      "metadata": {
        "id": "3c1fc316"
      },
      "outputs": [],
      "source": [
        "text = \"this game is trash\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb659007",
      "metadata": {
        "id": "eb659007"
      },
      "source": [
        "Veamos el flujo completo:\n",
        "\n",
        "- Preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a769f38",
      "metadata": {
        "id": "7a769f38"
      },
      "outputs": [],
      "source": [
        "prep_text = preprocess(text)\n",
        "display(prep_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9585c5f",
      "metadata": {
        "id": "b9585c5f"
      },
      "source": [
        "- Extracci칩n de caracter칤sticas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75449f30",
      "metadata": {
        "id": "75449f30"
      },
      "outputs": [],
      "source": [
        "features = vect.transform([prep_text])\n",
        "display(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9942d1c",
      "metadata": {
        "id": "b9942d1c"
      },
      "source": [
        "- Modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2a09c1",
      "metadata": {
        "id": "1d2a09c1"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(features)\n",
        "display(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d163e09",
      "metadata": {
        "id": "7d163e09"
      },
      "source": [
        "Por 칰ltimo, decodificamos la predicci칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2fe1a7",
      "metadata": {
        "id": "3c2fe1a7"
      },
      "outputs": [],
      "source": [
        "display(labeler.inverse_transform(prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d45eca4",
      "metadata": {
        "id": "6d45eca4"
      },
      "source": [
        "Con esto tenemos un modelo personalizado para an치lisis de sentimientos basado en bolsas de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b57dad",
      "metadata": {
        "id": "b8b57dad"
      },
      "source": [
        "## **4. Clasificaci칩n con Embeddings**\n",
        "---\n",
        "\n",
        "Tambi칠n podemos utilizar otros tipos de representaciones para manejar los documentos. Como en este caso buscamos clasificar documentos completos, y no palabras, vamos a usar un embedding **Doc2Vec**.\n",
        "\n",
        "> **Nota**: si se busca clasificar tokens, puede utilizar representaciones como bolsas de N-grams a nivel de caracteres, Word2Vec o FastText."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdfba92",
      "metadata": {
        "id": "ffdfba92"
      },
      "source": [
        "### **4.1. Extracci칩n de Caracter칤sticas**\n",
        "---\n",
        "\n",
        "Para la extracci칩n de caracter칤sticas importamos el modelo `Doc2Vec` de `gensim`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7d2891",
      "metadata": {
        "id": "bc7d2891"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69de0691",
      "metadata": {
        "id": "69de0691"
      },
      "source": [
        "Creamos el corpus anotado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08872a76",
      "metadata": {
        "id": "08872a76"
      },
      "outputs": [],
      "source": [
        "tagged_corpus = [\n",
        "        TaggedDocument(doc.split(), [i])\n",
        "        for i, doc in enumerate(data_prep.text.to_list())\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc2deb4",
      "metadata": {
        "id": "8bc2deb4"
      },
      "source": [
        "Ahora entrenamos el embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99dd72bd",
      "metadata": {
        "id": "99dd72bd"
      },
      "outputs": [],
      "source": [
        "embedding = Doc2Vec(\n",
        "        tagged_corpus,\n",
        "        vector_size=500,\n",
        "        alpha=1e-3,\n",
        "        epochs=1000,\n",
        "        workers=-1\n",
        "        )\n",
        "display(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4faa8b2",
      "metadata": {
        "id": "b4faa8b2"
      },
      "source": [
        "Obtenemos una matriz de caracter칤sticas basada en este embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603d917c",
      "metadata": {
        "id": "603d917c"
      },
      "outputs": [],
      "source": [
        "features = list(map(lambda doc: embedding.infer_vector(doc.words), tagged_corpus))\n",
        "features = np.vstack(features)\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7edd50",
      "metadata": {
        "id": "0d7edd50"
      },
      "source": [
        "Tambi칠n debemos codificar las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2cb9e9",
      "metadata": {
        "id": "bf2cb9e9"
      },
      "outputs": [],
      "source": [
        "labeler = LabelEncoder().fit(data_prep.category)\n",
        "display(labeler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7247075",
      "metadata": {
        "id": "f7247075"
      },
      "source": [
        "Obtenemos las etiquetas codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b17e04",
      "metadata": {
        "id": "43b17e04"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_prep.category)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29dd160",
      "metadata": {
        "id": "f29dd160"
      },
      "source": [
        "### **4.2. Modelamiento**\n",
        "---\n",
        "\n",
        "Al igual que en el caso anterior, vamos a seguir una metodolog칤a de validaci칩n cruzada para determinar la generalizaci칩n del modelo y seleccionar hiper-par치metros. Comenzamos particionando el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876155d5",
      "metadata": {
        "id": "876155d5"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=0.4, # tama침o del conjunto de prueba\n",
        "    random_state=13, # semilla de n칰meros aleatorios\n",
        "    stratify=labels, # mantenemos distribuci칩n de etiquetas\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6e665",
      "metadata": {
        "id": "5fe6e665"
      },
      "source": [
        "Veamos el tama침o de las matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfac2c81",
      "metadata": {
        "id": "cfac2c81"
      },
      "outputs": [],
      "source": [
        "display(features_train.shape)\n",
        "display(features_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867389ee",
      "metadata": {
        "id": "867389ee"
      },
      "source": [
        "En este caso utilizaremos un clasificador **Bayesiano ingenuo Gaussiano** (*Gaussian Naive Bayes*), el cual es un algoritmo de aprendizaje autom치tico que se utiliza para clasificar documentos de texto basados en embeddings. En lugar de tratar con caracter칤sticas discretas como las palabras individuales, se emplean embeddings para representar cada documento de texto como un vector continuo en un espacio de caracter칤sticas de alta dimensi칩n. El algoritmo asume que los embeddings de los documentos de una clase determinada se distribuyen de manera gaussiana en el espacio de caracter칤sticas, y usa la media y la varianza de esta distribuci칩n para calcular la probabilidad de que un nuevo documento pertenezca a esa clase. Utiliza la probabilidad _a priori_ de cada clase para calcular la probabilidad _a posteriori_ de cada clase dado el texto, y finalmente, asigna la clase con la probabilidad _a posteriori_ m치s alta al texto, como se muestra en la siguiente ecuaci칩n:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QxbbA9_zfIwteHX2lrG04zRZbvQxbDMK\" width=\"80%\">\n",
        "\n",
        "Veamos c칩mo importar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75af56b3",
      "metadata": {
        "id": "75af56b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596478de",
      "metadata": {
        "id": "596478de"
      },
      "source": [
        "Este modelo tiene como hiper-par치metro `var_smoothing`, el cual funciona de una forma equivalente al par치metro `alpha` en la versi칩n multinomial. Definimos el rango de valores a explorar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "796d97f8",
      "metadata": {
        "id": "796d97f8"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"var_smoothing\": 10. ** np.arange(-9, -3)}\n",
        "display(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830e7c2c",
      "metadata": {
        "id": "830e7c2c"
      },
      "source": [
        "Ahora entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291467fe",
      "metadata": {
        "id": "291467fe"
      },
      "outputs": [],
      "source": [
        "gsearch = GridSearchCV(\n",
        "    GaussianNB(),\n",
        "    param_grid=param_grid,\n",
        "    cv=3\n",
        "    ).fit(features_train, labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846c352c",
      "metadata": {
        "id": "846c352c"
      },
      "source": [
        "Veamos los resultados de la exploraci칩n de hiper-par치metros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d5e3a2",
      "metadata": {
        "id": "64d5e3a2"
      },
      "outputs": [],
      "source": [
        "display(pd.DataFrame(gsearch.cv_results_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "410af161",
      "metadata": {
        "id": "410af161"
      },
      "source": [
        "Extraemos el mejor modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd163344",
      "metadata": {
        "id": "bd163344"
      },
      "outputs": [],
      "source": [
        "model = gsearch.best_estimator_\n",
        "display(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db149cb0",
      "metadata": {
        "id": "db149cb0"
      },
      "source": [
        "### **4.3. Evaluaci칩n**\n",
        "---\n",
        "\n",
        "Extraemos las predicciones del modelo sobre el conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f93523e",
      "metadata": {
        "id": "4f93523e"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(features_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d4f6a8",
      "metadata": {
        "id": "45d4f6a8"
      },
      "source": [
        "Veamos el reporte de clasificaci칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba215562",
      "metadata": {
        "id": "ba215562"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d343f52",
      "metadata": {
        "id": "5d343f52"
      },
      "source": [
        "Tambi칠n podemos ver la matriz de confusi칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a76832",
      "metadata": {
        "id": "a5a76832"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b17cfe59",
      "metadata": {
        "id": "b17cfe59"
      },
      "source": [
        "Veamos una visualizaci칩n de la matriz de confusi칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eeb64ee",
      "metadata": {
        "id": "5eeb64ee"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicci칩n\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6355f2c3",
      "metadata": {
        "id": "6355f2c3"
      },
      "source": [
        "Como podemos ver, el desempe침o con **Doc2Vec** no es tan bueno. Recuerde que los _embeddings_ requieren una gran cantidad de datos y mucho tiempo de entrenamiento para llegar a representar de forma correcta un corpus. Para que este enfoque funcione mejor, necesitamos m치s datos o utilizar un modelo pre-entrenado en un corpus similar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850017d",
      "metadata": {
        "id": "d850017d"
      },
      "source": [
        "## **5. Clasificaci칩n con Vader**\n",
        "\n",
        "Una alternativa para an치lisis de sentimientos es con modelos pre-entrenados o librer칤as dise침adas para ello. Un ejemplo de esto es [VADER](https://github.com/cjhutto/vaderSentiment) (*Valence Aware Dictionary and sEntiment Reasoner*). Se trata de una librer칤a basada en reglas que usa l칠xicos para el an치lisis de sentimientos. Es una herramienta de uso libre que est치 enfocada en el an치lisis de datos en redes sociales y provee informaci칩n acerca de los sentimientos en un texto (qu칠 tan positivo o negativo es).\n",
        "\n",
        "Algunas de las ventajas de VADER son:\n",
        "\n",
        "- Funciona bien en datos de redes sociales, sin embargo, se puede generalizar en otros dominios.\n",
        "- No requiere datos para el entrenamiento.\n",
        "- Es lo suficientemente r치pido como para ser usado con datos en streaming.\n",
        "\n",
        "Comenzamos instalando la librer칤a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd8c72b",
      "metadata": {
        "id": "efd8c72b"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e367f8",
      "metadata": {
        "id": "49e367f8"
      },
      "source": [
        "Para usar `vader` debemos importar la clase `SentimentIntensityAnalyzer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac283f82",
      "metadata": {
        "id": "ac283f82"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7027a727",
      "metadata": {
        "id": "7027a727"
      },
      "source": [
        "Instanciamos el analizador de sentimientos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28557cda",
      "metadata": {
        "id": "28557cda"
      },
      "outputs": [],
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d6b7a4",
      "metadata": {
        "id": "f0d6b7a4"
      },
      "source": [
        "Veamos un ejemplo de c칩mo podemos usar el analizador con un texto con sentimientos positivos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4a0a83",
      "metadata": {
        "id": "5a4a0a83"
      },
      "outputs": [],
      "source": [
        "res = analyzer.polarity_scores(\n",
        "        \"I am happy today, because, it is my birthday.\"\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4fbbade",
      "metadata": {
        "id": "b4fbbade"
      },
      "source": [
        "Tambi칠n podemos hacerlo con un texto negativo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e7f9a8",
      "metadata": {
        "id": "c4e7f9a8"
      },
      "outputs": [],
      "source": [
        "res = analyzer.polarity_scores(\n",
        "        \"I think I won't go, my grandma is ill.\"\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec8a907",
      "metadata": {
        "id": "4ec8a907"
      },
      "source": [
        "El analizador nos da cuatro m칠tricas:\n",
        "\n",
        "- _neg, neu, pos_: son la proporci칩n de expresiones negativas, neutrales y positivas encontradas en el texto.\n",
        "- _compound_: se trata de una calificaci칩n que toma valores entre -1 y 1. Puede verse como el sentimiento del texto dado.\n",
        "\n",
        "As칤 mismo, podemos clasificar el sentimiento del texto de acuerdo con la siguiente convenci칩n seg칰n los desarrolladores de la librer칤a:\n",
        "\n",
        "| Sentimiento | Compound |\n",
        "| --- | --- |\n",
        "| Negativo | $\\text{compound}\\leq -0.05$ |\n",
        "| Neutral | $-0.05 < \\text{compound} < 0.05$|\n",
        "| Positivo | $\\text{compound}\\geq 0.05$ |\n",
        "\n",
        "Adem치s de analizar el l칠xico de las palabras, **VADER** incluye algunas reglas adicionales:\n",
        "\n",
        "- **Puntuaci칩n**: el uso del signo de exclamaci칩n significa una mayor intensidad, sucesiones de signos de exclamaci칩n alteran el score total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ec04ac",
      "metadata": {
        "id": "b7ec04ac"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10fb422",
      "metadata": {
        "id": "c10fb422"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfaee29e",
      "metadata": {
        "id": "dfaee29e"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065fff93",
      "metadata": {
        "id": "065fff93"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!!!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ada7fb",
      "metadata": {
        "id": "d4ada7fb"
      },
      "source": [
        "- **May칰sculas**: palabras relevantes que est칠n en may칰sculas enfatizan el sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02451fa",
      "metadata": {
        "id": "a02451fa"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was nice to me.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332ec0c2",
      "metadata": {
        "id": "332ec0c2"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was NICE to me\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d757a7d",
      "metadata": {
        "id": "0d757a7d"
      },
      "source": [
        "- **Modificadores de grado**: el uso de palabras para enfatizar un mayor grado tambi칠n modifica el score final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5857af05",
      "metadata": {
        "id": "5857af05"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was partially nice to me.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4867454",
      "metadata": {
        "id": "f4867454"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was extremely nice to me.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d01614",
      "metadata": {
        "id": "62d01614"
      },
      "source": [
        "- **Conjunciones**: algunas palabras pueden cambiar el sentimiento de una oraci칩n; **VADER** tambi칠n tiene en cuenta estas conjunciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2ecbc0",
      "metadata": {
        "id": "ba2ecbc0"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"The zoo was ok\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5441f0f8",
      "metadata": {
        "id": "5441f0f8"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"The zoo was ok, but I'm sad for the animals\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "739f86ca",
      "metadata": {
        "id": "739f86ca"
      },
      "source": [
        "- **Lenguaje informal**: como **VADER** est치 especializado en el an치lisis de datos de redes sociales, funciona bien cuando se utilizan coloquialismos y emojis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befd8eb5",
      "metadata": {
        "id": "befd8eb5"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"I'm feeling 游 this evening.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d02d563",
      "metadata": {
        "id": "3d02d563"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"游땤\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9877d93f",
      "metadata": {
        "id": "9877d93f"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"游땴\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a7a892",
      "metadata": {
        "id": "e5a7a892"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"游땝\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01b9b31",
      "metadata": {
        "id": "d01b9b31"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"LOL, that joke was fun.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf48cd4",
      "metadata": {
        "id": "bdf48cd4"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"This sux\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c322630e",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "c322630e"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"You seem so :) when I was like :D\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bf1876",
      "metadata": {
        "id": "58bf1876"
      },
      "source": [
        "Veamos el desempe침o de `vader` sobre el conjunto de datos que estamos manejando. Para esto definimos la siguiente funci칩n para extraer una categor칤a de acuerdo al clasificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829fb988",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "829fb988"
      },
      "outputs": [],
      "source": [
        "def vader_prediction(text):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    compound = scores[\"compound\"]\n",
        "    if compound < -0.05:\n",
        "        return \"Negative\"\n",
        "    elif compound < 0.05:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb2a9a7",
      "metadata": {
        "id": "7eb2a9a7"
      },
      "source": [
        "Obtenemos las predicciones de `vader` para cada documento del corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99165066",
      "metadata": {
        "id": "99165066"
      },
      "outputs": [],
      "source": [
        "data_vader = data.assign(prediction = data.text.apply(vader_prediction))\n",
        "display(data_vader.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc0c5fa",
      "metadata": {
        "id": "1dc0c5fa"
      },
      "source": [
        "Veamos el desempe침o del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627611dd",
      "metadata": {
        "id": "627611dd"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_vader.category)\n",
        "predictions = labeler.transform(data_vader.prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85c7e3a",
      "metadata": {
        "id": "e85c7e3a"
      },
      "source": [
        "Veamos el reporte de clasificaci칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93de89b",
      "metadata": {
        "id": "f93de89b"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae173d2",
      "metadata": {
        "id": "bae173d2"
      },
      "source": [
        "Tambi칠n podemos ver la matriz de confusi칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81252280",
      "metadata": {
        "id": "81252280"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae83287f",
      "metadata": {
        "id": "ae83287f"
      },
      "source": [
        "Veamos una visualizaci칩n de la matriz de confusi칩n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8068323b",
      "metadata": {
        "id": "8068323b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicci칩n\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4cae43",
      "metadata": {
        "id": "be4cae43"
      },
      "source": [
        "Como se puede ver, el desempe침o no es tan bueno como el modelo basado en bolsas de palabras. No obstante, `vader` nos da un resultado aceptable sin la necesidad de entrenar un modelo.\n",
        "\n",
        "En este caso mostramos un ejemplo de an치lisis de sentimientos en ingl칠s, ya que librer칤as importantes como `vader` funcionan en este idioma. Tenga en cuenta que puede entrenar modelos en espa침ol siempre que disponga de un corpus etiquetado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3831bc96",
      "metadata": {
        "id": "3831bc96"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrar치 informaci칩n muy 칰til para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment).\n",
        "- [Sentiment Analysis using Python](https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/).\n",
        "- _Fuente de los 칤conos_\n",
        "     - Flaticon. Document free icon [PNG]. https://www.flaticon.com/free-icon/document_888071\n",
        "     - Flaticon. Happy face free icon [PNG]. https://www.flaticon.com/free-icon/happy-face_5624232\n",
        "     - Flaticon. Review free icon [PNG]. https://www.flaticon.com/free-icon/review_5624236\n",
        "     - Flaticon. Neutral free icon [PNG]. https://www.flaticon.com/free-icon/neutral_3688054"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a394dd7a",
      "metadata": {
        "id": "a394dd7a"
      },
      "source": [
        "## Cr칠ditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebasti치n Lara Ram칤rez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Dise침o de im치genes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualizaci칩n:**\n",
        "    - [Edder Hern치ndez Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingenier칤a*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}