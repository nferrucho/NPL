{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo3/3_ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19590516",
      "metadata": {
        "id": "19590516"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1e7ctPi8O3bTQoLZaO9ZZjwGr2r8Z93RS\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdXlpfU5Iz5g"
      },
      "id": "LdXlpfU5Iz5g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5KFUjCwI0Zz"
      },
      "id": "n5KFUjCwI0Zz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noCvZVjKI05f"
      },
      "id": "noCvZVjKI05f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fae6dd31",
      "metadata": {
        "id": "fae6dd31"
      },
      "source": [
        "# N-grams\n",
        "---\n",
        "\n",
        "En este notebook veremos cómo podemos extraer características a partir de texto utilizando una estrategia de representación conocida como bolsas de N-grams (BoN - Bag-of-N-grams). Primero importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d375b56",
      "metadata": {
        "id": "0d375b56"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ee1208",
      "metadata": {
        "id": "b4ee1208"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, IFrame\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from unidecode import unidecode\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb793e1",
      "metadata": {
        "id": "3bb793e1"
      },
      "source": [
        "## **1. Motivación y Definición**\n",
        "---\n",
        "\n",
        "Los N-grams son un tipo de representación que generaliza las bolsas de palabras (BoW), de hecho, un BoW corresponde a un caso específico de unigrama (1-gram a nivel de palabra).\n",
        "\n",
        "Este tipo de *embedding* consiste en conteos de secuencias de tokens, es decir, se busca una distribución de secuencias $s_j$ dado un determinado documento $d_i$, de esta forma: $P(S=s_j | D=d_i)$.\n",
        "\n",
        "Los N-grams se definen como secuencias de tokens de longitud $N$, veamos un ejemplo con la palabra:\n",
        "\n",
        "> `\"universidad\"`:\n",
        "\n",
        "- Los 1-grams a nivel de carácter son: `\"u\"`, `\"n\"`, `\"i\"`, `\"v\"`, `\"e\"`, `\"r\"`, `\"s\"`, `\"d\"`, `\"a\"`.\n",
        "- Los 2-grams a nivel de carácter son: `\"un\"`, `\"ni\"`, `\"iv\"`, \"`ve`\", `\"er\"`, `\"rs\"`, `\"si\"`, `\"id\"`, `\"da\"`, `\"ad\"`.\n",
        "- Los 3-grams a nivel de carácter son: `\"uni\"`, `\"niv\"`, `\"ive\"`, `\"ver\"`, `\"ers\"`, `\"rsi\"`, `\"sid\"`, `\"ida\"`, `\"dad\"`.\n",
        "\n",
        "También es posible calcular N-grams a nivel palabra. Veamos un ejemplo con la oración:\n",
        "\n",
        "> `\"Albert Einstein era un científico\"`\n",
        "\n",
        "- Los 1-grams a nivel de palabra son: `\"Albert\"`, `\"Einstein\"`, `\"era\"`, `\"un\"`, `\"científico\"`.\n",
        "- Los 2-grams a nivel de palabra son: `\"Albert Einstein\"`, `\"Einstein era\"`, `\"era un\"`, `\"un científico\"`.\n",
        "- Los 3-grams a nivel de palabra son: `\"Albert Einstein era\"`, `\"Einstein era un\"`, `\"era un científico\"`.\n",
        "\n",
        "En la siguiente figura se presenta un ejemplo con N-grams a nivel de palabra para una frase más larga:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16YxKp76Uu9SzbIn1RwKYq0IBmPoXHe29\" width=\"100%\">\n",
        "\n",
        "\n",
        "Veamos un ejemplo en _Python_ para calcular los N-grams. Primero definimos un texto de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ef8ba3",
      "metadata": {
        "id": "87ef8ba3"
      },
      "outputs": [],
      "source": [
        "text = \"este es un texto de ejemplo para calcular n-grams y sus conteos\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c88c039",
      "metadata": {
        "id": "2c88c039"
      },
      "source": [
        "Primero, calculamos todos los posibles 2-grams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "761e7088",
      "metadata": {
        "id": "761e7088"
      },
      "outputs": [],
      "source": [
        "bigrams = list(set(text[i: i + 2] for i in range(len(text) - 2)))\n",
        "display(bigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97806b6",
      "metadata": {
        "id": "f97806b6"
      },
      "source": [
        "Ahora, podemos calcular los conteos de bigramas en el texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "844a5d5e",
      "metadata": {
        "id": "844a5d5e"
      },
      "outputs": [],
      "source": [
        "counts = {bigram: text.count(bigram) for bigram in bigrams}\n",
        "display(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8bc4c7",
      "metadata": {
        "id": "5a8bc4c7"
      },
      "source": [
        "Veamos un diagrama de barras de los conteos de bigramas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37ea4fc3",
      "metadata": {
        "id": "37ea4fc3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "ax.bar(counts.keys(), counts.values())\n",
        "for tick in ax.get_xticklabels():\n",
        "    tick.set_rotation(90)\n",
        "ax.set_xlabel(\"Bigrama\")\n",
        "ax.set_ylabel(\"Conteo\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a47503",
      "metadata": {
        "id": "43a47503"
      },
      "source": [
        "## **2. Implementación con sklearn**\n",
        "---\n",
        "\n",
        "Utilizando las clases `CountVectorizer` y `TfidfVectorizer` de `sklearn` podemos calcular representaciones de N-grams de la misma forma en la que calculábamos bolsas de palabras, para ello, haremos uso de los siguientes dos parámetros:\n",
        "\n",
        "- `analyzer`: específica si se calculan n-grams a nivel `\"char\"` (carácter) o `\"word\"` (palabra).\n",
        "- `ngram_range`: específica el rango de grams a considerar, por ejemplo, `(1, 3)` calcula 1-grams, 2-grams y 3-grams.\n",
        "\n",
        "Veamos un ejemplo sobre el siguiente corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f72317",
      "metadata": {
        "id": "c2f72317"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "        \"albert einstein era un científico\",\n",
        "        \"la teoría de la relatividad de albert einstein\"\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ee14d89",
      "metadata": {
        "id": "3ee14d89"
      },
      "source": [
        "Veamos un ejemplo de bigramas a nivel de palabra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b970e3be",
      "metadata": {
        "id": "b970e3be"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer(\n",
        "        analyzer=\"word\",\n",
        "        ngram_range=(2, 2)\n",
        "        ).fit(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0771c1bd",
      "metadata": {
        "id": "0771c1bd"
      },
      "source": [
        "Extraemos la representación y  el vocabulario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04ac3b8",
      "metadata": {
        "id": "b04ac3b8"
      },
      "outputs": [],
      "source": [
        "X = vect.transform(corpus).toarray()\n",
        "vocab  = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05bad1a6",
      "metadata": {
        "id": "05bad1a6"
      },
      "source": [
        "Veamos la representación como un `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ec2ec5",
      "metadata": {
        "id": "a5ec2ec5"
      },
      "outputs": [],
      "source": [
        "X_pd = pd.DataFrame(columns=vocab, data=X)\n",
        "display(X_pd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f80151",
      "metadata": {
        "id": "25f80151"
      },
      "source": [
        "Veamos otro ejemplo con trigramas a nivel de carácter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ae4ad1",
      "metadata": {
        "id": "71ae4ad1"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer(\n",
        "        analyzer=\"char\",\n",
        "        ngram_range=(3, 3)\n",
        "        ).fit(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66398e4",
      "metadata": {
        "id": "b66398e4"
      },
      "source": [
        "Extraemos la representación y  el vocabulario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aacc083",
      "metadata": {
        "id": "4aacc083"
      },
      "outputs": [],
      "source": [
        "X = vect.transform(corpus).toarray()\n",
        "vocab  = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c48f37",
      "metadata": {
        "id": "18c48f37"
      },
      "source": [
        "Veamos la representación como un `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682472f5",
      "metadata": {
        "id": "682472f5"
      },
      "outputs": [],
      "source": [
        "X_pd = pd.DataFrame(columns=vocab, data=X)\n",
        "display(X_pd)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b654ed55",
      "metadata": {
        "id": "b654ed55"
      },
      "source": [
        "## **3. Modelos Probabilísticos del Lenguaje**\n",
        "---\n",
        "\n",
        "Los modelos probabilísticos del lenguaje son una forma clásica de entender los textos en procesamiento de lenguaje natural, estos modelos parten de una distribución conjunta de determinado documento $d_i$ compuesto de un conjunto $T=\\{t_1,t_2,\\dots, t_l\\}$ de términos ordenados:\n",
        "\n",
        "$$\n",
        "P(t_1, t_2, \\dots, t_l | d_i) = P(t_1 | d_i) P(t_2 | t_1, d_i) P(t_3 | t_1, t_2, d_i) \\dots P(t_l | t_{l-1}, t_{l-2}, \\dots, t_1, d_i)\n",
        "$$\n",
        "\n",
        "Por ejemplo, la distribución conjunta del siguiente ejemplo $d_0$ = `\"Esta es la casa que Jack construyó\"` sería:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "P(\\text{Esta, es, la, casa, que, Jack, construyó}) &= P(\\text{Esta})P(\\text{es}|\\text{Esta})P(\\text{la} | \\text{Esta}, \\text{es})\\\\\n",
        "&~~~~ \\dots P(\\text{construyó} | \\text{Esta,es,la,casa,que,Jack})\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Los N-grams surgen naturalmente al suponer que los documentos son [cadenas de Markov](https://es.wikipedia.org/wiki/Cadena_de_M%C3%A1rkov). Más específicamente, una suposición de Markov de grado $K$ considera un $(K+1)$-gram. Las _cadenas de Markov_ son modelos probabilísticos en los que se asume un tipo específico de independencia condicional, en el caso de texto, una cadena de grado $K$ representa que cada palabra es condicionada únicamente por sus $K$ palabras precedentes. Por ejemplo, veamos la siguiente cadena de grado 1:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Q-ORveyrHZy8gt_cqJ4xcwGioXfrmgdh\" width=\"80%\">\n",
        "\n",
        "Se puede ver que cada palabra depende únicamente de su predecesora, y palabras como `\"Photography\"`, `\"Science\"` y `\"Mathematics\"` son condicionalmente independientes de `\"I\"`, es decir:\n",
        "\n",
        "$$\n",
        "P(\\text{Photography} | \\text{like, I}) = P(\\text{Photography} | \\text{like})\n",
        "$$\n",
        "\n",
        "Adicionalmente, bajo esta independencia condicional, sólo se forman distribuciones entre secuencias de dos palabras, es decir, un 2-gram.\n",
        "\n",
        "Veamos algunos ejemplos de aplicación de los modelos probabilísticos del lenguaje."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07fcb4da",
      "metadata": {
        "id": "07fcb4da"
      },
      "source": [
        "### **3.1. Autocompletado**\n",
        "---\n",
        "\n",
        "El objetivo del autocompletado es determinar la secuencia de caracteres o palabras más probable en una distribución condicional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f656ea0e",
      "metadata": {
        "cellView": "form",
        "id": "f656ea0e"
      },
      "outputs": [],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/19fQ6RGRKZ-dCIv6Ypoku7n0PsaQj5J_W/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b1de8d",
      "metadata": {
        "id": "59b1de8d"
      },
      "source": [
        "Por ejemplo, en el siguiente corpus:\n",
        "\n",
        "- Esta es la casa que Jack construyó.\n",
        "- Esta es la casa de Pedro.\n",
        "- Esta es la tienda.\n",
        "- Esta es la rata.\n",
        "- Esta es la gata.\n",
        "\n",
        "Si partimos de la secuencia `\"Esta es la\"` podemos construir la distribución: $P(t_4 | t_1 = Esta, t_2 = es, t_3 = la)$. La cual puede ser usada para determinar la palabra que sigue de acuerdo a la siguiente regla:\n",
        "\n",
        "$$\n",
        "w_4 = \\text{argmax}_{t_i} P(t_4 | t_1 = Esta, t_2 = es, t_3 = la)\n",
        "$$\n",
        "\n",
        "En este caso, sabemos que la palabra más probable es `\"casa\"`, ya que tenemos las siguientes probabilidades:\n",
        "\n",
        "- $P(\\text{casa} | \\text{Esta, es la}) = \\frac{2}{5}$.\n",
        "- $P(\\text{tienda} | \\text{Esta, es la}) = \\frac{1}{5}$.\n",
        "- $P(\\text{rata} | \\text{Esta, es la}) = \\frac{1}{5}$.\n",
        "- $P(\\text{gata} | \\text{Esta, es la}) = \\frac{1}{5}$.\n",
        "\n",
        "Veamos un ejemplo práctico sobre el dataset [TMDB](https://www.themoviedb.org/?language=en-US) con resúmenes de películas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19724e8b",
      "metadata": {
        "id": "19724e8b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u3/movies.csv\")\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d8cf73",
      "metadata": {
        "id": "f9d8cf73"
      },
      "source": [
        "En específico el corpus está contenido en la columna `\"overview\"`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f836775",
      "metadata": {
        "id": "0f836775"
      },
      "outputs": [],
      "source": [
        "corpus = (\n",
        "        data\n",
        "        .dropna(subset=[\"overview\"])\n",
        "        .overview.tolist()\n",
        "        )\n",
        "display(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36f6d77",
      "metadata": {
        "id": "c36f6d77"
      },
      "source": [
        "Vamos a definir una función de preprocesamiento para el corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467994e5",
      "metadata": {
        "id": "467994e5"
      },
      "outputs": [],
      "source": [
        "pat = re.compile(r\"[^a-z ]\")\n",
        "spaces = re.compile(r\"\\s{2,}\")\n",
        "def preprocess(text, min_len=1, max_len=23):\n",
        "    # Normalizamos el texto\n",
        "    norm_text = unidecode(text).lower()\n",
        "\n",
        "    # Extraemos tokens\n",
        "    tokens = norm_text.split()\n",
        "\n",
        "    # Filtramos palabras por longitud\n",
        "    filtered_tokens = filter(\n",
        "            lambda token: len(token) >= min_len and len(token) <= max_len,\n",
        "            tokens\n",
        "        )\n",
        "    filtered_text = \" \".join(filtered_tokens)\n",
        "    # Eliminamos caracteres especiales\n",
        "    clean_text = re.sub(pat, \"\", filtered_text)\n",
        "    # Eliminamos espacios duplicados\n",
        "    spaces_text = re.sub(spaces, \" \", clean_text)\n",
        "    return spaces_text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b0f1128",
      "metadata": {
        "id": "4b0f1128"
      },
      "source": [
        "Obtenemos el corpus preprocesado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c1981b",
      "metadata": {
        "id": "06c1981b"
      },
      "outputs": [],
      "source": [
        "corpus_prep = list(map(preprocess, corpus))\n",
        "display(corpus_prep)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a836de8",
      "metadata": {
        "id": "9a836de8"
      },
      "source": [
        "Finalmente, calculamos una representación de 3-grams a nivel de palabra:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15756294",
      "metadata": {
        "id": "15756294"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer(\n",
        "        ngram_range = (3, 3),\n",
        "        analyzer = \"word\"\n",
        "        )\n",
        "counts = np.array(vect.fit_transform(corpus_prep).sum(axis=0)).flatten()\n",
        "display(counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb7a5b29",
      "metadata": {
        "id": "cb7a5b29"
      },
      "source": [
        "También, extraemos una lista de todos los 3-grams encontrados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acdc849",
      "metadata": {
        "id": "5acdc849"
      },
      "outputs": [],
      "source": [
        "grams = list(\n",
        "        map(\n",
        "            lambda i: i.split(\" \"),\n",
        "            vect.get_feature_names_out()\n",
        "            )\n",
        "        )\n",
        "display(grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b066a57b",
      "metadata": {
        "id": "b066a57b"
      },
      "source": [
        "Como puede ver, tenemos secuencias de 3 palabras y el conteo de cada secuencia, podemos construir un `DataFrame` con esta información y los conteos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627e523a",
      "metadata": {
        "id": "627e523a"
      },
      "outputs": [],
      "source": [
        "grams_df = pd.DataFrame(\n",
        "        grams, columns=[f\"t{i}\" for i in range(1, 4)]\n",
        "        ).assign(counts=counts)\n",
        "display(grams_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4ae475",
      "metadata": {
        "id": "2e4ae475"
      },
      "source": [
        "En este caso, podemos autocompletar tomando secuencias de dos tokens (tenemos 3-grams), veamos un ejemplo con la siguiente secuencia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e05ccc90",
      "metadata": {
        "id": "e05ccc90"
      },
      "outputs": [],
      "source": [
        "sent = [\"accused\", \"of\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92983c3c",
      "metadata": {
        "id": "92983c3c"
      },
      "source": [
        "Puede probar otros ejemplos de autocompletado con las siguientes secuencias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da396e4",
      "metadata": {
        "id": "6da396e4"
      },
      "outputs": [],
      "source": [
        "# sent = [\"accompanied\",\"by\"]\n",
        "# sent = [\"about\", \"to\"]\n",
        "# sent = [\"about\", \"the\"]\n",
        "# sent = [\"be\", \"an\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320bde2d",
      "metadata": {
        "id": "320bde2d"
      },
      "source": [
        "Vamos a filtrar todos los trigramas donde los primeros dos términos coinciden con la secuencia que deseamos autocompletar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7caf4311",
      "metadata": {
        "id": "7caf4311"
      },
      "outputs": [],
      "source": [
        "valid_grams = grams_df.query(\"t1 == @sent[0] and t2 == @sent[1]\")\n",
        "display(valid_grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e469a9",
      "metadata": {
        "id": "04e469a9"
      },
      "source": [
        "Como podemos ver, en la columna `\"t3\"` tenemos las posibles palabras que ocurren en el corpus luego de `\"accused of\"`, podemos normalizar estos valores para que sean probabilidades válidas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522dfb6d",
      "metadata": {
        "id": "522dfb6d"
      },
      "outputs": [],
      "source": [
        "valid_grams = valid_grams.assign(\n",
        "        prob = valid_grams.counts / valid_grams.counts.sum()\n",
        "        )\n",
        "display(valid_grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2da0066f",
      "metadata": {
        "id": "2da0066f"
      },
      "source": [
        "Podemos ver las probabilidades como un diagrama de barras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d956ec8",
      "metadata": {
        "id": "7d956ec8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.bar(valid_grams.t3, valid_grams.prob)\n",
        "ax.set_xlabel(\"$t_3$\")\n",
        "ax.set_ylabel(\"$P(t_3 | t_1, t_2)$\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f09cf447",
      "metadata": {
        "id": "f09cf447"
      },
      "source": [
        "Finalmente, podemos generar la palabra autocompletada como el término con mayor probabilidad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb947fd",
      "metadata": {
        "id": "1cb947fd"
      },
      "outputs": [],
      "source": [
        "word = valid_grams.iloc[valid_grams.prob.argmax()].t3\n",
        "display(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87cae6b",
      "metadata": {
        "id": "e87cae6b"
      },
      "source": [
        "### **3.2. Modelos Generativos**\n",
        "---\n",
        "\n",
        "La generación automática de texto a partir del modelo probabilístico de N-grams utiliza las probabilidades condicionales que vimos anteriormente y técnicas de generación de números aleatorios. En este caso, utilizaremos el generador de números aleatorios de `numpy` para generar palabras de forma iterativa.\n",
        "\n",
        "Podemos generar automáticamente secuencias de caracteres, de acuerdo a la siguiente ecuación:\n",
        "\n",
        "$$\n",
        "t_{i+2} \\sim P(t_{i+2} | t_{i+1}, t_{i})\n",
        "$$\n",
        "\n",
        "Donde $t_{i + 2}$ es un token generado a partir de la secuencia $t_i, ~t_{i + 1}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d81ead5a",
      "metadata": {
        "cellView": "form",
        "id": "d81ead5a"
      },
      "outputs": [],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/1XTEbe7WElxWfaVouuNXZSUtvBhljzCY6/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f504ef88",
      "metadata": {
        "id": "f504ef88"
      },
      "source": [
        "Veamos un ejemplo de texto generado usando el modelo de trigramas que teníamos definido, para ello, comenzaremos con una secuencia de dos palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ab3e25",
      "metadata": {
        "id": "53ab3e25"
      },
      "outputs": [],
      "source": [
        "seq = [\"about\", \"to\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d058576c",
      "metadata": {
        "id": "d058576c"
      },
      "source": [
        "También definimos un número de palabras a generar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a20f8af",
      "metadata": {
        "id": "9a20f8af"
      },
      "outputs": [],
      "source": [
        "N = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9f80e24",
      "metadata": {
        "id": "d9f80e24"
      },
      "source": [
        "Iterativamente calculamos probabilidades y generamos nuevas palabras:\n",
        "\n",
        "> **Nota**: puede ejecutar el siguiente código varias veces y en cada una el resultado será distinto, ya que es un modelo generativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3b753a5",
      "metadata": {
        "id": "e3b753a5"
      },
      "outputs": [],
      "source": [
        "for i in range(N):\n",
        "    sent = seq[-2:] # seleccionamos las últimas 2 palabras.\n",
        "    probs = (\n",
        "            grams_df\n",
        "            .query(\"t1 == @sent[0] and t2 == @sent[1]\") # filtramos coincidencias\n",
        "            .assign(prob = lambda df: df.counts / df.counts.sum()) # calculamos las probabilidades\n",
        "            .filter([\"t3\", \"prob\"]) # filtramos las columnas en cuestión\n",
        "            )\n",
        "    if probs.shape[0] == 0: # cuando un n-gram no está en el vocabulario\n",
        "        probs = (\n",
        "                grams_df\n",
        "                .query(\"t1 == 'this' and t2 == 'is'\") # completamos con un 2-gram muy común\n",
        "                .assign(prob = lambda df: df.counts / df.counts.sum())\n",
        "                .filter([\"t3\", \"prob\"])\n",
        "                )\n",
        "    word = np.random.choice(probs.t3, p=probs.prob) # seleccionamos una palabra\n",
        "    seq.append(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88da8191",
      "metadata": {
        "id": "88da8191"
      },
      "source": [
        "Veamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99269fc",
      "metadata": {
        "id": "e99269fc"
      },
      "outputs": [],
      "source": [
        "display(\" \".join(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379212c0",
      "metadata": {
        "id": "379212c0"
      },
      "source": [
        "En este caso, obtuvimos un texto que sigue reglas del lenguaje, pero no tiene mucha coherencia. Esto es un problema típico en las representaciones de N-grams y se conoce como el problema de la memoria a corto plazo, la representación de trigramas que estamos usando únicamente considera las últimas dos palabras para generar una tercera, es decir, el modelo olvida por completo dependencias a largo plazo con otras palabras.\n",
        "\n",
        "Hoy en día se suelen usar modelos de redes neuronales (como redes recurrentes o transformers) que solucionan el problema de la memoria a corto plazo. Este tipo de modelos se estudiarán en el módulo de _Deep Learning_."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b04e3009",
      "metadata": {
        "id": "b04e3009"
      },
      "source": [
        "## **4. Entendimiento de Idiomas**\n",
        "---\n",
        "\n",
        "Una de las aplicaciones típicas de los N-grams es para el entendimiento de idiomas, por ejemplo, si hacemos un análisis de los n-grams más comunes entre distintos idiomas podemos llegar a identificar diferencias entre los mismos. También podemos llegar a entrenar un modelo de clasificación a partir de los N-grams para una clasificación automática de idiomas (como lo veremos en la siguiente unidad).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KkPaATcdr_XPVEbxppaE4DNAJ-S37TK3\" width=\"100%\">\n",
        "\n",
        "Veamos un ejemplo con el conjunto de datos [Language Detection de Kaggle](https://www.kaggle.com/datasets/basilb2s/language-detection):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc2054b",
      "metadata": {
        "id": "4fc2054b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u3/language.csv\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2cee80",
      "metadata": {
        "id": "fe2cee80"
      },
      "source": [
        "Creamos una columna con el texto preprocesado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eebf3b7",
      "metadata": {
        "id": "6eebf3b7"
      },
      "outputs": [],
      "source": [
        "data = data.assign(\n",
        "        text_prep = lambda df: df.text.apply(preprocess)\n",
        "        )\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51b5be4e",
      "metadata": {
        "id": "51b5be4e"
      },
      "source": [
        "Vamos a calcular desde 2-grams hasta 4-grams de carácteres en los textos con el `CountVectorizer` para los textos en español:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b388cf09",
      "metadata": {
        "id": "b388cf09"
      },
      "outputs": [],
      "source": [
        "data_spa = (\n",
        "        data\n",
        "        .query(\"language == 'Spanish'\")\n",
        "        .text_prep\n",
        "        )\n",
        "\n",
        "vect_spa = CountVectorizer(\n",
        "        ngram_range=(2, 4),\n",
        "        analyzer=\"char\"\n",
        "        ).fit(data_spa)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64e71a45",
      "metadata": {
        "id": "64e71a45"
      },
      "source": [
        "Extraemos la representación de N-grams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f1ed5a",
      "metadata": {
        "id": "00f1ed5a"
      },
      "outputs": [],
      "source": [
        "counts = np.array(vect_spa.transform(data_spa).sum(axis=0)).flatten()\n",
        "vocab = vect_spa.get_feature_names_out()\n",
        "counts_spa = {word: count for word, count in zip(vocab, counts)}\n",
        "display(counts_spa)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da678725",
      "metadata": {
        "id": "da678725"
      },
      "source": [
        "Ahora, repetimos el mismo proceso para textos en árabe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6004899a",
      "metadata": {
        "id": "6004899a"
      },
      "outputs": [],
      "source": [
        "data_ara = (\n",
        "        data\n",
        "        .query(\"language == 'Arabic'\")\n",
        "        .text_prep\n",
        "        )\n",
        "\n",
        "vect_ara = CountVectorizer(\n",
        "        ngram_range=(2, 4),\n",
        "        analyzer=\"char\"\n",
        "        ).fit(data_ara)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cc1a90",
      "metadata": {
        "id": "d6cc1a90"
      },
      "source": [
        "Extraemos la representación de N-grams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506e6b4b",
      "metadata": {
        "id": "506e6b4b"
      },
      "outputs": [],
      "source": [
        "counts = np.array(vect_ara.transform(data_ara).sum(axis=0)).flatten()\n",
        "vocab = vect_spa.get_feature_names_out()\n",
        "counts_ara = {word: count for word, count in zip(vocab, counts)}\n",
        "display(counts_ara)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06bb14ea",
      "metadata": {
        "id": "06bb14ea"
      },
      "source": [
        "Veamos una comparativa de ambos idiomas usando nubes de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae62cd7c",
      "metadata": {
        "id": "ae62cd7c"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e446c4",
      "metadata": {
        "id": "61e446c4"
      },
      "source": [
        "Importamos la librería:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3e2630",
      "metadata": {
        "id": "ae3e2630"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6eb7895",
      "metadata": {
        "id": "f6eb7895"
      },
      "source": [
        "Creamos las nubes de palabras para ambos idiomas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d019cde",
      "metadata": {
        "id": "5d019cde"
      },
      "outputs": [],
      "source": [
        "wc_spa = (\n",
        "        WordCloud(background_color=\"#FFFFFF\")\n",
        "        .generate_from_frequencies(counts_spa)\n",
        "        )\n",
        "wc_ara = (\n",
        "        WordCloud(background_color=\"#FFFFFF\")\n",
        "        .generate_from_frequencies(counts_ara)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c498dab",
      "metadata": {
        "id": "5c498dab"
      },
      "source": [
        "Finalmente, mostramos las dos nubes de palabras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2dcdcb8",
      "metadata": {
        "id": "a2dcdcb8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax[0].imshow(wc_spa)\n",
        "ax[0].axis(\"off\")\n",
        "ax[0].set_title(\"Español\")\n",
        "\n",
        "ax[1].imshow(wc_ara)\n",
        "ax[1].axis(\"off\")\n",
        "ax[1].set_title(\"Árabe\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e4a58ee",
      "metadata": {
        "id": "2e4a58ee"
      },
      "source": [
        "Como se puede observar, en español predominan palabras de una única letra como `\"a\"`, `\"e\"`, `\"o\"` mientras que en árabe tenemos más 4-grams como `\"tund\"`, `\"humi\"` o `\"acas\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabddd3e",
      "metadata": {
        "id": "fabddd3e"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [Language model](https://en.wikipedia.org/wiki/Language_model).\n",
        "- [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "- [N-grams](https://es.wikipedia.org/wiki/N-grama).\n",
        "- _Fuente de los íconos_\n",
        "    - Flaticon. Scrabble free icon [PNG]. https://www.flaticon.com/free-icon/scrabble_3367498\n",
        "    - Flaticon. Icon Pack: A to Z Capital Letter | Flat [Pack Icon - PNG]. https://www.flaticon.com/packs/a-to-z-capital-letter-1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98267cd",
      "metadata": {
        "id": "a98267cd"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}