{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/taller5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790ab065",
      "metadata": {
        "id": "790ab065"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1WNLKH10YpQNNk9eeRIyYLwGkxNbNp-Mm\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d6e5aa1",
      "metadata": {
        "id": "3d6e5aa1"
      },
      "source": [
        "# **Taller 5**\n",
        "---\n",
        "\n",
        "En este taller se evaluarán los conocimientos adquiridos en análisis no supervisado de textos con modelos de agrupamiento y de tópicos. Para esto, usaremos un conjunto de datos de poemas en español.\n",
        "\n",
        "Comenzaremos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb759b98",
      "metadata": {
        "id": "eb759b98",
        "outputId": "146bc350-d40b-48a3-b3f4-dc34acbc6a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "#TEST_CELL\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f60a493",
      "metadata": {
        "id": "1f60a493"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "from IPython.display import display\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b12bf9",
      "metadata": {
        "id": "a1b12bf9"
      },
      "source": [
        "Ahora cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37e6bad",
      "metadata": {
        "id": "c37e6bad"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "data = (\n",
        "        pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u5/poems.parquet\")\n",
        "        .dropna()\n",
        "        )\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12edc382",
      "metadata": {
        "id": "12edc382"
      },
      "source": [
        "Como podemos ver, el conjunto tiene columnas:\n",
        "\n",
        "- `author`: Nombre del autor del poema.\n",
        "- `content`: Texto el poema.\n",
        "- `title`: Título del poema.\n",
        "\n",
        "Vamos a preprocesar el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c199c41",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5c199c41"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"es\")\n",
        "def preprocess(text):\n",
        "    doc = nlp(text) # creamos un documento de spacy\n",
        "    no_stops = \" \".join(\n",
        "        token.text\n",
        "        for token in filter(\n",
        "            lambda token: not token.is_stop and len(token) > 3 and len(token) < 24,\n",
        "            doc,\n",
        "            )\n",
        "        ) # eliminamos stopwords y palabras por longitud\n",
        "    norm_text = unidecode(no_stops.lower()) # normalizamos el texto\n",
        "    no_chars = re.sub(r\"[^a-z ]\", \" \", norm_text) # eliminamos caracteres especiales\n",
        "    no_spaces = re.sub(r\"\\s+\", \" \", no_chars) # eliminamos espacios duplicados\n",
        "    striped_text = no_spaces.strip()\n",
        "    if not len(striped_text):\n",
        "        return None\n",
        "    else:\n",
        "        return striped_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f4bb87",
      "metadata": {
        "id": "94f4bb87"
      },
      "source": [
        "Aplicamos la función de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9816cad2",
      "metadata": {
        "id": "9816cad2"
      },
      "outputs": [],
      "source": [
        "data = (\n",
        "        data\n",
        "        .assign(\n",
        "            corpus=data.content.apply(preprocess)\n",
        "            )\n",
        "        .dropna()\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e01bf3",
      "metadata": {
        "id": "c6e01bf3"
      },
      "source": [
        "Inspeccionemos el tamaño de este conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0643cb04",
      "metadata": {
        "id": "0643cb04"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ea2889b",
      "metadata": {
        "id": "4ea2889b"
      },
      "source": [
        "## **1. Extracción de Características**\n",
        "---\n",
        "\n",
        "En este punto deberá codificar de forma numérica el corpus. Para ello, deberá entrenar un vectorizador TF-IDF con sublinear scaling que permita extraer únicamente los términos que aparecen por lo menos en el 0.5% de los documentos en el corpus.\n",
        "\n",
        "Para esto, deberá implementar la función `vectorizer` la cual recibirá el corpus preprocesado y deberá retornar un arreglo de `numpy` con la representación y el vectorizador.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `corpus`: `pd.Series` con los textos preprocesados del conjunto de datos.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `features`: arreglo de numpy con la representación de tipo TF-IDF.\n",
        "- `vect`: `TfidfVectorizer` entrenado con las especificaciones dadas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e444d68",
      "metadata": {
        "id": "1e444d68"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que _sublinear scaling_ se puede controlar con el parámetro `sublinear_tf` del vectorizador.\n",
        "- Recuerde convertir la representación a un arreglo de `numpy`.\n",
        "- Puede usar el parámetro `min_df` para filtrar términos por frecuencia de documento.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46959ae",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f46959ae"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA vectorizer:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def vectorizer(corpus):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    vect = ...\n",
        "    features = ...\n",
        "    return features, vect\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5391f55d",
      "metadata": {
        "id": "5391f55d"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c109185",
      "metadata": {
        "id": "9c109185"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el tamaño de la representación:\n",
        "\n",
        "```python\n",
        "❱ display(features.shape)\n",
        "(5125, 2232)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba9caac7",
      "metadata": {
        "id": "ba9caac7"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(vect.get_feature_names_out()[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15176e70",
      "metadata": {
        "id": "15176e70"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las primeras 5 palabras del vocabulario:\n",
        "\n",
        "```python\n",
        "❱ display(vect.get_feature_names_out()[:5])\n",
        "array(['abajo', 'abandonado', 'abandono', 'abeja', 'abejas'], dtype=object)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb5ae8d",
      "metadata": {
        "id": "0cb5ae8d"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "display(features.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb9d89ab",
      "metadata": {
        "id": "bb9d89ab"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener la suma de toda la matriz:\n",
        "\n",
        "```python\n",
        "❱ display(features.sum())\n",
        "26109.80862778348\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca39f732",
      "metadata": {
        "id": "ca39f732"
      },
      "source": [
        "## **2. Modelo de Agrupamiento**\n",
        "---\n",
        "\n",
        "En este punto deberá entrenar un modelo de K-Means y evaluar el coeficiente de silueta para un número específico de clusters $K$.\n",
        "\n",
        "Para esto, deberá implementar la función `clustering`, la cual recibirá una matriz de características y deberá retornar el modelo entrenado y el valor del coeficiente de silueta.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features`: arreglo de `numpy` con las características de los textos.\n",
        "- `n_clusters`: número de clusters a usar.\n",
        "- `seed`: semilla de números aleatorios.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `model`: modelo de K-Means entrenado.\n",
        "- `score`: valor del coeficiente de silueta."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa221d0",
      "metadata": {
        "id": "efa221d0"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede controlar el número de clusters con el parámetro `n_clusters`.\n",
        "- Recuerde que el coeficiente de silueta no necesita ninguna etiqueta, la función recibe las características y las predicciones del modelo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8d53e6",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "6c8d53e6"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA clustering:\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "def clustering(features, n_clusters, seed):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    model = ...\n",
        "    score = ...\n",
        "    return model, score\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57cb13a5",
      "metadata": {
        "id": "57cb13a5"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model, score = clustering(\n",
        "        features=features,\n",
        "        n_clusters=5,\n",
        "        seed=0\n",
        "        )\n",
        "display(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dabc873",
      "metadata": {
        "id": "7dabc873"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "El coeficiente de silueta debería dar un resultado igual a:\n",
        "\n",
        "```python\n",
        "❱ display(score)\n",
        "0.0011509503589058696\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecdbe61a",
      "metadata": {
        "id": "ecdbe61a"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model, score = clustering(\n",
        "        features=features,\n",
        "        n_clusters=10,\n",
        "        seed=0\n",
        "        )\n",
        "display(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f57849a",
      "metadata": {
        "id": "1f57849a"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "El coeficiente de silueta debería dar un resultado igual a:\n",
        "\n",
        "```python\n",
        "❱ display(score)\n",
        "0.0024804861748867956\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2014a38",
      "metadata": {
        "id": "d2014a38"
      },
      "source": [
        "## **3. Documento Más Relevante**\n",
        "---\n",
        "\n",
        "En este punto deberá encontrar el documento más similar a un cluster en específico. El proceso debe seguir los siguientes pasos:\n",
        "\n",
        "1. Calcular la similitud coseno entre las características de cada documento y el centroide de un cluster dado.\n",
        "2. Encontrar el id del documento con mayor similitud coseno.\n",
        "3. Extraer el documento del corpus.\n",
        "\n",
        "Para esto deberá implementar la función `cluster_document`, la cual toma como entrada el corpus, las características, un modelo entrenado y el id de un cluster. Esta función debe retornar el texto del documento más relevante.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `corpus`: `pd.Series` con el texto preprocesado.\n",
        "- `features`: arreglo de `numpy` con las características de los textos.\n",
        "- `model`: modelo de K-Means entrenado.\n",
        "- `cluster_id`: identificador del cluster a analizar.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `relevant_doc`: documento más relevante para el cluster en cuestión."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5ca7f6",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "4b5ca7f6"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede acceder a los centroides del modelo K-Means con el atributo `cluster_centers_` del modelo entrenado.\n",
        "- Puede usar la función `np.argmax` para encontrar el documento más similar.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7954c31c",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "7954c31c"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA cluster_document:\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def cluster_document(corpus, features, model, cluster_id):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    relevant_doc = ...\n",
        "    return relevant_doc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1865829b",
      "metadata": {
        "id": "1865829b"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = clustering(features, 25, 0)[0]\n",
        "relevant_doc = cluster_document(data.content, features, model, 0)\n",
        "print(relevant_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546f8198",
      "metadata": {
        "id": "546f8198"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este primer ejemplo debería retornar el documento más relevante para el cluster 0.\n",
        "\n",
        "```python\n",
        "❱ print(relevant_doc)\n",
        "Cien sonetos de amor\n",
        "\n",
        "«Vendrás conmigo» ?dije? sin que nadie supiera\n",
        "dónde y cómo latía mi estado doloroso,\n",
        "y para mí no había clavel ni barcarola,\n",
        "nada sino una herida por el amor abierta.\n",
        "Repetí: ven conmigo, como si me muriera,\n",
        "y nadie vio en mi boca la luna que sangraba,\n",
        "nadie vio aquella sangre que subía al silencio.\n",
        "Oh amor ahora olvidemos la estrella con espinas!\n",
        "Por eso cuando oí que tu voz repetía\n",
        "«Vendrás conmigo» ?fue como si desataras\n",
        "dolor, amor, la furia del vino encarcelado\n",
        "que desde su bodega sumergida subiera\n",
        "y otra vez en mi boca sentí un sabor de llama,\n",
        "de sangre y de claveles, de piedra y quemadura.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349ae5eb",
      "metadata": {
        "id": "349ae5eb"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = clustering(features, 25, 0)[0]\n",
        "relevant_doc = cluster_document(data.content, features, model, 2)\n",
        "print(relevant_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce12824b",
      "metadata": {
        "id": "ce12824b"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este segundo ejemplo debería retornar el documento más relevante para el cluster 2.\n",
        "\n",
        "```python\n",
        "❱ print(relevant_doc)\n",
        "\n",
        "Eres uno con Dios, porque le amas.\n",
        "¡Tu pequeñez qué importa y tu miseria,\n",
        "eres uno con Dios, porque le amas!\n",
        "Le buscaste en los libros,\n",
        "le buscaste en los templos,\n",
        "le buscaste en los astros,\n",
        "y un día el corazón te dijo, trémulo:\n",
        "«aquí está», y desde entonces ya sois uno,\n",
        "ya sois uno los dos, porque le amas.\n",
        "No podrían separaros\n",
        "ni el placer de la vida\n",
        "ni el dolor de la muerte.\n",
        "En el placer has de mirar su rostro,\n",
        "en el dolor has de mirar su rostro,\n",
        "en vida y muerte has de mirar su rostro.\n",
        "«¡Dios!» dirás en los besos,\n",
        "dirás «Dios» en los cantos,\n",
        "dirás «¡Dios!» en los ayes.\n",
        "Y comprendiendo al fin que es ilusorio\n",
        "todo pecado (como toda vida),\n",
        "y que nada de Él puede separarte,\n",
        "uno con Dios te sentirás por siempre:\n",
        "uno solo con Dios, porque le amas.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a57278",
      "metadata": {
        "id": "e2a57278"
      },
      "source": [
        "## **4. Modelo de Tópicos**\n",
        "---\n",
        "\n",
        "En este punto deberá entrenar un modelo de *Latent Semantic Analysis* sobre el corpus de poemas.\n",
        "\n",
        "Para esto deberá implementar la función `topic_model`, la cual toma como entrada las características del texto y el número de tópicos. Esta deberá retornar el modelo entrenado.\n",
        "\n",
        "**Nota**: debe utilizar el algoritmo `arpack` en `TruncatedSVD` para que los resultados sean consistentes, es decir, `algorithm=\"arpack\"` como argumento del modelo.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features`: arreglo de `numpy` con las características de los textos.\n",
        "- `n_components`: número de tópicos.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `model`: modelo de tópicos entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab30421",
      "metadata": {
        "id": "8ab30421"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde especificar el algorithmo de optimización, de lo contrario los resultados pueden ser variables.\n",
        "- Puede especificar el número de tópicos con el parámetro `n_components` del modelo.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162a8d62",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "162a8d62"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA topic_model:\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def topic_model(features, n_components):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    model = ...\n",
        "    return model\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1abfb1",
      "metadata": {
        "id": "2b1abfb1"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = topic_model(features, 10)\n",
        "display(model.components_[:5, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27b80d40",
      "metadata": {
        "id": "27b80d40"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este ejemplo debería mostrar las primeras 5 filas y las primeras 5 columnas de la matriz tópico-término.\n",
        "\n",
        "```python\n",
        "❱ print(model.components_[:5, :5])\n",
        "array([[ 0.02037573,  0.01055891,  0.01040283,  0.00990592,  0.00902456],\n",
        "       [-0.01477555, -0.00338276, -0.00075354, -0.01209799, -0.00512086],\n",
        "       [-0.02064902, -0.01047121, -0.01311938,  0.01244566,  0.00910363],\n",
        "       [-0.0211558 ,  0.00615672,  0.01806387, -0.00759171, -0.00587832],\n",
        "       [ 0.01138   ,  0.00010993, -0.01209617, -0.00322183,  0.00915466]])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e7245d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "21e7245d"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = topic_model(features, 2)\n",
        "display(model.components_[:, :5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bde89091",
      "metadata": {
        "id": "bde89091"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este ejemplo debería mostrar las primeras las primeras 5 columnas de la matriz tópico-término.\n",
        "\n",
        "```python\n",
        "❱ display(model.components_[:5])\n",
        "array([[ 0.02037573,  0.01055891,  0.01040283,  0.00990592,  0.00902456],\n",
        "       [-0.01477555, -0.00338276, -0.00075354, -0.01209799, -0.00512086]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef2cc1c",
      "metadata": {
        "id": "6ef2cc1c"
      },
      "source": [
        "## **5. Documento Más Relevante**\n",
        "---\n",
        "\n",
        "En este punto deberá extraer el documento más relevante de un tópico específico. El proceso debe seguir los siguientes pasos:\n",
        "\n",
        "1. Extraer la matriz documento-tópico y sacar su valor absoluto.\n",
        "2. Extraer la columna correspondiente al identificador de un tópico dado.\n",
        "3. Encontrar el identificador del documento con mayor valor dentro de la columna del tópico.\n",
        "4. Retornar el texto del documento correspondiente.\n",
        "\n",
        "Para ello deberá implementar la función `topic_document`, la cual toma como entrada las características de los textos, el corpus, el modelo entrenado y un identificador de tópico y debe retornar el documento más relevante para dicho tópico.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `features`: arreglo de `numpy` con las características de los textos.\n",
        "- `corpus`: `pd.Series` con los documentos.\n",
        "- `model`: modelo de tópicos entrenado.\n",
        "- `topic_id`: identificador del tópico.\n",
        "\n",
        "**Retorna**:\n",
        "\n",
        "- `relevant_doc`: documento relevante para el tópico en cuestión."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ec6610",
      "metadata": {
        "id": "47ec6610"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- La matriz documento-tópico se puede extraer con el método `transform` del modelo.\n",
        "- Puede usar la función `np.argmax` para encontrar el documento más relevante en un tópico.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0209be64",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "0209be64"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA topic_document:\n",
        "def topic_document(features, corpus, model, topic_id):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    relevant_doc = ...\n",
        "    return relevant_doc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2dacc25",
      "metadata": {
        "id": "e2dacc25"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = topic_model(features, 10)\n",
        "relevant_doc = topic_document(features, data.content, model, 1)\n",
        "print(relevant_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abbb2f2f",
      "metadata": {
        "id": "abbb2f2f"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este ejemplo debería mostrar el poema más relacionado al tópico 1:\n",
        "\n",
        "```python\n",
        "❱ print(relevant_doc)\n",
        "Dios mío, yo te ofrezco mi dolor:\n",
        "¡Es todo lo que puedo ya ofrecerte!\n",
        "Tú me diste un amor, un solo amor,\n",
        "¡un gran amor!\n",
        "Me lo robó la muerte\n",
        "...y no me queda más que mi dolor.\n",
        "Acéptalo, Señor:\n",
        "¡Es todo lo que puedo ya ofrecerte!...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd4e6a7",
      "metadata": {
        "id": "0fd4e6a7"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "features, vect = vectorizer(data.corpus)\n",
        "model = topic_model(features, 10)\n",
        "relevant_doc = topic_document(features, data.content, model, 2)\n",
        "print(relevant_doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2db10727",
      "metadata": {
        "id": "2db10727"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "Este ejemplo debería mostrar el poema más relacionado al tópico 2:\n",
        "\n",
        "```python\n",
        "❱ print(relevant_doc)\n",
        "Cien sonetos de amor\n",
        "\n",
        "Mi fea, eres una castaña despeinada,\n",
        "mi bella, eres hermosa como el viento,\n",
        "mi fea, de tu boca se pueden hacer dos,\n",
        "mi bella, son tus besos frescos como sandías.\n",
        "Mi fea, dónde están escondidos tus senos?\n",
        "Son mínimos como dos copas de trigo.\n",
        "Me gustaría verte dos lunas en el pecho:\n",
        "las gigantescas torres de tu soberanía.\n",
        "Mi fea, el mar no tiene tus uñas en su tienda,\n",
        "mi bella, flor a flor, estrella por estrella,\n",
        "ola por ola, amor, he contado tu cuerpo:\n",
        "mi fea, te amo por tu cintura de oro,\n",
        "mi bella, te amo por una arruga en tu frente,\n",
        "amor, te amo por clara y por oscura.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4b4659c",
      "metadata": {
        "id": "f4b4659c"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}