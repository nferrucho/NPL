{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo3/taller3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "539db62a",
      "metadata": {
        "id": "539db62a"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1e7ctPi8O3bTQoLZaO9ZZjwGr2r8Z93RS\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c020a89a",
      "metadata": {
        "id": "c020a89a"
      },
      "source": [
        "# Taller 3\n",
        "---\n",
        "\n",
        "En este taller se evaluarán las habilidades adquiridas en _embeddings_ a partir del conjunto de datos de Kaggle: [Tweets from El Espectador](https://www.kaggle.com/datasets/jcatumba/tweetsfromelespectador), el cual contiene tweets del periódico colombiano [El Espectador](https://www.elespectador.com/).\n",
        "\n",
        "En este caso, usted deberá limpiar el conjunto de datos, calcular algunas representaciones, estimar algunas métricas y generar visualizaciones de los datos. Comenzamos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d92898",
      "metadata": {
        "id": "07d92898"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbeb6dc2",
      "metadata": {
        "id": "dbeb6dc2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Counter\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from unidecode import unidecode\n",
        "from IPython.display import display\n",
        "plt.style.use(\"ggplot\")\n",
        "spacy.cli.download(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df04cd31",
      "metadata": {
        "id": "df04cd31"
      },
      "source": [
        "Comenzamos cargando el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54af95be",
      "metadata": {
        "id": "54af95be"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "df = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u3/espectador.parquet\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b5c2507",
      "metadata": {
        "id": "4b5c2507"
      },
      "source": [
        "Este conjunto de datos contiene dos columnas:\n",
        "\n",
        "- `text`: texto del Tweet.\n",
        "- `year`: año de publicación.\n",
        "\n",
        "Este corpus está conformado por `9000` documentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c92bb4",
      "metadata": {
        "id": "f0c92bb4"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c2c7b7",
      "metadata": {
        "id": "15c2c7b7"
      },
      "source": [
        "## **1. Preprocesamiento**\n",
        "---\n",
        "\n",
        "En este punto deberá preprocesar los documentos de acuerdo al siguiente procedimiento:\n",
        "\n",
        "1. Convertir en minúsculas.\n",
        "2. Eliminar acentos.\n",
        "3. Eliminar todos los caracteres que no sean letras minúsculas.\n",
        "4. Eliminar espacios duplicados.\n",
        "5. Filtrar stopwords y palabras de 3 o menos letras.\n",
        "6. Eliminar caracteres vacíos al inicio y final de cada texto.\n",
        "\n",
        "Puede usar el siguiente _Pipeline_ de `spacy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c17aa7",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "42c17aa7"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\n",
        "        \"es_core_news_sm\",\n",
        "        exclude=[\n",
        "            \"tok2vec\",\n",
        "            \"morphologizer\",\n",
        "            \"parser\",\n",
        "            \"senter\",\n",
        "            \"attribute_ruler\",\n",
        "            \"lemmatizer\",\n",
        "            \"ner\"\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54b343d0",
      "metadata": {
        "id": "54b343d0"
      },
      "source": [
        "Para esto, deberá implementar la función `preprocess` la cual recibirá como entrada un texto crudo y un _Pipeline_ de `spacy` para retornar el texto preprocesado.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `text`: texto crudo.\n",
        "- `nlp`: _Pipeline_ de `spacy`.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `preprocess_text`: texto preprocesado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778fe6c1",
      "metadata": {
        "id": "778fe6c1"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede usar `unidecode` para eliminar acentos.\n",
        "- Debe construir expresiones regulares con `re` para eliminar caracteres especiales.\n",
        "- El _Pipeline_ de `spacy` debe usarse exclusivamente para eliminar _stopwords_.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "badfb3be",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "badfb3be"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA preprocess:\n",
        "\n",
        "def preprocess(text, nlp):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    preprocess_text = ...\n",
        "    return preprocess_text\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87cab00a",
      "metadata": {
        "id": "87cab00a"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "text = preprocess(df.text.iloc[0], nlp)\n",
        "display(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7dce34",
      "metadata": {
        "id": "bc7dce34"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el primer documento pre-procesado:\n",
        "\n",
        "```python\n",
        "❱ display(text)\n",
        "'feliz quedarse deportes extremos https usckq https eeqnt'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc773914",
      "metadata": {
        "id": "bc773914"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "text = preprocess(df.text.iloc[1], nlp)\n",
        "display(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea06683",
      "metadata": {
        "id": "0ea06683"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este primer ejemplo debe obtener el segundo documento pre-procesado:\n",
        "\n",
        "```python\n",
        "❱ display(text)\n",
        "'espectadorvideo novia caiman imagenes curiosas deja https lkqoijcuwu https gjyqxbhdib'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47da2ef6",
      "metadata": {
        "id": "47da2ef6"
      },
      "source": [
        "## **2. Bolsa de palabras**\n",
        "---\n",
        "\n",
        "En este punto deberá extraer una representación de bolsa de palabras basada en conteos. Esta representación debe usar únicamente los 2000 tokens más comunes del corpus.\n",
        "\n",
        "Para esto deberá implementar la función `bow`, la cual tiene como entrada el corpus preprocesado y deberá retornar un arreglo de `numpy` con los resultados:\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `preprocess_corpus`: corpus con los textos preprocesados.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `X`: representación de bolsa de palabras.\n",
        "- `vect`: vectorizador de `sklearn` entrenado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31fcda66",
      "metadata": {
        "id": "31fcda66"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde filtrar los 2000 términos más frecuentes con el parámetro `max_features`.\n",
        "- Recuerde convertir el resultado a un arreglo de `numpy` con el método `toarray`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddeb2cf6",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "ddeb2cf6"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA bow:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def bow(preprocess_corpus):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    vect = ...\n",
        "    X = ...\n",
        "    return X, vect\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4503ede0",
      "metadata": {
        "id": "4503ede0"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "display(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2337f158",
      "metadata": {
        "id": "2337f158"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso, debería obtener el tamaño del arreglo:\n",
        "\n",
        "```python\n",
        "❱ display(X.shape)\n",
        "(9000, 2000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b4e465",
      "metadata": {
        "id": "05b4e465"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(vect.get_feature_names_out()[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6df0b1",
      "metadata": {
        "id": "1a6df0b1"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso debería obtener las primeras 10 palabras del vocabulario:\n",
        "\n",
        "```python\n",
        "❱ display(vect.get_feature_names_out()[:10])\n",
        "array(['abogado', 'aborto', 'abre', 'abrio', 'abuso', 'acaba', 'acabar',\n",
        "       'academicos', 'acceder', 'acceso'], dtype=object)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45f47e0",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "d45f47e0"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "display(X.sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4e4bc3",
      "metadata": {
        "id": "5f4e4bc3"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener la cantidad total de términos incluidos en la bolsa de palabras:\n",
        "\n",
        "```python\n",
        "❱ display(X.sum())\n",
        "62281\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64633147",
      "metadata": {
        "id": "64633147"
      },
      "source": [
        "## **3. Términos Más Frecuentes**\n",
        "---\n",
        "\n",
        "En este punto deberá extraer los $N$ términos más frecuentes del conjunto de datos a partir de la bolsa de palabras y el vectorizador.\n",
        "\n",
        "Para esto deberá implementar la función `get_top_n`, la cual tiene como entrada la representación de bolsa de palabras, el vectorizador y el número top de términos, y deberá retornar una lista con los $N$ términos más frecuentes en el corpus.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `X`: representación de bolsa de palabras.\n",
        "- `vect`: vectorizador entrenado.\n",
        "- `n`: número de palabras a extraer.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `words`: listado de las $N$ palabras más frecuentes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1a786f1",
      "metadata": {
        "id": "b1a786f1"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede usar la función `sorted` de `Python` para ordenar términos de acuerdo a una condición.\n",
        "- Puede convertir los datos a un `pd.Series` y usar métodos como `sort_values`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204d0259",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "204d0259"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_top_n:\n",
        "\n",
        "def get_top_n(X, vect, n):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "\n",
        "    words = ...\n",
        "    return words\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f90ef982",
      "metadata": {
        "id": "f90ef982"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "words = get_top_n(X, vect, 5)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd3889d",
      "metadata": {
        "id": "4dd3889d"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 5 palabras más frecuentes del corpus:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['https', 'lomasleido', 'colombia', 'bogota', 'anos']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9819479",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "c9819479"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "words = get_top_n(X, vect, 10)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ed339a",
      "metadata": {
        "id": "65ed339a"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['https',\n",
        " 'lomasleido',\n",
        " 'colombia',\n",
        " 'bogota',\n",
        " 'anos',\n",
        " 'eecolombia',\n",
        " 'deportesee',\n",
        " 'covid',\n",
        " 'pais',\n",
        " 'presidente']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d9c7a1b",
      "metadata": {
        "id": "9d9c7a1b"
      },
      "source": [
        "## **4. Términos Más Frecuentes en un Año Específico**\n",
        "---\n",
        "\n",
        "En este punto deberá filtrar los $N$ términos más frecuentes de un año en específico a partir de la representación de bolsa de palabras, el vectorizador y una lista con el año de cada documento.\n",
        "\n",
        "Para esto deberá implementar la función `get_top_n_year`, la cual tiene como entrada la representación de bolsa de palabras, el vectorizador, el número top de términos, una lista con los años de cada documento y el año a filtrar. Deberá retornar una lista con los $N$ términos más frecuentes en el corpus.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `X`: representación de bolsa de palabras.\n",
        "- `vect`: vectorizador entrenado.\n",
        "- `n`: número de palabras a extraer.\n",
        "- `years`: lista del año de cada documento.\n",
        "- `year_query`: año sobre el que se debe filtrar.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `words`: lista con las palabras más frecuentes por año."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e671959",
      "metadata": {
        "id": "8e671959"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Tenga en cuenta que la lista `years` está alineada con la representación de bolsa de palabras `X`, es decir, el año en la posición 5 (`years[5]`) corresponde a la fila 5 de la representación (`X[5]`).\n",
        "- Puede usar la indexación basada en máscaras de `numpy` para seleccionar los casos correspondientes.\n",
        "- Puede reutilizar la función `get_top_n`, recuerde que la tarea es muy similar.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a369fc",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f4a369fc"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_top_n_year:\n",
        "\n",
        "def get_top_n_year(X, vect, n, years, year_query):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    words = ...\n",
        "    return words\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17b9d51",
      "metadata": {
        "id": "c17b9d51"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "years = df.year.to_list()\n",
        "words = get_top_n_year(X, vect, 10, years, 2019)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "932c94f6",
      "metadata": {
        "id": "932c94f6"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus en el año 2019:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['https',\n",
        " 'lomasleido',\n",
        " 'colombia',\n",
        " 'bogota',\n",
        " 'anos',\n",
        " 'deportesee',\n",
        " 'nacional',\n",
        " 'diciembre',\n",
        " 'gobierno',\n",
        " 'presidente']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367e5510",
      "metadata": {
        "id": "367e5510"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "years = df.year.to_list()\n",
        "words = get_top_n_year(X, vect, 10, years, 2020)\n",
        "display(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0310cd3",
      "metadata": {
        "id": "e0310cd3"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener las 10 palabras más frecuentes del corpus en el año 2020:\n",
        "\n",
        "```python\n",
        "❱ display(words)\n",
        "['https',\n",
        " 'eecolombia',\n",
        " 'colombia',\n",
        " 'anos',\n",
        " 'bogota',\n",
        " 'lomasleido',\n",
        " 'diciembre',\n",
        " 'deportesee',\n",
        " 'covid',\n",
        " 'pais']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b57692",
      "metadata": {
        "id": "41b57692"
      },
      "source": [
        "## **5. Nube de Palabras**\n",
        "---\n",
        "\n",
        "En este punto deberá generar una nube de palabras a partir de una representación de bolsa de palabras con un fondo de color blanco.\n",
        "\n",
        "Para ello, deberá implementar la función `get_wordcloud`, la cual tiene como entrada una representación de bolsa de palabras y un vectorizador y debe generar un objeto de tipo `WordCloud`.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `X`: representación de bolsa de palabras.\n",
        "- `vect`: vectorizador de `sklearn`.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `wc`: nube de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1abc798d",
      "metadata": {
        "id": "1abc798d"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Recuerde que puede usar el parámetro `background_color` para especificar el color del fondo de la imagen.\n",
        "- El método `generate_from_frequencies` permite generar la nube de palabras a partir de un diccionario donde las claves son las palabras y los valores son los conteos.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf48f5e",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "1bf48f5e"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_wordcloud:\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def get_wordcloud(X, vect):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    wc = ...\n",
        "    return wc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c66769",
      "metadata": {
        "id": "47c66769"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "wc = get_wordcloud(X, vect)\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(wc)\n",
        "ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2417d306",
      "metadata": {
        "id": "2417d306"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "En este caso deberá obtener una imagen similar a la siguiente:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MJg-wZhiupR_FAtV8Kz5jZAbhLE1bGNU\" width=\"80%\">\n",
        "\n",
        "**Nota**: el orden de las palabras puede variar un poco, pero el resultado debería ser equivalente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "738b2f3a",
      "metadata": {
        "id": "738b2f3a"
      },
      "source": [
        "## **6. Nube de Palabras Por Año**\n",
        "---\n",
        "\n",
        "En este punto deberá generar una nube de palabras a partir de una representación de bolsa de palabras para un año específico con un fondo de color blanco.\n",
        "\n",
        "Para ello, deberá implementar la función `get_wordcloud_year`, la cual tiene como entrada una representación de bolsa de palabras, un vectorizador, una lista de años y un año específico y debe generar un objeto de tipo `WordCloud`.\n",
        "\n",
        "**Parámetros**\n",
        "\n",
        "- `X`: representación de bolsa de palabras.\n",
        "- `vect`: vectorizador de `sklearn`.\n",
        "- `years`: lista de años por cada documento.\n",
        "- `year_query`: año a filtrar.\n",
        "\n",
        "**Retorna**\n",
        "\n",
        "- `wc`: nube de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f604905",
      "metadata": {
        "id": "5f604905"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pistas</b></font>\n",
        "</summary>\n",
        "\n",
        "- Puede reutilizar la función `get_wordcloud`, ya que las tareas son bastante similares.\n",
        "- Debe filtrar las filas de la representación de bolsa de palabras de la misma forma en la que realizó el punto 4.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c41ddeb",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "9c41ddeb"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA get_wordcloud:\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def get_wordcloud_year(X, vect, years, year):\n",
        "    ### ESCRIBA SU CÓDIGO AQUÍ ###\n",
        "    wc = ...\n",
        "    return wc\n",
        "    ### FIN DEL CÓDIGO ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2621ff56",
      "metadata": {
        "id": "2621ff56"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "preprocess_text = df.text.apply(preprocess, nlp=nlp)\n",
        "X, vect = bow(preprocess_text)\n",
        "years = df.year.to_list()\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 7))\n",
        "cats = [2019, 2020, 2021]\n",
        "for i, cat in enumerate(cats):\n",
        "    ax = axes[i]\n",
        "    wc = get_wordcloud_year(X, vect, years, cat)\n",
        "    ax.imshow(wc)\n",
        "    ax.set_title(cat)\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bf5be1",
      "metadata": {
        "id": "f1bf5be1"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "La celda anterior debería generar una imagen similar a la siguiente:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1bs1QdYriI7drISHJ5OlATKHxdiFyjWro\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2ed4f4",
      "metadata": {
        "id": "8a2ed4f4"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "title,-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}