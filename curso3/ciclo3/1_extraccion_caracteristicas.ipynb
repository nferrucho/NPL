{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso3/ciclo3/1_extraccion_caracteristicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fa8d8c",
      "metadata": {
        "id": "32fa8d8c"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=14reVO1X6LsjqJ3cFgoeHxxddZVGfZn3t\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19334586",
      "metadata": {
        "id": "19334586"
      },
      "source": [
        "# Extracción de Características\n",
        "---\n",
        "\n",
        "En este notebook veremos una aproximación práctica al enfoque de ingeniería de características desde _Python_. Veremos algunas herramientas que podemos utilizar para extraer características de distintos tipos de datos.\n",
        "\n",
        "Comenzamos instalando e importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7db3b562",
      "metadata": {
        "id": "7db3b562"
      },
      "outputs": [],
      "source": [
        "!apt install tree\n",
        "!pip install dvc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72762a10",
      "metadata": {
        "id": "72762a10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b86d7a9",
      "metadata": {
        "id": "1b86d7a9"
      },
      "source": [
        "## **1. Motivación**\n",
        "---\n",
        "\n",
        "La extracción de características en machine learning consiste en la transformación de datos crudos en representaciones numéricas más informativas y útiles para un algoritmo de aprendizaje automático. Esto se hace con el objetivo de mejorar la capacidad de un modelo para realizar una tarea determinada, como la clasificación o la regresión. La elección de las características adecuadas y su representación son cruciales para el éxito del modelo y pueden tener un impacto significativo en su precisión y rendimiento. Además, la extracción de características también puede ser útil para reducir la dimensionalidad de los datos y para eliminar características redundantes o irrelevantes.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1BtnrvfFspLnD1OE0STiTVwEwpEp9hCFW\" width=\"80%\">\n",
        "\n",
        "La extracción de características se realiza por varias razones, incluyendo:\n",
        "\n",
        "- **Mejora del rendimiento**: Al convertir los datos en una representación más informativa y relevante, se puede mejorar la capacidad del modelo para realizar una tarea determinada, lo que resulta en una mejora del rendimiento.\n",
        "- **Reducción de la dimensionalidad**: La extracción de características también puede ser útil para reducir la dimensionalidad de los datos, lo que puede mejorar el tiempo de entrenamiento y prevenir el sobreajuste.\n",
        "- **Eliminación de características irrelevantes o redundantes**: La extracción de características puede ayudar a eliminar características irrelevantes o redundantes, lo que puede mejorar la interpretabilidad y la eficiencia del modelo.\n",
        "- **Facilitación de la interpretabilidad**: Al convertir los datos en una representación más informativa y relevante, también se puede facilitar la interpretabilidad del modelo y su capacidad para hacer inferencias.\n",
        "\n",
        "La extracción de características varía en dependencia del tipo de datos que estemos manejando. Veamos un ejemplo con distintas herramientas especializadas y `dvc`, comenzamos creando una carpeta donde tendremos el repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c857e24",
      "metadata": {
        "id": "1c857e24"
      },
      "outputs": [],
      "source": [
        "!mkdir features\n",
        "%cd features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b065468",
      "metadata": {
        "id": "2b065468"
      },
      "source": [
        "Ahora configuramos `git`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d3523c",
      "metadata": {
        "id": "a1d3523c"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"ejemplo@unal.edu.co\"\n",
        "!git config --global user.name \"Ejemplo\"\n",
        "!git config --global init.defaultBranch master"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cef164e",
      "metadata": {
        "id": "6cef164e"
      },
      "source": [
        "Inicializamos el repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5eff4da",
      "metadata": {
        "id": "b5eff4da"
      },
      "outputs": [],
      "source": [
        "!git init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0eeaf60",
      "metadata": {
        "id": "a0eeaf60"
      },
      "source": [
        "Ahora, vamos a crear un folder para almacenar datos crudos y modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "752c7ddb",
      "metadata": {
        "id": "752c7ddb"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data/raw data/features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1979fab4",
      "metadata": {
        "id": "1979fab4"
      },
      "source": [
        "Veamos la estructura de directorios que tenemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a37f24d2",
      "metadata": {
        "id": "a37f24d2"
      },
      "outputs": [],
      "source": [
        "!tree"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb4d38f",
      "metadata": {
        "id": "0fb4d38f"
      },
      "source": [
        "Inicializamos `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39cb6fc",
      "metadata": {
        "id": "c39cb6fc"
      },
      "outputs": [],
      "source": [
        "!dvc init"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fcbf4ac",
      "metadata": {
        "id": "4fcbf4ac"
      },
      "source": [
        "Creamos un commit con `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255aff41",
      "metadata": {
        "id": "255aff41"
      },
      "outputs": [],
      "source": [
        "!git add .dvc\n",
        "!git commit -m \"Inicializamos dvc\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a6a3f5e",
      "metadata": {
        "id": "6a6a3f5e"
      },
      "source": [
        "## **2. Imágenes**\n",
        "---\n",
        "\n",
        "La extracción de características en imágenes es un proceso en el aprendizaje automático y la visión por computadora donde se extraen y se representan características relevantes de imágenes para su posterior uso en tareas como clasificación, detección, segmentación, etc. Estas características pueden ser formas, texturas, colores, entre otros; su representación suele ser en forma de vectores numéricos. La elección de las características a extraer y cómo representarlas es importante para el rendimiento de la tarea.\n",
        "\n",
        "Vamos a descargar el conjunto de datos Olivetti Faces, el cual es un conjunto de imágenes de rostros humanos comúnmente utilizado en investigaciones en el campo de la visión por computadora y el aprendizaje automático. Contiene imágenes de 40 personas diferentes, cada una de ellas tomada en 4 posiciones diferentes y en 64x64 píxeles. Cada imagen está representada en escala de grises y está normalizada para tener una iluminación uniforme.\n",
        "\n",
        "Este conjunto de datos se utiliza comúnmente para evaluar técnicas de extracción de características faciales y para comparar diferentes algoritmos de clasificación. Es un conjunto de datos pequeño y fácilmente accesible, por lo que es ideal para experimentos iniciales en el campo. Sin embargo, debido a su tamaño limitado y a la simplicidad de las imágenes, también se considera que es limitado en términos de complejidad y diversidad de las caras representadas.\n",
        "\n",
        "Vamos a cargarlo dentro de la carpeta de datos crudos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0d9ee9",
      "metadata": {
        "id": "9e0d9ee9"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mindlab-unal/mlds6-datasets/main/u3/olivetti.npy -O data/raw/olivetti.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293f5466",
      "metadata": {
        "id": "293f5466"
      },
      "source": [
        "Podemos validar el estado del repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fba2a44b",
      "metadata": {
        "id": "fba2a44b"
      },
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34780c34",
      "metadata": {
        "id": "34780c34"
      },
      "source": [
        "Agregamos los datos con `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb46cf8",
      "metadata": {
        "id": "ccb46cf8"
      },
      "outputs": [],
      "source": [
        "!dvc add data/raw/olivetti.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d08e514e",
      "metadata": {
        "id": "d08e514e"
      },
      "source": [
        "Ahora, vamos a agregar los metadatos creados por `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f0c4d0",
      "metadata": {
        "id": "16f0c4d0"
      },
      "outputs": [],
      "source": [
        "!git add data/raw/olivetti.npy.dvc data/raw/.gitignore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8170242",
      "metadata": {
        "id": "a8170242"
      },
      "source": [
        "Creamos un commit con estos datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f2b73da",
      "metadata": {
        "id": "1f2b73da"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"Agregamos el conjunto de datos Olivetti\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6923d80f",
      "metadata": {
        "id": "6923d80f"
      },
      "source": [
        "Ahora, cargamos el conjunto de datos para inspeccionarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232ca1ab",
      "metadata": {
        "id": "232ca1ab"
      },
      "outputs": [],
      "source": [
        "data = np.load(\"data/raw/olivetti.npy\")\n",
        "display(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258b2472",
      "metadata": {
        "id": "258b2472"
      },
      "source": [
        "Los datos son un arreglo de `numpy` que contiene 400 imágenes de tamaño 64x64.\n",
        "\n",
        "Veamos una imagen aleatoria del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a91381c",
      "metadata": {
        "id": "9a91381c"
      },
      "outputs": [],
      "source": [
        "idx = np.random.randint(data.shape[0])\n",
        "img = data[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eb847e",
      "metadata": {
        "id": "11eb847e"
      },
      "source": [
        "Visualizamos la imagen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0de02d",
      "metadata": {
        "id": "2b0de02d"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.imshow(img, cmap=\"gray\")\n",
        "ax.axis(\"off\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e61b7e2",
      "metadata": {
        "id": "0e61b7e2"
      },
      "source": [
        "Ahora, veamos cómo podemos convertir las imágenes en un vector de características. Para esto usaremos la librería `scikit-image`. Se trata de una biblioteca de software libre para procesamiento de imágenes en _Python_. Se enfoca en proporcionar herramientas eficientes y fáciles de usar para realizar tareas comunes de procesamiento de imágenes.\n",
        "\n",
        "En este caso utilizaremos una técnica clásica de procesamiento de imágenes conocida como HOG, o *Histogram of Oriented Gradients*. Se trata de una técnica de extracción de características utilizada para describir regiones de una imagen en términos de la distribución de gradientes de intensidad de la luz en diferentes orientaciones, como se muestra en la siguiente figura:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=13Tcijgc2hcoIl5DNo9dsj01FVpKxK9yj\" width=\"80%\">\n",
        "\n",
        "En resumen, la técnica HOG consiste en los siguientes pasos:\n",
        "\n",
        "Cálculo de gradientes: Se calcula el gradiente de intensidad de la luz en diferentes direcciones en cada punto de la imagen.\n",
        "\n",
        "1. **Discretización**: Se discretiza el espacio de orientación en un número finito de direcciones.\n",
        "2. **Agrupación en celdas**: Se divide la imagen en celdas pequeñas y se agrupan los gradientes dentro de cada celda.\n",
        "3. **Cálculo de histogramas**: Se calcula un histograma de orientación para cada celda, describiendo la distribución de gradientes dentro de ella.\n",
        "4. **Concatenación de histogramas**: Se concatenan los histogramas de orientación de todas las celdas para formar un vector de características.\n",
        "\n",
        "Este vector de características se utiliza como entrada para un algoritmo de aprendizaje automático, como un clasificador, para realizar tareas como la detección de objetos o la identificación de características. La técnica HOG es ampliamente utilizada en el campo de la visión por computadora debido a su capacidad para describir la distribución de características en una imagen de manera efectiva y compacta.\n",
        "\n",
        "Comenzamos instalando `scikit-image`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad72659",
      "metadata": {
        "id": "6ad72659"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29f924b0",
      "metadata": {
        "id": "29f924b0"
      },
      "source": [
        "Importamos la función `hog` para aplicarlo sobre las imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd0b64b",
      "metadata": {
        "id": "bcd0b64b"
      },
      "outputs": [],
      "source": [
        "from skimage.feature import hog"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8293d31d",
      "metadata": {
        "id": "8293d31d"
      },
      "source": [
        "Veamos las características para la imagen que teníamos seleccionada, usamos algunos hiperparámetros como:\n",
        "\n",
        "- `orientations`: direcciones de gradiente a considerar.\n",
        "- `pixels_per_cell`: tamaño de las celdas donde se calculan los gradientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a371d4f8",
      "metadata": {
        "id": "a371d4f8"
      },
      "outputs": [],
      "source": [
        "features = hog(img, orientations=4, pixels_per_cell=(16, 16))\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "oOKmAGJvb0Yc"
      },
      "id": "oOKmAGJvb0Yc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b4e6bad7",
      "metadata": {
        "id": "b4e6bad7"
      },
      "source": [
        "Como podemos ver, obtenemos un vector de tamaño `144`. Podemos repetir este proceso para todas las imágenes para obtener una matriz de características de todo el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bb195a",
      "metadata": {
        "id": "86bb195a"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate([\n",
        "    hog(data[i], orientations=4, pixels_per_cell=(16, 16))[np.newaxis, ...]\n",
        "    for i in range(data.shape[0])\n",
        "    ])\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06ded99",
      "metadata": {
        "id": "b06ded99"
      },
      "source": [
        "Guardamos las características dentro del repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0352de58",
      "metadata": {
        "id": "0352de58"
      },
      "outputs": [],
      "source": [
        "np.save(\"data/features/olivetti.npy\", features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab7d585",
      "metadata": {
        "id": "5ab7d585"
      },
      "source": [
        "Agregamos las características a `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e99d7ef",
      "metadata": {
        "id": "6e99d7ef"
      },
      "outputs": [],
      "source": [
        "!dvc add data/features/olivetti.npy\n",
        "!git add data/features/olivetti.npy.dvc data/features/.gitignore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a54068af",
      "metadata": {
        "id": "a54068af"
      },
      "source": [
        "Creamos un commit con las características extraídas de las imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1c210d",
      "metadata": {
        "id": "bd1c210d"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"Agregamos características de olivetti\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b11e197",
      "metadata": {
        "id": "9b11e197"
      },
      "source": [
        "## **2. Texto**\n",
        "---\n",
        "\n",
        "La extracción de características en textos es el proceso de convertir un corpus de texto en una representación numérica que pueda ser utilizada por un algoritmo de aprendizaje automático. Se trata de un paso crítico en la mayoría de los sistemas de procesamiento de lenguaje natural (NLP, por sus siglas en inglés) y de análisis de texto, ya que permite a los algoritmos trabajar con los datos en una forma que puedan comprender y utilizar.\n",
        "\n",
        "Hay muchas técnicas diferentes de extracción de características para textos, dependiendo del problema que se esté tratando de resolver y del tipo de corpus que se esté utilizando. Algunas técnicas comunes incluyen:\n",
        "\n",
        "- **Bolsa de palabras**: Se representa cada documento como una lista de frecuencias de palabras, ignorando el orden y la gramática de las palabras.\n",
        "- **N-gramas**: Se representa cada documento como una lista de frecuencias de secuencias de n palabras.\n",
        "- **Representación distribucional**: Se representa cada documento como un vector que describe las probabilidades de co-ocurrencia de las palabras en el corpus.\n",
        "- **Modelos semánticos**: Se representa cada documento como un vector que describe la semántica subyacente, utilizando técnicas como word2vec o GloVe.\n",
        "\n",
        "> **Nota**: puede ver más detalle de estos modelos en el módulo 4 de procesamiento y entendimiento de lenguaje natural.\n",
        "\n",
        "La extracción de características es una tarea importante y desafiante en el NLP, ya que debe capturar de manera efectiva la información relevante y suprimir la información irrelevante o redundante en el corpus. La elección de la técnica adecuada de extracción de características puede tener un impacto significativo en la efectividad de los sistemas de NLP y de análisis de texto.\n",
        "\n",
        "En este caso utilizaremos un modelo semántico contenido en la librería `spacy`, la cual es una biblioteca de procesamiento de lenguaje natural de código abierto para _Python_. Se destaca por su alta velocidad y eficiencia, lo que la convierte en una opción popular para muchos problemas de NLP.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1nk8ZGj27YhT-GCZtlyJq1c5P_AuPoFLr\" width=\"80%\">\n",
        "\n",
        "Además, spaCy ofrece una amplia gama de modelos pre-entrenados para muchos idiomas, incluyendo inglés, alemán, francés, español, italiano, portugués, holandés, danés, sueco, finlandés y noruego, lo que permite a los usuarios utilizar sus funciones de forma rápida y efectiva sin tener que entrenar desde cero.\n",
        "\n",
        "Comenzamos instalando `spacy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90bfdc1",
      "metadata": {
        "id": "e90bfdc1"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5851c6ba",
      "metadata": {
        "id": "5851c6ba"
      },
      "source": [
        "Importamos `spacy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "446dc106",
      "metadata": {
        "id": "446dc106"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91715f00",
      "metadata": {
        "id": "91715f00"
      },
      "source": [
        "Vamos a descargar un _Pipeline_ de `spacy` para su uso en el idioma inglés:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e4ecd5",
      "metadata": {
        "id": "70e4ecd5"
      },
      "outputs": [],
      "source": [
        "spacy.cli.download(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5d2a54",
      "metadata": {
        "id": "7f5d2a54"
      },
      "source": [
        "Cargamos el _Pipeline_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62cbf952",
      "metadata": {
        "id": "62cbf952"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f1ac5c",
      "metadata": {
        "id": "d8f1ac5c"
      },
      "source": [
        "Vamos a cargar el conjunto de datos [Twitter Financial News](https://www.kaggle.com/datasets/sulphatet/twitter-financial-news) de Kaggle. El cual contiene textos de tweets relacionados con finanzas.\n",
        "\n",
        "Cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff235ed0",
      "metadata": {
        "id": "ff235ed0"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mindlab-unal/mlds6-datasets/main/u3/twitter_financial.parquet -O data/raw/twitter_financial.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "572fe304",
      "metadata": {
        "id": "572fe304"
      },
      "source": [
        "Agregamos los datos con `dvc` y creamos el commit correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efc402b5",
      "metadata": {
        "id": "efc402b5"
      },
      "outputs": [],
      "source": [
        "!dvc add data/raw/twitter_financial.parquet\n",
        "!git add data/raw/.gitignore data/raw/twitter_financial.parquet.dvc\n",
        "!git commit -m \"Agregamos los datos de twitter financial\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ec139d",
      "metadata": {
        "id": "f4ec139d"
      },
      "source": [
        "Ahora veamos el proceso de extracción de características sobre texto. Primero cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9223731",
      "metadata": {
        "id": "f9223731"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"data/raw/twitter_financial.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41c88f7",
      "metadata": {
        "id": "d41c88f7"
      },
      "source": [
        "Veamos cómo podemos extraer características con el _Pipeline_, lo haremos con un documento aleatorio del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e824ede",
      "metadata": {
        "id": "2e824ede"
      },
      "outputs": [],
      "source": [
        "doc = data.loc[np.random.randint(data.shape[0]), \"text\"]\n",
        "display(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc50c92b",
      "metadata": {
        "id": "fc50c92b"
      },
      "source": [
        "Extraemos un vector de características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94a3ffd",
      "metadata": {
        "id": "a94a3ffd"
      },
      "outputs": [],
      "source": [
        "features = nlp(doc).vector\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "VDBuzGo-gM3J"
      },
      "id": "VDBuzGo-gM3J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d5573351",
      "metadata": {
        "id": "d5573351"
      },
      "source": [
        "Como podemos ver, obtenemos un vector de características de tamaño 96.\n",
        "\n",
        "Ahora representamos todo el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58075cd",
      "metadata": {
        "id": "b58075cd"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate([\n",
        "    nlp(doc).vector[np.newaxis, ...]\n",
        "    for doc in data.text.tolist()\n",
        "    ])\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607b651e",
      "metadata": {
        "id": "607b651e"
      },
      "source": [
        "Exportamos las características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76aaeac",
      "metadata": {
        "id": "d76aaeac"
      },
      "outputs": [],
      "source": [
        "np.save(\"data/features/twitter_financial.npy\", features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350522a4",
      "metadata": {
        "id": "350522a4"
      },
      "source": [
        "Por último, agregamos las características a `dvc` y creamos un commit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9fe7731",
      "metadata": {
        "id": "a9fe7731"
      },
      "outputs": [],
      "source": [
        "!dvc add data/features/twitter_financial.npy\n",
        "!git add data/features/.gitignore data/features/twitter_financial.npy.dvc\n",
        "!git commit -m \"Agregamos las características de twitter financial\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ed9ead",
      "metadata": {
        "id": "83ed9ead"
      },
      "source": [
        "## **3. Series de Tiempo**\n",
        "---\n",
        "\n",
        "La extracción de características con series de tiempo es el proceso de transformar una serie temporal en una representación numérica que pueda ser utilizada por un algoritmo de aprendizaje automático. Esto es necesario debido a que los algoritmos de aprendizaje automático no pueden trabajar directamente con datos temporales, ya que los datos temporales son secuencias de valores que varían con el tiempo.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1JyzLpm5nfSdY31p3xw5zIG3v2vARuh4e\" width=\"80%\">\n",
        "\n",
        "Hay muchas técnicas diferentes para la extracción de características con series de tiempo. La elección de la técnica adecuada depende de la naturaleza de la serie temporal y del problema que se esté tratando de resolver. Algunas técnicas comunes incluyen:\n",
        "\n",
        "- **Transformadas**: Se utiliza una transformada matemática, como la transformada de Fourier, para analizar la frecuencia y el espectro de la serie temporal.\n",
        "- **Características estadísticas**: Se extraen características estadísticas como la media, la desviación estándar, la mediana y la moda de la serie temporal.\n",
        "- **Características de la tendencia**: Se extraen características que describen la tendencia de la serie temporal, como la tasa de crecimiento o la tasa de cambio.\n",
        "- **Características de la estacionalidad**: Se extraen características que describen la estacionalidad de la serie temporal, como la frecuencia y la amplitud de los patrones estacionales.\n",
        "\n",
        "La extracción de características es un paso crítico en el análisis de series de tiempo, ya que permite a los algoritmos de aprendizaje automático trabajar con los datos en una forma que puedan comprender y utilizar. Además, es importante seleccionar cuidadosamente las características a extraer para evitar la inclusión de características irrelevantes o redundantes, que pueden perjudicar la efectividad de los algoritmos.\n",
        "\n",
        "En este caso utilizaremos la librería `tsfresh` para extracción de características a partir de series de tiempo. Se trata de una biblioteca de _Python_ que se enfoca en la extracción de características de series de tiempo. Es una herramienta automatizada para la selección y la extracción de características que son relevantes y útiles para el análisis de series de tiempo.\n",
        "\n",
        "tsfresh utiliza un enfoque de aprendizaje automático para identificar las características relevantes, además utiliza una variedad de técnicas estadísticas y matemáticas para extraer esas características de los datos. Estas características se pueden utilizar en una variedad de aplicaciones, incluyendo la clasificación, la regresión y la detección de anomalías.\n",
        "\n",
        "tsfresh es una herramienta muy útil para los investigadores y los científicos de datos que trabajan con series de tiempo, ya que permite extraer características relevantes de los datos de forma rápida y efectiva, sin tener que escribir código para realizar esta tarea manualmente. Además, tsfresh es fácil de usar y se integra con otras bibliotecas de aprendizaje automático y análisis de datos de _Python_.\n",
        "\n",
        "Veamos cómo es su instalación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e09f58",
      "metadata": {
        "id": "42e09f58"
      },
      "outputs": [],
      "source": [
        "!pip install tsfresh"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e2b78d",
      "metadata": {
        "id": "23e2b78d"
      },
      "source": [
        "Vamos a descargar el conjunto de datos [Robot Execution Failures](http://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures) que contiene mediciones de fuerza y torque de fallos de un robot en el tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94040ac1",
      "metadata": {
        "id": "94040ac1"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mindlab-unal/mlds6-datasets/main/u3/robot_failures.parquet -O data/raw/robot_failures.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1987dcb5",
      "metadata": {
        "id": "1987dcb5"
      },
      "source": [
        "Ahora, agregamos los datos a `dvc` y `git`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf25b5f",
      "metadata": {
        "id": "adf25b5f"
      },
      "outputs": [],
      "source": [
        "!dvc add data/raw/robot_failures.parquet\n",
        "!git add data/raw/.gitignore data/raw/robot_failures.parquet.dvc\n",
        "!git commit -m \"Agregamos los datos de robot failures\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48591255",
      "metadata": {
        "id": "48591255"
      },
      "source": [
        "Cargamos los datos con `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887fdcdc",
      "metadata": {
        "id": "887fdcdc"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"data/raw/robot_failures.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c78fa02",
      "metadata": {
        "id": "4c78fa02"
      },
      "source": [
        "El conjunto de datos contiene las siguientes columnas:\n",
        "\n",
        "- `id`: identificador de la serie de tiempo.\n",
        "- `time`: tiempo.\n",
        "- `F_i`: fuerza ejercida en un eje `i`.\n",
        "- `T_i`: torque ejercido en un eje `i`.\n",
        "\n",
        "Veamos una gráfica de una serie de tiempo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b70d28",
      "metadata": {
        "id": "39b70d28"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "data.query(\"id == 20\").plot(x=\"time\", subplots=True, sharex=True, ax=ax)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89830d55",
      "metadata": {
        "id": "89830d55"
      },
      "source": [
        "Para extraer características con `tsfresh` podemos usar la función `extract_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d55e598",
      "metadata": {
        "id": "1d55e598"
      },
      "outputs": [],
      "source": [
        "from tsfresh import extract_features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4ab278",
      "metadata": {
        "id": "7c4ab278"
      },
      "source": [
        "Extraemos las características, para ello usamos los parámetros:\n",
        "\n",
        "- `column_id`: específica el identificador de cada serie de tiempo.\n",
        "- `column_sort`: específica el tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a67a1f2",
      "metadata": {
        "id": "7a67a1f2"
      },
      "outputs": [],
      "source": [
        "features = extract_features(data, column_id=\"id\", column_sort=\"time\")\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93c8aefd",
      "metadata": {
        "id": "93c8aefd"
      },
      "source": [
        "Obtenemos 4698 características (de los tipos que mencionamos anteriormente) para cada una de las 88 series de tiempo en el conjunto de datos.\n",
        "\n",
        "Vamos a exportar estas características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a30d5fe3",
      "metadata": {
        "id": "a30d5fe3"
      },
      "outputs": [],
      "source": [
        "features.to_parquet(\"data/features/robot_failures.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4108eb",
      "metadata": {
        "id": "ee4108eb"
      },
      "source": [
        "Agregamos las características al repositorio con `dvc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a709cb2f",
      "metadata": {
        "id": "a709cb2f"
      },
      "outputs": [],
      "source": [
        "!dvc add data/features/robot_failures.parquet\n",
        "!git add data/features/.gitignore data/features/robot_failures.parquet.dvc\n",
        "!git commit -m \"Agregamos las características de robot failures\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5306833",
      "metadata": {
        "id": "c5306833"
      },
      "source": [
        "## **4. Aprendizaje de Características**\n",
        "---\n",
        "\n",
        "El aprendizaje de características es un proceso en el que se utiliza un algoritmo de machine learning para automáticamente identificar y extraer características relevantes de los datos de entrada. La idea detrás de esto es que la mayoría de los algoritmos de machine learning funcionan mejor con datos en formato numérico, y los datos originales (por ejemplo, imágenes, audio, texto, etc.) no siempre están en este formato.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1O_nI1j8R_c1Zjher9rpl_w9MhvdFJIyr\" width=\"80%\">\n",
        "\n",
        "El proceso de aprendizaje de características se divide en dos partes: la extracción de características y la selección de características. La extracción de características se refiere a la conversión de los datos originales en una forma que se pueda utilizar en un algoritmo de machine learning. La selección de características se refiere a la identificación de las características más relevantes y significativas que se deben utilizar en el algoritmo de aprendizaje.\n",
        "\n",
        "El aprendizaje de características es un paso crítico en muchos problemas de machine learning, ya que ayuda a mejorar la precisión y el rendimiento de los algoritmos. Por ejemplo, si un algoritmo de aprendizaje de máquina recibe como entrada características irrelevantes o no significativas, su precisión disminuirá y tendrá un rendimiento más bajo. Por lo tanto, es importante realizar una buena extracción y selección de características para obtener buenos resultados en el aprendizaje de máquinas.\n",
        "\n",
        "Vamos a ver un modelo de autoencoder para aprendizaje de características con `tensorflow`. Un autoencoder es un tipo de red neuronal artificial que se utiliza para aprender una representación compacta y densa de los datos de entrada. Se compone de dos partes principales: un codificador que convierte los datos de entrada en una representación compacta, y un decodificador que intenta reconstruir los datos de entrada originales a partir de la representación comprimida.\n",
        "\n",
        "El objetivo de un autoencoder es aprender una representación de los datos que sea lo suficientemente compacta para que se pueda usar como entrada en otras tareas, como la clasificación o la detección de anormalidades. Durante el entrenamiento, el autoencoder recibe los datos de entrada y compara la reconstrucción realizada por el decodificador con los datos de entrada originales, y se ajusta para minimizar la diferencia entre las dos.\n",
        "\n",
        "Comenzamos importando los componentes de `tensorflow` que necesitamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca84ae0a",
      "metadata": {
        "id": "ca84ae0a"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import MeanSquaredError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23946ed2",
      "metadata": {
        "id": "23946ed2"
      },
      "source": [
        "Vamos a reutilizar el conjunto de datos de Olivetti:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8145ef",
      "metadata": {
        "id": "ff8145ef"
      },
      "outputs": [],
      "source": [
        "data = np.load(\"data/raw/olivetti.npy\")\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c36ff88",
      "metadata": {
        "id": "3c36ff88"
      },
      "source": [
        "Vamos a extraer todos los píxeles de las imágenes como vectores individuales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc84b483",
      "metadata": {
        "id": "cc84b483"
      },
      "outputs": [],
      "source": [
        "data = data.reshape(400, -1)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb88ec4",
      "metadata": {
        "id": "fbb88ec4"
      },
      "source": [
        "Ahora vamos a implementar un modelo de Autoencoder, comenzamos con el codificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bd45a61",
      "metadata": {
        "id": "9bd45a61"
      },
      "outputs": [],
      "source": [
        "encoder = Sequential([\n",
        "    Input(shape=(4096, )),\n",
        "    Dense(units=128, activation=\"relu\"),\n",
        "    Dense(units=64, activation=\"linear\")\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253cc571",
      "metadata": {
        "id": "253cc571"
      },
      "source": [
        "Ahora el decodificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69eab09a",
      "metadata": {
        "id": "69eab09a"
      },
      "outputs": [],
      "source": [
        "decoder = Sequential([\n",
        "    Input(shape=(64, )),\n",
        "    Dense(units=128, activation=\"relu\"),\n",
        "    Dense(units=4096, activation=\"linear\"),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497b6c51",
      "metadata": {
        "id": "497b6c51"
      },
      "source": [
        "Implementamos el modelo completo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630a979f",
      "metadata": {
        "id": "630a979f"
      },
      "outputs": [],
      "source": [
        "autoencoder = Sequential([\n",
        "    Input(shape=(4096, )),\n",
        "    encoder,\n",
        "    decoder\n",
        "    ])\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68753292",
      "metadata": {
        "id": "68753292"
      },
      "source": [
        "Compilamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ec9eae",
      "metadata": {
        "id": "71ec9eae"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=MeanSquaredError()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ee8441",
      "metadata": {
        "id": "00ee8441"
      },
      "source": [
        "Ahora lo entrenamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f0a032",
      "metadata": {
        "id": "20f0a032"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(data, data, epochs=100, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc52314b",
      "metadata": {
        "id": "cc52314b"
      },
      "source": [
        "Veamos la pérdida del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5032ea61",
      "metadata": {
        "id": "5032ea61"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(history.history[\"loss\"])\n",
        "ax.set_xlabel(\"Épocas\")\n",
        "ax.set_ylabel(\"Pérdida\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbdd8157",
      "metadata": {
        "id": "bbdd8157"
      },
      "source": [
        "Podemos utilizar el modelo para extraer características de las imágenes de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0040ba4d",
      "metadata": {
        "id": "0040ba4d"
      },
      "outputs": [],
      "source": [
        "features = encoder.predict(data)\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d731a3a",
      "metadata": {
        "id": "4d731a3a"
      },
      "source": [
        "Como podemos ver, obtenemos una representación de tamaño 64 para cada una de las 400 imágenes. Se trata de una representación neuronal que probablemente no se interprete tan fácilmente. No obstante, es útil si deseamos entrenar algún modelo a partir de estas imágenes, además resulta ser más específica que representaciones clásicas como HOG.\n",
        "\n",
        "Exportamos las características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fba33b",
      "metadata": {
        "id": "e7fba33b"
      },
      "outputs": [],
      "source": [
        "np.save(\"data/features/learned.npy\", features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f88834",
      "metadata": {
        "id": "e8f88834"
      },
      "source": [
        "Finalmente, las agregamos al repositorio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a17bef",
      "metadata": {
        "id": "b9a17bef"
      },
      "outputs": [],
      "source": [
        "!dvc add data/features/learned.npy\n",
        "!git add data/features/.gitignore data/features/learned.npy.dvc\n",
        "!git commit -m \"Agregamos las características aprendidas\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a16b2ac",
      "metadata": {
        "id": "5a16b2ac"
      },
      "source": [
        "Como pudimos ver, existen distintas alternativas para extracción de características en dependencia del tipo de dato. De hecho, existen muchas técnicas específicas para cada tipo de dato o aplicación. Por ejemplo, características en imágenes médicas, en imágenes térmicas, en detección de rostros, entre otras.\n",
        "\n",
        "No obstante, es importante entender el proceso de extracción de características —independiente de la librería o los datos que usemos— y su integración con herramientas de versionamiento como `git` y `dvc`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0404c419",
      "metadata": {
        "id": "0404c419"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "**Profesor**\n",
        "\n",
        "- [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "\n",
        "**Asistente docente**:\n",
        "\n",
        "- [Juan S. Lara MSc](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/)\n",
        "\n",
        "**Diseño de imágenes:**\n",
        "- [Brian Chaparro Cetina](mailto:bchaparro@unal.edu.co).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}