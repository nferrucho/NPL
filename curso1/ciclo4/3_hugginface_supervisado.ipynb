{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo4/3_hugginface_supervisado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c666a5",
      "metadata": {
        "id": "48c666a5"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Q6vQcIWFPY27isBepABpJ7nroUNKox_Z\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3cfe0ff",
      "metadata": {
        "id": "f3cfe0ff"
      },
      "source": [
        "# **Introducción al Análisis Supervisado con Transformers**\n",
        "---\n",
        "\n",
        "En este notebook veremos una introducción práctica a la librería `transformers` de [HuggingFace](https://huggingface.co/).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1joVUiGIgNZSfygmPrOr-U3_TvnEm3ccQ\" width=\"60%\">\n",
        "\n",
        "Se trata de una de las librerías más populares para procesamiento de lenguaje natural que utiliza modelos basados en redes neuronales de tipo transformers para realizar distintos tipos de tareas.\n",
        "\n",
        "Importamos las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043d92d7",
      "metadata": {
        "id": "043d92d7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5691a3fc",
      "metadata": {
        "id": "5691a3fc"
      },
      "source": [
        "## **1. Descripción General**\n",
        "---\n",
        "\n",
        "Los `transformers` son una familia de modelos basados en redes neuronales que pueden ser utilizados en distintos tipos de aplicaciones.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hIDeviRokZPLeSXyp9rLCuFMgCWU3Gn2\" width=\"80%\">\n",
        "\n",
        "Estos modelos fueron originalmente usados en aplicaciones de procesamiento de lenguaje natural. Dado que demostraron tener un gran desempeño, comenzaron a ser usados en otros tipos de aplicaciones como visión por computador, procesamiento de señales, análisis de videos, entre otras.\n",
        "\n",
        "En un principio, estos modelos se implementaban a bajo nivel con librerías como `tensorflow` o `pytorch` (para _Deep Learning_). No obstante, la compañía [HuggingFace](https://huggingface.co/) se ha encargado de crear un ecosistema de librerías para usar varios modelos pre-entrenados de una forma sencilla y más dirigida al usuario.\n",
        "\n",
        "En especial, vamos a instalar la librería `transformers` y a ver su uso para procesamiento de lenguaje natural. También instalamos `sentencepiece` y `sacremoses` (módulos con muchas funciones de preprocesamiento para los modelos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c51c30",
      "metadata": {
        "id": "91c51c30"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] sentencepiece sacremoses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fde6d73",
      "metadata": {
        "id": "1fde6d73"
      },
      "source": [
        "Comenzamos importando `pipeline` (similar a `spacy`) de `transformers`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d38125",
      "metadata": {
        "id": "36d38125"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5288d93a",
      "metadata": {
        "id": "5288d93a"
      },
      "source": [
        "## **2. Búsqueda de Modelos**\n",
        "---\n",
        "\n",
        "Para comenzar a usar `transformers` primero debemos seleccionar el tipo de aplicación que vamos a desarrollar, y filtrar dentro de los distintos tipos de modelos disponibles en los repositorios de [HuggingFace](https://huggingface.co/).\n",
        "\n",
        "A continuación se presenta un video acerca de cómo podemos seleccionar un modelo de acuerdo a las posibles tareas, idiomas, y tipo de modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370bc0c4",
      "metadata": {
        "cellView": "form",
        "id": "370bc0c4"
      },
      "outputs": [],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "from IPython.display import IFrame\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/1bgNE8oz4joKp0Amx1j7OBxYJYbwQ7Ldm/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "292a1105",
      "metadata": {
        "id": "292a1105"
      },
      "source": [
        "Como veremos más adelante, es suficiente con tener el nombre del modelo para comenzar a descargar, instanciar y realizar inferencia sobre estos modelos.\n",
        "\n",
        "Veamos algunas tareas con `transformers`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c2fba7",
      "metadata": {
        "id": "47c2fba7"
      },
      "source": [
        "## **3. Clasificación de Tokens**\n",
        "---\n",
        "\n",
        "La tarea de clasificación de tokens busca clasificar palabras u oraciones dentro de un texto en alguna categoría.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1tgzuToinJmOsPHEMr2NMIfMn4ADZftkm\" width=\"80%\">\n",
        "\n",
        "Para ello, se utilizan modelos de `transformers` para clasificación multiclase. Veamos un ejemplo con un modelo para reconocimiento de entidades nombradas en español.\n",
        "\n",
        "Primero cargamos el modelo, para ello debemos especificar el tipo de tarea y el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8494baaa",
      "metadata": {
        "id": "8494baaa"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"ner\", \"mrm8488/bert-spanish-cased-finetuned-ner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a49c9796",
      "metadata": {
        "id": "a49c9796"
      },
      "source": [
        "Para aplicar el modelo, lo podemos usar como si se tratara de una función. Tomemos como base el siguiente texto de ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7989ae5",
      "metadata": {
        "id": "c7989ae5"
      },
      "outputs": [],
      "source": [
        "text = \"Argentina se consagró campeón del mundo al derrotar por penales a Francia 4 a 2. La final de Qatar se disputó en el estadio de Doha.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b5b5e3",
      "metadata": {
        "id": "a1b5b5e3"
      },
      "source": [
        "Extraemos las entidades:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20366eb8",
      "metadata": {
        "id": "20366eb8"
      },
      "outputs": [],
      "source": [
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1c83a3",
      "metadata": {
        "id": "4d1c83a3"
      },
      "source": [
        "Como podemos ver, obtenemos distintos metadatos de la entidad:\n",
        "\n",
        "- `entity`: tipo de entidad encontrada, en este caso, países y ubicaciones.\n",
        "- `score`: probabilidad predicha por el modelo.\n",
        "- `index`: índice del token.\n",
        "- `word`: texto de la entidad.\n",
        "- `start`: carácter inicial dentro de la secuencia.\n",
        "- `end`: carácter final dentro de la secuencia."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3250f28b",
      "metadata": {
        "id": "3250f28b"
      },
      "source": [
        "## **4. Clasificación de Textos**\n",
        "---\n",
        "\n",
        "Desde `transformers` también podemos realizar clasificación a nivel de documentos.\n",
        "\n",
        "Por ejemplo, podemos usar un modelo para análisis de sentimientos en español:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QCEsPK7ganFQ0SEt8Cn9B3gi2diQwx-F\" width=\"80%\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "518c055c",
      "metadata": {
        "id": "518c055c"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"text-classification\", \"finiteautomata/beto-sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c337ffab",
      "metadata": {
        "id": "c337ffab"
      },
      "source": [
        "Definimos un texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d819e257",
      "metadata": {
        "id": "d819e257"
      },
      "outputs": [],
      "source": [
        "text = \"me encanta como la gente dona regalos para navidad\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08891dca",
      "metadata": {
        "id": "08891dca"
      },
      "source": [
        "Veamos las predicciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c760d40f",
      "metadata": {
        "id": "c760d40f"
      },
      "outputs": [],
      "source": [
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4780dd4a",
      "metadata": {
        "id": "4780dd4a"
      },
      "source": [
        "En este caso, el modelo nos da dos resultados:\n",
        "\n",
        "- `label`: sentimiento encontrado.\n",
        "- `score`: probabilidad predicha por el modelo.\n",
        "\n",
        "Veamos otro ejemplo con un texto con una polaridad negativa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f073d7",
      "metadata": {
        "id": "b8f073d7"
      },
      "outputs": [],
      "source": [
        "text = \"me siento muy mal, estoy un poco enfermo\"\n",
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f65d6c",
      "metadata": {
        "id": "b1f65d6c"
      },
      "source": [
        "## **5. Traducción Automática**\n",
        "---\n",
        "\n",
        "Los modelos para traducción automática son modelos supervisados de tipo secuencia a secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e9e0e2",
      "metadata": {
        "cellView": "form",
        "id": "97e9e0e2"
      },
      "outputs": [],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "from IPython.display import IFrame\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/1Ezcp94fLKLJM_o_z-cLyJN7HUIUrb-KO/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59360c0a",
      "metadata": {
        "id": "59360c0a"
      },
      "source": [
        "Muchas de las herramientas para traducción más populares hoy en día, como [DeepL](https://www.deepl.com/es/translator) o [Google Translate](https://translate.google.com/?hl=es), hacen uso de este tipo de modelos.\n",
        "\n",
        "Estos modelos se entrenan tomando como entrada el texto en un idioma, y tienen como salida el mismo texto, pero en idioma objetivo.\n",
        "\n",
        "Veamos un modelo para traducción de español a inglés:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37103424",
      "metadata": {
        "id": "37103424"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"translation\", \"Helsinki-NLP/opus-mt-es-en\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258225f0",
      "metadata": {
        "id": "258225f0"
      },
      "source": [
        "Definimos un texto para traducir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ea5537",
      "metadata": {
        "id": "84ea5537"
      },
      "outputs": [],
      "source": [
        "text = \"estamos aprendiendo sobre transformers en el curso de procesamiento de lenguaje natural\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c56f13",
      "metadata": {
        "id": "53c56f13"
      },
      "source": [
        "Veamos la traducción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a6f4793",
      "metadata": {
        "id": "6a6f4793"
      },
      "outputs": [],
      "source": [
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49462414",
      "metadata": {
        "id": "49462414"
      },
      "source": [
        "El resultado tiene un único campo:\n",
        "\n",
        "- `translation_text`: texto traducido."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ba8feb",
      "metadata": {
        "id": "72ba8feb"
      },
      "source": [
        "## **6. Llenado de Máscaras**\n",
        "---\n",
        "\n",
        "El llenado de máscaras o _mask filling_ es otra tarea supervisada donde el modelo trata de predecir un token de acuerdo a su contexto:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1UB0-dIMIp85DEFowqZD5OI9GFWn7oUTe\" width=\"80%\">\n",
        "\n",
        "Normalmente, los modelos de llenado de máscaras tratan de reemplazar un token específico por una predicción dentro del vocabulario, similar al juego del ahorcado. Por ejemplo, el siguiente texto:\n",
        "\n",
        "> `\"ayer compramos ____ en la panadería\"`\n",
        "\n",
        "Hay múltiples tokens que podrían reemplazarse acá, por ejemplo: `\"pan\", \"panes\", \"galletas\"`.\n",
        "\n",
        "Podemos cargar un modelo para llenado de máscaras en español:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31fd80de",
      "metadata": {
        "id": "31fd80de"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"fill-mask\", \"xlm-roberta-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d3d97dd",
      "metadata": {
        "id": "3d3d97dd"
      },
      "source": [
        "Para este modelo, las máscaras se representan por medio del token `<mask>`. Veamos un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e6f9a3",
      "metadata": {
        "id": "00e6f9a3"
      },
      "outputs": [],
      "source": [
        "text = \"ayer viajé desde <mask> hacia Colombia\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab0db4d",
      "metadata": {
        "id": "cab0db4d"
      },
      "source": [
        "Veamos la predicción del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6cff11",
      "metadata": {
        "id": "ed6cff11"
      },
      "outputs": [],
      "source": [
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8143e6af",
      "metadata": {
        "id": "8143e6af"
      },
      "source": [
        "Las predicciones corresponden a una lista de las palabras más probables que puede autocompletar el modelo. Estas tienen los siguientes campos:\n",
        "\n",
        "- `score`: probabilidad predicha por el modelo.\n",
        "- `token`: identificador de token dentro del vocabulario.\n",
        "- `token_str`: texto del token.\n",
        "- `sequence`: texto resultante."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8472b8ce",
      "metadata": {
        "id": "8472b8ce"
      },
      "source": [
        "## **7. Resumen Abstractivo**\n",
        "---\n",
        "\n",
        "El resumen abstractivo es una aplicación donde se realiza síntesis de un texto para obtener una versión más corta del mismo.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PGqgH9OixCyTeTThL0ob9ZFFCzmQmMWl\" width=\"80%\">\n",
        "\n",
        "Es una tarea donde el resultado puede contener palabras que ni siquiera se encuentran en el vocabulario del texto original. Es decir, el modelo debe generar un texto completamente nuevo que contenga la mayor cantidad de información posible del texto original pero con menos palabras.\n",
        "\n",
        "Veamos un modelo en español:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e525971",
      "metadata": {
        "id": "7e525971"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\"summarization\", \"josmunpen/mt5-small-spanish-summarization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d1d9286",
      "metadata": {
        "id": "2d1d9286"
      },
      "source": [
        "Definimos un texto a resumir:\n",
        "\n",
        "El contenido es el siguiente\n",
        "\n",
        ">La Guardia Civil ha desarticulado un grupo organizado dedicado a copiar en los examenes teoricos para la obtencion del permiso de conducir. Para ello, empleaban receptores y camaras de alta tecnologia y operaban desde la misma sede del Centro de examenes de la Direccion General de Trafico (DGT) en Mostoles. Es lo que han llamado la Operacion pinga. El grupo desarticulado ofrecia el servicio de transporte y tecnologia para copiar y poder aprobar. Por dicho servicio cobraban 1.000 euros. Los investigadores sorprendieron in fraganti a una mujer intentando copiar en el examen. Portaba una chaqueta con dispositivos electronicos ocultos, concretamente un telefono movil al que estaba conectada una camara que habia sido insertada en la parte frontal de la chaqueta para transmitir online el examen y que orientada al ordenador del Centro de Examenes en el que aparecen las preguntas, permitia visualizar las imagenes en otro ordenador alojado en el interior de un vehiculo estacionado en las inmediaciones del centro. En este vehiculo, se encontraban el resto del grupo desarticulado con varios ordenadores portatiles y tablets abiertos y conectados a paginas de test de la DGT para consultar las respuestas. Estos, comunicaban con la mujer que estaba en el aula haciendo el examen a traves de un diminuto receptor bluetooth que portaba en el interior de su oido.  Luis de Lama, portavoz de la Guardia Civil de Trafico destaca que los ciudadanos, eran de origen chino, y copiaban en el examen utilizando la tecnologia facilitada por una organizacion. Destaca que, ademas de parte del fraude que supone copiar en un examen muchos de estos ciudadanos desconocian el idioma, no hablan ni entienden el español lo que supone un grave riesgo para la seguridad vial por desconocer las señales y letreros que avisan en carretera de muchas incidencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c44237",
      "metadata": {
        "id": "d1c44237"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"La Guardia Civil ha desarticulado un grupo organizado dedicado a copiar en los examenes teoricos para la obtencion del permiso de conducir. Para ello, empleaban receptores y camaras de alta tecnologia y operaban desde la misma sede del Centro de examenes de la Direccion General de Trafico (DGT) en Mostoles. Es lo que han llamado la Operacion pinga. El grupo desarticulado ofrecia el servicio de transporte y tecnologia para copiar y poder aprobar. Por dicho servicio cobraban 1.000 euros. Los investigadores sorprendieron in fraganti a una mujer intentando copiar en el examen. Portaba una chaqueta con dispositivos electronicos ocultos, concretamente un telefono movil al que estaba conectada una camara que habia sido insertada en la parte frontal de la chaqueta para transmitir online el examen y que orientada al ordenador del Centro de Examenes en el que aparecen las preguntas, permitia visualizar las imagenes en otro ordenador alojado en el interior de un vehiculo estacionado en las inmediaciones del centro. En este vehiculo, se encontraban el resto del grupo desarticulado con varios ordenadores portatiles y tablets abiertos y conectados a paginas de test de la DGT para consultar las respuestas. Estos, comunicaban con la mujer que estaba en el aula haciendo el examen a traves de un diminuto receptor bluetooth que portaba en el interior de su oido.  Luis de Lama, portavoz de la Guardia Civil de Trafico destaca que los ciudadanos, eran de origen chino, y copiaban en el examen utilizando la tecnologia facilitada por una organizacion. Destaca que, ademas de parte del fraude que supone copiar en un examen muchos de estos ciudadanos desconocian el idioma, no hablan ni entienden el español lo que supone un grave riesgo para la seguridad vial por desconocer las señales y letreros que avisan en carretera de muchas incidencias. \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91e1ecd",
      "metadata": {
        "id": "e91e1ecd"
      },
      "source": [
        "Veamos el resumen del texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc2a11c",
      "metadata": {
        "id": "6cc2a11c"
      },
      "outputs": [],
      "source": [
        "res = model(text)\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf484093",
      "metadata": {
        "id": "cf484093"
      },
      "source": [
        "El resultado contiene un único campo:\n",
        "\n",
        "- `summary_text`: texto resumido."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6702b2a9",
      "metadata": {
        "id": "6702b2a9"
      },
      "source": [
        "## **8. Question Answering**\n",
        "---\n",
        "\n",
        "Los modelos de pregunta-respuesta son modelos supervisados que buscan generar una respuesta a una pregunta dada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fba943c",
      "metadata": {
        "cellView": "form",
        "id": "5fba943c"
      },
      "outputs": [],
      "source": [
        "#@markdown ##**Ejecute esta celda para ver el video.**\n",
        "from IPython.display import IFrame\n",
        "IFrame(\n",
        "        src=\"https://drive.google.com/file/d/1Dtppx-D2suNZuo3owGHXdRo0ZRf1kEPE/preview\",\n",
        "        width=\"768px\",\n",
        "        height=\"432px\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e725886a",
      "metadata": {
        "id": "e725886a"
      },
      "source": [
        "El ejemplo anterior muestra uno de los modelos más recientes de transformers aplicado como agente conversacional (una aplicación bastante similar a pregunta-respuesta).\n",
        "\n",
        "Veamos un ejemplo en español:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b01c7ab8",
      "metadata": {
        "id": "b01c7ab8"
      },
      "outputs": [],
      "source": [
        "model = pipeline(\n",
        "    \"question-answering\",\n",
        "    \"PlanTL-GOB-ES/roberta-base-bne-sqac\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9edb82",
      "metadata": {
        "id": "ff9edb82"
      },
      "source": [
        "Bajo el siguiente contexto:\n",
        "\n",
        "El contenido es el siguiente\n",
        "> Alan Mathison Turing (Paddington, Londres; 23 de junio de 1912-Wilmslow, Cheshire; 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo teórico británico. Está considerado uno de los padres de la ciencia de la computación y precursor de la informática moderna. Proporcionó una influyente formalización de los conceptos de algoritmo y computación: la máquina de Turing. Formuló su propia versión que hoy es ampliamente aceptada como la tesis de Church-Turing (1936)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601d8f75",
      "metadata": {
        "id": "601d8f75"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"Alan Mathison Turing (Paddington, Londres; 23 de junio de 1912-Wilmslow, Cheshire; 7 de junio de 1954) fue un matemático, lógico, informático teórico, criptógrafo, filósofo y biólogo teórico británico. Está considerado uno de los padres de la ciencia de la computación y precursor de la informática moderna. Proporcionó una influyente formalización de los conceptos de algoritmo y computación: la máquina de Turing. Formuló su propia versión que hoy es ampliamente aceptada como la tesis de Church-Turing (1936).\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21cedb6a",
      "metadata": {
        "id": "21cedb6a"
      },
      "source": [
        "Vamos a plantear la siguiente pregunta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b1678d1",
      "metadata": {
        "id": "6b1678d1"
      },
      "outputs": [],
      "source": [
        "text = \"¿Quién es el padre de la computación?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf50afa",
      "metadata": {
        "id": "eaf50afa"
      },
      "source": [
        "Veamos la respuesta del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fad98e5",
      "metadata": {
        "id": "1fad98e5"
      },
      "outputs": [],
      "source": [
        "res = model(\n",
        "        question=text,\n",
        "        context=context\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6555cb9",
      "metadata": {
        "id": "c6555cb9"
      },
      "source": [
        "Podemos formular otra pregunta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11c8326",
      "metadata": {
        "id": "b11c8326"
      },
      "outputs": [],
      "source": [
        "text = \"¿Qué profesión tenía Alan Turing?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1954eaf2",
      "metadata": {
        "id": "1954eaf2"
      },
      "source": [
        "Veamos la respuesta del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca4e6a0",
      "metadata": {
        "id": "bca4e6a0"
      },
      "outputs": [],
      "source": [
        "res = model(\n",
        "        question=text,\n",
        "        context=context\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7690976e",
      "metadata": {
        "id": "7690976e"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [HuggingFace](https://huggingface.co/).\n",
        "- [ChatGPT](https://openai.com/blog/chatgpt/).\n",
        "- _Fuente de los íconos_\n",
        "     - Flaticon. Text free icon [PNG]. https://www.flaticon.com/free-icon/text_8356088\n",
        "     - Flaticon. Machine Learning free icon [PNG]. https://www.flaticon.com/free-icon/machine-learning_3806229\n",
        "     - Flaticon. Neural Network free icon [PNG]. https://www.flaticon.com/free-icon/neural-network_6461771\n",
        "     - Flaticon. Question free icon [PNG]. https://www.flaticon.com/free-icon/question_3464867\n",
        "     - Flaticon. Screwdriver free icon [PNG]. https://www.flaticon.com/free-icon/screwdriver_698728\n",
        "     - Flaticon. Abstract free icon [PNG]. https://www.flaticon.com/free-icon/abstract_7444340\n",
        "     - Flaticon. Hangman free icon [PNG]. https://www.flaticon.com/free-icon/hangman_7399647\n",
        "     - Flaticon. Hierarchy free icon [PNG]. https://www.flaticon.com/free-icon/hierarchy_6261577\n",
        "     - Flaticon. Loupe free icon [PNG]. https://www.flaticon.com/free-icon/loupe_4336376\n",
        "     - Flaticon. Virtual Reality free icon [PNG]. https://www.flaticon.com/free-icon/virtual-reality_8055545\n",
        "     - Flaticon. Sports free icon [PNG]. https://www.flaticon.com/free-icon/sports_3311567\n",
        "     - Flaticon. Add file free icon [PNG]. https://www.flaticon.com/free-icon/add-file_3979404\n",
        "     - Flaticon. Document free icon [PNG]. https://www.flaticon.com/free-icon/document_888071\n",
        "     - Flaticon. Happy face free icon [PNG]. https://www.flaticon.com/free-icon/happy-face_5624232\n",
        "     - Flaticon. Review free icon [PNG]. https://www.flaticon.com/free-icon/review_5624236\n",
        "     - Flaticon. Neutral free icon [PNG]. https://www.flaticon.com/free-icon/neutral_3688054\n",
        "     - Flaticon. Process free icon [PNG]. https://www.flaticon.com/free-icon/process_4149680\n",
        "     - Flaticon. Languages free icon [PNG]. https://www.flaticon.com/free-icon/languages_3898150"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "746825a0",
      "metadata": {
        "id": "746825a0"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}