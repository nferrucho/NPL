{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso3/ciclo1/2_semma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7825621f",
      "metadata": {
        "id": "7825621f"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1li4ahmMhPo2cEUVqQKRDA9ahHp2py4Xb\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cea93a",
      "metadata": {
        "id": "b9cea93a"
      },
      "source": [
        "# Sample, Explore, Modify, Model, Assess\n",
        "---\n",
        "\n",
        "En este notebook veremos una introducción práctica a la metodología estadística _Sample, Explore, Modify, Model, Assses_ (SEMMA), la cual se puede ver descrita en el siguiente diagrama:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1NB8u_CC-NmUyKBPiQ-9VFUi_8CdrJZ6q\" width=\"80%\">\n",
        "\n",
        "Para la aplicación de machine learning usaremos dos librerías muy conocidas como `pandas`, para manipulación de datos, y `sklearn`, para modelamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc1f9ba",
      "metadata": {
        "id": "bfc1f9ba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89cdb44",
      "metadata": {
        "id": "e89cdb44"
      },
      "source": [
        "No obstante, usaremos una librería para visualización que es muy común en herramientas estadísticas (por ejemplo en el lenguaje de programación `R`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728936d6",
      "metadata": {
        "id": "728936d6"
      },
      "outputs": [],
      "source": [
        "!pip install plotnine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a620a3",
      "metadata": {
        "id": "25a620a3"
      },
      "source": [
        "## **1. Introducción a Plotnine**\n",
        "---\n",
        "\n",
        "`plotnine` es una librería que implementa [the layered grammar of graphics](https://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf). Se trata de una sintaxis general para definir gráficos estadísticos de una forma sencilla y personalizable.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Fmyhpw_RojLlCnlfoUAozI-HZa-MBM5j\" width=\"60%\">\n",
        "\n",
        "`plotnine` por detrás utiliza `matplotlib` para generar gráficas, de hecho podemos ver una comparativa con sus librerías hermanas:\n",
        "\n",
        "- `matplotlib`: altamente personalizable pero requiere mucho código.\n",
        "- `seaborn`: poco personalizable pero requiere muy poco código.\n",
        "- `plotnine`: intermedio entre `seaborn` y `matplotlib`, es decir, no requiere tanto código y permite cierto grado de personalización.\n",
        "\n",
        "_The layered grammar of graphics_ se conoce popularmente por el paquete `ggplot` de `R`, no obstante, con `plotnine` lo podemos usar desde _Python_. La creación de una gráfica con esta metodología consiste en dividir un gráfico estadístico en 7 capas:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ZUblbDVFBTFQqvPm0-GXE8zD_njKtVAa\" width=\"50%\">\n",
        "\n",
        "Estas capas nos permiten personalizar gráficos a distintos niveles:\n",
        "\n",
        "- **Datos**: consiste en especificar la fuente de datos para los gráficos.\n",
        "- **Aestética**: permite especificar qué elementos serán visibles en la gráfica, por ejemplo, qué va en el eje `x` y qué va en el eje `y`.\n",
        "- **Geometrías**: permite especificar el tipo de gráfico que generaremos, por ejemplo, diagramas de barras, nubes de puntos, entre otros.\n",
        "- **Facetas**: permite dividir el gráfico en distintos paneles (equivalente a los `subplots` de `matplotlib`).\n",
        "- **Estadísticos**: permiten realizar operaciones estadísticas sobre los datos.\n",
        "- **Coordenadas**: permite modificar los ejes coordenados de la visualización (coordenadas polares, escalas logarítmicas, entre otros).\n",
        "- **Tema**: permite personalizar paletas de colores, fuentes del texto, entre otros.\n",
        "\n",
        "Veamos un ejemplo sencillo de `plotnine` antes de continuar con la parte metodológica, primero importamos las funciones que necesitamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c325bc6d",
      "metadata": {
        "id": "c325bc6d"
      },
      "outputs": [],
      "source": [
        "from plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n",
        "from plotnine.data import mtcars"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0375caf1",
      "metadata": {
        "id": "0375caf1"
      },
      "source": [
        "Veamos el conjunto de datos de ejemplo que provee `plotnine`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3964fe",
      "metadata": {
        "id": "af3964fe"
      },
      "outputs": [],
      "source": [
        "display(mtcars)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "232039e8",
      "metadata": {
        "id": "232039e8"
      },
      "source": [
        "[Motor Trend Car Road Tests](https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars) (mtcars) es un conjunto de datos que contiene información del consumo de combustible en 10 aspectos relacionados al diseño y desempeño de 32 automóviles. Tenemos las siguientes variables:\n",
        "\n",
        "- `mpg`: millas por galón.\n",
        "- `cyl`: número de cilindros.\n",
        "- `disp`: desplacamiento.\n",
        "- `hp`: caballos de fuerza.\n",
        "- `drat`: relación del eje trasero o diferencial.\n",
        "- `wt`: peso.\n",
        "- `qsec`: tiempo de cuarto de milla.\n",
        "- `vs`: tipo de motor (0 = motor en v, 1 = motor recto).\n",
        "- `am`: tipo de transmisión (0 = automático, 1 = manual).\n",
        "- `gear`: número de engranajes delanteros.\n",
        "\n",
        "Podemos generar una gráfica con `plotnine` para ver relaciones entre el peso y las millas por galón. Veamos cómo se genera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41e1ccc",
      "metadata": {
        "id": "c41e1ccc"
      },
      "outputs": [],
      "source": [
        "fig = (\n",
        "        ggplot(mtcars, aes(x=\"wt\", y=\"mpg\", color=\"factor(gear)\")) +\n",
        "        geom_point() +\n",
        "        stat_smooth(method=\"lm\") +\n",
        "        facet_wrap(\"~gear\")\n",
        "        )\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4c917d",
      "metadata": {
        "id": "eb4c917d"
      },
      "source": [
        "En este caso:\n",
        "\n",
        "- Definimos un objeto `ggplot` especificando los datos `mtcars` y la aestética `aes`.\n",
        "- Con `\"factor(gear)\"` convertimos la columna `gear` a categorías.\n",
        "- `geom_point` define una geometría de nube de puntos (`scatter`).\n",
        "- `stat_smooth` define que se debe mostrar un modelo lineal `lm` sobre los datos.\n",
        "- `facet_wrap` define que la gráfica se debe dividir en varios paneles de acuerdo a lo que contenga el campo `gear`.\n",
        "\n",
        "Esta librería nos será de mucha ayuda para definir visualizaciones estadísticas en la metodología _SEMMA_, vamos a importar las funciones que necesitaremos de `plotnine`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc35a5c3",
      "metadata": {
        "id": "cc35a5c3"
      },
      "outputs": [],
      "source": [
        "from plotnine import (\n",
        "        ggplot, aes, facet_wrap, geom_density,\n",
        "        geom_tile, geom_boxplot, theme, element_text\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c5774b",
      "metadata": {
        "id": "a6c5774b"
      },
      "source": [
        "## **2. Contexto**\n",
        "---\n",
        "\n",
        "En este caso implementaremos una metodología para encontrar distintos perfiles de contaminación de productos alimenticios, para ello utilizaremos el conjunto de datos [food product emissions en Kaggle](https://www.kaggle.com/amandaroseknudsen/foodproductemissions).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1m3RV-gtqiaugZ5xvOBRwt9KmOcV7Brct\" width=\"80%\">\n",
        "\n",
        "Para algunos de los productos alimenticios más comunes en todo el mundo, se ha encontrado que las emisiones de gases de efecto invernadero (GEI) producidos puede tener distintas causas que van desde la cadena de valor de los alimentos, cambio de uso de la tierra o LUC, hasta el comercio minorista (punto de compra/adquisición del usuario final).\n",
        "\n",
        "Algo importante a tener en cuenta es que hay variaciones en las emisiones generadas de un mismo producto y distintos productos. Esto se debe fundamentalmente a factores como la región geográfica y el perfil ecológico del sistema de producción, el tamaño y el tipo de sistema de producción, entre otros. Este conjunto de datos utiliza la media global de GEI por tipo de alimento, esto con el fin de permitir un análisis más robusto.\n",
        "\n",
        "Las emisiones de GEI se miden en kg de CO2 por kg de alimentos producidos.\n",
        "\n",
        "> `kg CO2` = Kilogramo de dióxido de carbono.\n",
        "    \n",
        "Cargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "966fae41",
      "metadata": {
        "id": "966fae41"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/mindlab-unal/mlds6-datasets/main/u1/food_emissions.csv\", index_col=0)\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2008966f",
      "metadata": {
        "id": "2008966f"
      },
      "source": [
        "El conjunto de datos tiene los siguientes campos:\n",
        "\n",
        "- `product`: nombre del alimento.\n",
        "- `land`: cambio de uso en la tierra.\n",
        "- `feed`: emisión en alimentos (para animales).\n",
        "- `farm`: emisión en granja.\n",
        "- `processing`: emisión en procesamiento del producto.\n",
        "- `transport`: emisión por transporte.\n",
        "- `packaging`: emisión por empaquetado.\n",
        "- `retail`: emisión por venta en tiendas minoristas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66e748f4",
      "metadata": {
        "id": "66e748f4"
      },
      "source": [
        "## **3. Sample**\n",
        "---\n",
        "\n",
        "En la etapa de muestreo o _sample_ debemos seleccionar la muestra sobre la que realizaremos el estudio y determinar las variables de interés para el problema.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ynp-FLIFxK7sJBArOxoPPChdig3vo5fb\" width=\"80%\">\n",
        "\n",
        "En este caso, como es un conjunto de datos pequeño (43 registros) podemos usar la totalidad de las muestras, no obstante, vamos a diferenciar las variables numéricas de las categóricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfedbc8",
      "metadata": {
        "id": "3dfedbc8"
      },
      "outputs": [],
      "source": [
        "numeric_variables = [\n",
        "        \"land\", \"feed\", \"farm\", \"processing\",\n",
        "        \"transport\", \"packaging\", \"retail\"\n",
        "        ]\n",
        "category_variables = [\"product\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1805ba68",
      "metadata": {
        "id": "1805ba68"
      },
      "source": [
        "## **4. Explore**\n",
        "---\n",
        "\n",
        "La etapa de exploración consiste en encontrar descriptivos de las variables, determinar correlaciones y distribuciones.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1vRAmSKl03nSoCVOk5GLQoBdXX7G7c8Vz\" width=\"80%\">\n",
        "\n",
        "Comenzamos generando descriptivos de las variables numéricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b992b01",
      "metadata": {
        "id": "4b992b01"
      },
      "outputs": [],
      "source": [
        "display(data[numeric_variables].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb91fe91",
      "metadata": {
        "id": "eb91fe91"
      },
      "source": [
        "Con esto, nos hacemos a una idea de la escala de las variables. De aquí identificamos la necesidad de escalar los datos, debido a las diferencias de magnitudes entre distintas variables.\n",
        "\n",
        "Ahora, vamos a visualizar la distribución de las variables. Para ello crearemos un gráfico de kernel de densidad con la librería `plotnine`.\n",
        "\n",
        "Para generar la gráfica realizamos el siguiente proceso:\n",
        "\n",
        "- Pivoteamos el dataframe con la función `melt` para que las variables de interés queden normalizadas (tabla vertical donde la selección de columnas se hace con un filtro y no por nombre de columna).\n",
        "- Agregamos una aestética indicando que tendremos la magnitud de cada variable en el eje `x` y diferenciaremos entre campos por color.\n",
        "- Agregamos un gráfico de kernel de densidad sin leyenda.\n",
        "- Dividimos en distintos paneles de acuerdo a el tipo de variable.\n",
        "\n",
        "Veamos el código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5577acc",
      "metadata": {
        "id": "c5577acc"
      },
      "outputs": [],
      "source": [
        "fig = (\n",
        "        ggplot(\n",
        "            data.pipe(\n",
        "                pd.melt,\n",
        "                id_vars = category_variables,\n",
        "                value_vars = numeric_variables\n",
        "                ),\n",
        "            aes(x = \"value\", color = \"variable\")\n",
        "            ) +\n",
        "        geom_density(show_legend = False) +\n",
        "        facet_wrap(\"~variable\")\n",
        "        )\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a278326f",
      "metadata": {
        "id": "a278326f"
      },
      "source": [
        "También podemos visualizar la matriz de correlación entre las variables numéricas. Para generar la gráfica debemos realizar el siguiente proceso:\n",
        "\n",
        "- Calculamos la matriz de correlación con el método `corr` y lo pivoteamos con la función `melt`.\n",
        "- Agregamos una aestética indicando qué valores están en el eje `x` y cuáles en el eje `y`. El parámetro `fill` indica que vamos a colorear usando la magnitud de los datos.\n",
        "- Con `geom_tile` mostramos puntos en el espacio en forma de rectángulos.\n",
        "- Agregamos un tema especificando que el texto del eje `x` debe rotar 90 grados.\n",
        "\n",
        "Veamos la gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644cf4df",
      "metadata": {
        "id": "644cf4df"
      },
      "outputs": [],
      "source": [
        "fig = (\n",
        "        ggplot(\n",
        "            (\n",
        "                data\n",
        "                .filter(numeric_variables)\n",
        "                .corr()\n",
        "                .reset_index()\n",
        "                .pipe(pd.melt, id_vars = [\"index\"], value_vars = numeric_variables)\n",
        "                ),\n",
        "            aes(x = \"index\", y = \"variable\", fill = \"value\")\n",
        "            ) +\n",
        "        geom_tile() +\n",
        "        theme(axis_text_x = element_text(rotation = 90))\n",
        "        )\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c4d821",
      "metadata": {
        "id": "54c4d821"
      },
      "source": [
        "Podemos ver que la variable `farm` tiene una correlación alta (mayor a 0.5) con  `land` y `processing`, esto tiene sentido debido a que muchos de los productos de granja requieren cierto uso de tierra y tratamiento posterior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c894d97e",
      "metadata": {
        "id": "c894d97e"
      },
      "source": [
        "## **5. Modify**\n",
        "---\n",
        "\n",
        "La etapa de modificación consiste en la limpieza y re-escalamiento de los datos.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1lfYVk_gnF5O88-O0R2sFycBqk4EMox4-\" width=\"80%\">\n",
        "\n",
        "En este caso, realizaremos un _Z-scaling_ de las variables numéricas para que queden con media 0 y desviación estandar 1 por medio del `StandardScaler` de `sklearn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83ea7a5",
      "metadata": {
        "id": "d83ea7a5"
      },
      "outputs": [],
      "source": [
        "transformer = StandardScaler()\n",
        "features = transformer.fit_transform(data.filter(numeric_variables))\n",
        "label = data.filter(category_variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c25e1e4",
      "metadata": {
        "id": "2c25e1e4"
      },
      "source": [
        "Con esto, obtenemos una matriz numérica `features` con las siguientes dimensiones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaaa172",
      "metadata": {
        "id": "ddaaa172"
      },
      "outputs": [],
      "source": [
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f46e3e0",
      "metadata": {
        "id": "1f46e3e0"
      },
      "source": [
        "También obtenemos el listado de productos sobre el que haremos un análisis posterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be6bc4e",
      "metadata": {
        "id": "6be6bc4e"
      },
      "outputs": [],
      "source": [
        "display(label.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d2849f",
      "metadata": {
        "id": "64d2849f"
      },
      "source": [
        "## **6. Model**\n",
        "---\n",
        "\n",
        "La etapa de modelamiento consiste en la definición y ajuste de un modelo.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1s69sNpUxMQ6CzR0r7_GJsFZBBuAObHWT\" width=\"80%\">\n",
        "\n",
        "En este caso, para determinar perfiles de alimentos por emisiones usaremos el modelo `KMeans`. Adicional a esto, deseamos encontrar 8 perfiles de productos para su posterior análisis (en caso de no saber cuántos clusters o perfiles deseamos obtener, debemos hacer una exploración con métricas como el coeficiente de silueta o el índice de Davies-Bouldin)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1430723c",
      "metadata": {
        "id": "1430723c"
      },
      "outputs": [],
      "source": [
        "model = (\n",
        "        KMeans(n_clusters = 8, random_state=42)\n",
        "        .fit(features)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb109ae0",
      "metadata": {
        "id": "eb109ae0"
      },
      "source": [
        "## **7. Assess**\n",
        "---\n",
        "\n",
        "Por último, en la etapa de evaluación debemos analizar los resultados obtenidos y calcular indicadores clave de rendimiento (KPI) en caso de ser posible.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1iL-OtG_aOWxmBwOZ-t_96IZwmTrDGmiY\" width=\"80%\">\n",
        "\n",
        "La evaluación suele ir acompañada con un diseño experimental para evaluar los modelos entrenados y determinar su aplicabilidad en el mundo real. En nuestro caso, haremos un análisis más descriptivo para interpretar los 8 perfiles de alimentos encontrados y sus distribuciones.\n",
        "\n",
        "Para ello, vamos a crear un nuevo `DataFrame` con las características que obtuvimos y los clusters encontrados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72208a2a",
      "metadata": {
        "id": "72208a2a"
      },
      "outputs": [],
      "source": [
        "new_data = (\n",
        "        pd.DataFrame(\n",
        "            data = features,\n",
        "            columns = numeric_variables\n",
        "            )\n",
        "        .assign(\n",
        "            clusters = model.predict(features),\n",
        "            product = label\n",
        "            )\n",
        "        )\n",
        "display(new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c01c86cb",
      "metadata": {
        "id": "c01c86cb"
      },
      "source": [
        "Podemos generar una visualización de la distribución de las variables en cada uno de los perfiles encontrados, para ello realizamos el siguiente proceso:\n",
        "\n",
        "- Normalizamos el conjunto de datos con la función `melt`.\n",
        "- Agregamos una geometría de tipo diagrama de cajas y bigotes.\n",
        "- Dividimos en distintos paneles por cluster o perfil.\n",
        "- Agregamos un tema con el texto del eje `x` rotado.\n",
        "\n",
        "Veamos la gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb68b27",
      "metadata": {
        "id": "bdb68b27"
      },
      "outputs": [],
      "source": [
        "fig = (\n",
        "        ggplot(\n",
        "            new_data.pipe(pd.melt, value_vars = numeric_variables, id_vars = \"clusters\"),\n",
        "            aes(x = \"variable\", y = \"value\", color = \"factor(clusters)\")\n",
        "            ) +\n",
        "        geom_boxplot() +\n",
        "        facet_wrap(\"~clusters\") +\n",
        "        theme(axis_text_x = element_text(rotation = 90))\n",
        "        )\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "850070e6",
      "metadata": {
        "id": "850070e6"
      },
      "source": [
        "Con esto, podemos ver que hay perfiles como:\n",
        "\n",
        "- Cluster 2 con niveles altos de alimentación `feed` y `retail`\n",
        "- Cluster 5 con niveles altos de transporte.\n",
        "- Cluster 7 con niveles bajos de tierra y empaquetado.\n",
        "\n",
        "Podemos ver de una forma más clara los productos asociados a cada perfil por medio de una matriz de contingencia, para generarla debemos seguir el siguiente proceso:\n",
        "\n",
        "- Generamos la matriz de contingencia entre los clusters encontrados y los nombres de los alimentos con la función `crosstab`.\n",
        "- Normalizamos los datos con la función `melt`.\n",
        "- Especificamos el eje `x` para los perfiles y el eje `y` para el tipo de alimento con una aestética.\n",
        "- Agregamos un gráfico por rectángulos con `geom_tile`.\n",
        "- Agregamos un tema con el texto del eje `x` rotado.\n",
        "\n",
        "Veamos la gráfica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122f48ef",
      "metadata": {
        "id": "122f48ef"
      },
      "outputs": [],
      "source": [
        "cross = pd.crosstab(new_data[\"clusters\"], new_data[\"product\"])\n",
        "categories = cross.columns\n",
        "fig = (\n",
        "        ggplot(\n",
        "            (\n",
        "                cross\n",
        "                .reset_index()\n",
        "                .pipe(pd.melt, id_vars = [\"clusters\"], value_vars = categories)\n",
        "                ),\n",
        "            aes(x = \"clusters\", y = \"product\", fill = \"value\")\n",
        "            ) +\n",
        "        geom_tile() +\n",
        "        theme(axis_text_x = element_text(rotation = 90))\n",
        "        )\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b293415c",
      "metadata": {
        "id": "b293415c"
      },
      "source": [
        "De esta gráfica podemos ver patrones en los perfiles:\n",
        "\n",
        "- Cluster 5 contiene productos derivados del azúcar como `Beet Sugar` o `Cane Sugar`.\n",
        "- Cluster 3 contiene productos similares en producción al aceite como `Sunflower Oil`, `Soybean Oil` o `Rapeseed Oil`.\n",
        "- Cluster 0 contiene productos que necesitan tierra para producirse como frutas, verduras o legumbres.\n",
        "\n",
        "Estos perfiles pueden ser de gran utilidad para interpretación de un conjunto de datos y para estudios un poco más estadísticos. No obstante, a pesar de que muchas etapas de la metodología _SEMMA_ tienen su equivalente con otras metodologías de ciencia de datos, su enfoque es más estadístico."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93700df",
      "metadata": {
        "id": "d93700df"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [Sklearn](https://scikit-learn.org/)\n",
        "- [Plotnine](https://plotnine.readthedocs.io/en/stable/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c8a1ff",
      "metadata": {
        "id": "09c8a1ff"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "**Profesor**\n",
        "\n",
        "- [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "\n",
        "**Asistente docente**:\n",
        "\n",
        "- [Juan S. Lara MSc](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/)\n",
        "\n",
        "**Diseño de imágenes:**\n",
        "\n",
        "- [Brian Chaparro Cetina](mailto:bchaparro@unal.edu.co).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}