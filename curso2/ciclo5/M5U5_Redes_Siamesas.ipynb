{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso2/ciclo5/M5U5_Redes_Siamesas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1Hh_G3M13P9xSNgSiQ-WnALg93XwK_hG8\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ],
      "metadata": {
        "id": "m-4wp9J5S2dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Redes Siamesas**\n",
        "---"
      ],
      "metadata": {
        "id": "zVXv3RzMhofC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introducción**\n",
        "---\n",
        "Una red neuronal siamesa (SNN - _Siamese Neural Network_) es una clase de arquitectura de red neuronal que contiene **dos o más subredes _idénticas_** en paralelo. _Idénticas_ significa que tienen la misma configuración con los mismos parámetros y pesos, y además que la actualización durante el entrenamiento de los parámetros se refleja igual en ambas subredes.\n",
        "\n",
        "A grandes rasgos, un modelo de este tipo se utiliza para aprender a reconocer la **similitud** (o diferencia) entre las muestras de un conjunto de datos comparando sus vectores de características, por lo que sus aplicaciones son amplias.\n",
        "\n",
        "- El siguiente es un esquema básico de un modelo de red siamesa:\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1WssDwZIEWUXlkitVpPhkiWgqUh6HRG4F\" alt = \"Gráfico ilustrativo del esquema básico de un modelo de red siamesa  \" width=\"54%\" /></center>\n",
        "\n",
        "- El modelo tiene dos entradas, cada una pasa por un modelo base de red neuronal exactamente igual, y las salidas de ese modelo se comparan según la función de pérdida, para al final determinar si las entradas son similares o no.\n",
        "\n",
        "**Nota**: el modelo que se replica en cada rama se escoge dependiendo de la tarea. Su labor va a ser la de un **extractor de características**. Entonces, si vamos a trabajar con imágenes, muy seguramente debemos usar una red convolucional. Pero si vamos a trabajar con textos, podemos usar una red recurrente o el _encoder_ de un _transformer_.\n",
        "\n",
        "### **Un cambio de enfoque**\n",
        "\n",
        "Tradicionalmente, una red neuronal aprende a predecir múltiples clases. Esto plantea un problema cuando necesitamos añadir o eliminar nuevas clases a los datos. En este caso, tenemos que actualizar la red neuronal y volver a entrenarla en todo el conjunto de datos. Además, las redes neuronales profundas necesitan un gran volumen de datos para entrenarse.\n",
        "\n",
        "- En cambio, **las redes siamesas aprenden una función de similitud**. Así, podemos entrenarla para ver si dos imágenes son iguales, o pertenecen a la misma clase. Esto nos permite, por ejemplo, clasificar nuevas clases de datos sin necesidad de volver a entrenar la red.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OITIZy9fS7ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ventajas e inconvenientes de las redes siamesas**\n",
        "\n",
        "Las principales ventajas de las redes siamesas son:\n",
        "\n",
        "*    **Tienen más resistencia al desbalanceo de clases**: Con la ayuda de técnicas de aprendizaje como _One-shot learning_, dadas unas pocas muestras por clase es suficiente para que las redes siamesas reconozcan esas imágenes en el futuro.\n",
        "*    **Aprendizaje por similitud semántica**: Las redes siamesas se centran en el aprendizaje de representaciones en espacios vectoriales donde (se espera que) los elementos de las mismas clases o conceptos estén _cerca_, y los elementos de clases diferentes estén _lejos_. Por lo tanto, puede aprender la similitud semántica. Lo _cerca_ o lo _lejos_ que queden dos muestras del conjunto de datos en el espacio de representación depende de la función de similitud que se use.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1CNgdo3ZQL0HJgm8naRo2WMBhK2PlfB7r\"  alt = \"Gráfico ilustrativo de una red neuronal siamesa y una red neuronal convolucional en un espacio vectorial \" width=\"48%\" /></center>\n",
        "\n",
        "Los inconvenientes de las redes siamesas pueden ser:\n",
        "\n",
        "*    **Necesitan más tiempo de entrenamiento que las redes normales**: Dado que las redes siamesas requieren pares cuadráticos para aprender (para ver toda la información disponible), son más lentas que las redes normales de clasificación.\n",
        "*    **No genera probabilidades**: Al tratarse de un aprendizaje por pares, no muestra las probabilidades de la predicción, sino la distancia a cada clase.\n",
        "\n"
      ],
      "metadata": {
        "id": "SmuqE3V8h-om"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **¿En qué situaciones puede ser útil una red siamesa?**\n",
        "\n",
        "Aunque se utilizan mucho en campos como el reconocimiento facial, las redes siamesas no se limitan al ámbito de las imágenes. Son muy populares en **NLP (Procesamiento de Lenguaje Natural)**, donde se pueden utilizar para identificar duplicados, textos que tratan el mismo tema, o incluso identificar si dos textos son del mismo estilo o autor. También pueden utilizarse para reconocer archivos de audio, por ejemplo, para comparar voces y saber si pertenecen a la misma persona.\n",
        "\n",
        "**Aplicaciones de las redes siamesas:**\n",
        "\n",
        "*    Verificación de firmas.\n",
        "*    Reconocimiento facial.\n",
        "*    Comparación de huellas dactilares.\n",
        "*    Evaluar la gravedad de una enfermedad basándose en la clasificación clínica.\n",
        "*    Similitud textual para emparejar el perfil de un puesto de trabajo con el currículum vitae.\n",
        "*    Similitud de texto para emparejar preguntas similares."
      ],
      "metadata": {
        "id": "_e56aKdn7Btm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Funcionamiento de una Red Siamesa**\n",
        "\n",
        "El proceso de entrenamiento y evaluación son, en principio, iguales a los de cualquier modelo de _Machine Learning_. Lo diferente es el **tratamiento que se le da a los datos y cómo se alimenta el modelo**. Si tenemos un conjunto de imágenes para una tarea de reconocimiento facial, es necesario hacer parejas de fotos: el modelo se entrena a partir de ver varias imágenes al tiempo, porque necesita aprender a comparar. Por ejemplo, en el caso de reconocimiento facial, cada pareja de fotos tiene solo dos opciones:\n",
        "\n",
        "*   Pertenecen a la misma persona (distancia = $0$), o\n",
        "*   Pertenecen a personas diferentes (distancia = $1$).\n",
        "\n",
        "es decir, **la tarea al final se convierte en una clasificación binaria**.\n",
        "\n",
        "Pero puede ser que nos interese tener una medida de similitud menos categórica. Por ejemplo, si tenemos imágenes de diferentes estadios progresivos de una misma enfermedad. En este caso habrá varias distancias posibles, y la tarea final va a ser una regresión.\n",
        "\n",
        "- De forma análoga, la evaluación es diferente a la que se hace para un modelo normal de clasificación. **Se deben construir parejas de datos de clases iguales y parejas de clases diferentes**, y evaluar la capacidad del modelo de reconocer la similitud o no similitud de los elementos en cada pareja.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l6neyTE7eypU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Entrenamiento de la red neuronal siamesa**\n",
        "\n",
        "Repasemos los detalles importantes al momento de entrenar un modelo de red siamesa:\n",
        "\n",
        "*    Cargue el conjunto de datos que contiene las diferentes clases.\n",
        "*    Cree pares de datos que cubran el espectro de posibilidades de comparación.\n",
        "*    Construya el modelo de aprendizaje de representación. Este puede ser una CNN para imágenes, o un codificador tipo _Transformer_ para textos, o lo que mejor se ajuste a los datos y a la tarea a resolver. Este modelo será la base de los siameses a través de la cual pasaremos los datos.\n",
        "*    Construya la capa de diferenciación para calcular la distancia entre las dos redes hermanas que codifican la salida.\n",
        "*    Compile el modelo utilizando la entropía cruzada binaria (si solo hay dos clases posibles) o una función de pérdida de regresión (si queremos aproximar directamente una función de similitud), o alguna de las funciones de pérdida que veremos a continuación."
      ],
      "metadata": {
        "id": "xvOwKcOf6bKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluación de la red neuronal siamesa**\n",
        "\n",
        "*    Envíe dos entradas al modelo entrenado para obtener la puntuación de similitud.\n",
        "*    Si solo hay dos clases posibles, use métricas de clasificación sobre el conjunto de parejas de datos. Si hay más de dos clases, o la medida de diferencia no es categórica, use métricas de regresión para evaluar el desempeño.\n"
      ],
      "metadata": {
        "id": "YBKFKSnk6bN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Funciones de pérdida**\n",
        "\n",
        "Queremos entrenar un modelo para minimizar la distancia entre muestras de la misma clase y aumentar la distancia entre clases. Aunque una simple distancia euclidiana puede ser la base de una buena función de pérdida para nuestro problema, existen varios tipos de funciones de similitud a través de las cuales se puede hacer un mejor trabajo diferenciando entre pares de muestras. Dos de las más comunes son la pérdida contrastiva (**_contrastive loss_**) y la pérdida de triplete (**_triplet loss_**).\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1jl27ZOQpSu0ybmTRgJii14xWfhCp6eTu\"  alt = \"Gráfico ilustrativo de las funciones de perdida contrastive loss y triplet loss \" width=\"90%\" /></center>"
      ],
      "metadata": {
        "id": "SEmfWNa-62v5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **_Contrastive Loss_**\n",
        "\n",
        "En la pérdida contrastiva, se toman pares de datos:\n",
        "\n",
        "* Para pares de la misma clase, el modelo debe predecir $1$.\n",
        "* Para pares diferentes, el modelo debe predecir $0$.\n",
        "\n",
        "La función de pérdida se define entonces por:\n",
        "\n",
        "$$L = y * D^2 + (1-y) * \\max\\{margen - D, 0\\}^2 ,$$\n",
        "\n",
        "donde $y$ es la predicción del modelo, $D$ es la distancia (calculada por el modelo) entre las características de la muestra (que puede ser la distancia euclidiana) y $margen$ es un parámetro que nos ayuda a controlar la separación entre las distintas clases.\n",
        "\n",
        "* Si $y≈1$, entonces $L≈D^2$. Es decir, si la pareja de datos es de la misma clase, la distancia se minimiza. Si $y≈0$, entonces $L≈\\max\\{margen - D, 0\\}^2$. Es decir, si la pareja de datos es de clases diferentes, la distancia tiende a maximizarse y tiende a ser mayor que $margen$.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1YTjziO9l-Er9Qs_OQvKmrO0rS01HBk-3\" alt = \"Gráfico ilustrativo de la función de perdida contrastive loss \" width=\"48%\" /></center>"
      ],
      "metadata": {
        "id": "duVHA9-O656l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **_Triplet Loss_**\n",
        "\n",
        "La pérdida de triplete fue introducida por Google en 2015 para el reconocimiento facial. Aquí, el modelo toma tres entradas:\n",
        "\n",
        "* **Un ancla** : Es una entrada de referencia.\n",
        "* **Un ejemplo positivo** : La entrada positiva pertenece a la misma clase que la entrada de anclaje.\n",
        "* **Un ejemplo negativo** : La entrada negativa pertenece a una clase aleatoria distinta de la clase de anclaje.\n",
        "\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1AZ18mNDNJbwPovSJnO2_6TEyZecFzvY8\" alt = \"Gráfico ilustrativo de la función de perdida triplet loss \" width=\"70%\" /></center>\n",
        "\n",
        "La idea que subyace a la función de pérdida de triplete es que **minimizamos la distancia entre el ancla y la muestra positiva** y, simultáneamente, también **maximizamos** la distancia entre el ancla y la muestra negativa.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1SIcFfPFHp556BZF3Z5uzKJA_3zCDYBs8\" alt = \"Gráfico ilustrativo de la minimización de la distancia entre el ancla y la muestra positiva \" width=\"90%\" /></center>\n",
        "\n",
        "\n",
        "Veamos la fórmula matemática de la pérdida del triplete.\n",
        "\n",
        "Si $d$ denota una métrica de distancia (por ejemplo, distancia euclidiana), y queremos que la distancia entre el ancla y la muestra positiva sea ser menor que la distancia entre la muestra negativa y el ancla, debemos tener:\n",
        "\n",
        "$$d(a,p) - d(a,n) < 0.$$\n",
        "\n",
        "La función de pérdida sería entonces minimizar lo siguiente:\n",
        "\n",
        "$$L = d(a,p) - d(a,n).$$\n",
        "\n",
        "Pero para mantenerla positiva, podemos modificarla así:\n",
        "\n",
        "$$L = max(d(a,n) - d(a,p), 0).$$\n",
        "\n",
        "Y para controlar la separación entre muestras positivas y negativas, se introduce un parámetro $margen$. Entonces nos queda:\n",
        "\n",
        "$$L = max(d(a,n) - d(a,p) + margen, 0).$$\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1zOMyTR6qA6YIPw8WOzgoBYYP3Lr6C35g\" alt = \"Gráfico ilustrativo del parámetro margen para la separación entre muestras positivas y negativas \" width=\"90%\" /></center>\n"
      ],
      "metadata": {
        "id": "IS-l1C3bayXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Un ejemplo sencillo**\n",
        "---\n",
        "Este es un problema muy simple para demostrar el concepto detrás de las redes siamesas. Tenemos una base de datos de diferentes formas (triángulos, círculos y rectángulos) con 3 colores diferentes (rojo, verde y azul). Estas formas tienen diferentes tamaños, están en diferentes lugares respecto al borde de la imagen, y están giradas en diferentes ángulos.\n",
        "\n",
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1IerY9Gsoz864rcaTkK_RlX1bcxAkBsfG\"  alt = \"Ejemplo Gráfico de la base de datos de diferentes formas geométricas con 3 colores distintos  \" width=\"50%\" /></center>\n",
        "\n",
        "Queremos **clasificar las imágenes en función de sus colores** aprendiendo una codificación de colores para imágenes. Por simplicidad, vamos a tomar solo 20 muestras de cada color.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mg_hUOy-lbzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Preparar los datos**\n",
        "---\n",
        "Debemos leer las imágenes y generar pares positivos y negativos. Hay dos matrices _NumPy_ que contienen pares de imágenes de tamaño Nx28x28x3. La etiqueta objetivo es `1` si el par es del mismo color y `0` si son de distinto color. Por ejemplo:\n",
        "\n",
        "**Entrada**: triángulo rojo, cuadrado rojo (objetos del mismo color).\n",
        "\n",
        "* **Salida**: 1\n",
        "\n",
        "**Entrada**: triángulo rojo, triángulo azul (objetos de distinto color)\n",
        "\n",
        "* **Salida**: 0\n",
        "\n",
        "Los archivos originales los puede encontrar [aquí](https://github.com/AdityaDutt/MultiColor-Shapes-Database). Sin embargo los vamos a descargar en nuestro entorno con los siguientes comandos :\n"
      ],
      "metadata": {
        "id": "MCeSwEIZmRpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 10WoBy7NgWD3KCaW9YV43PAHSgPHZL3at\n",
        "!unzip '/content/shapes.zip' -d '/content/' > /dev/null"
      ],
      "metadata": {
        "id": "_BC0HMzMtBED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a importar los paquetes necesarios :"
      ],
      "metadata": {
        "id": "i6u3LRWyCHVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, cv2, matplotlib.pyplot as plt, numpy as np, shutil\n",
        "from random import random, randint, seed\n",
        "import random\n",
        "import pickle, itertools, sklearn, pandas as pd, seaborn as sn\n",
        "from scipy.spatial import distance\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from scipy import spatial\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os, sys\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "from keras.layers import Input, Dense, InputLayer, Conv2D, MaxPooling2D, UpSampling2D, InputLayer, Concatenate, Flatten, Reshape, Lambda, Embedding, dot, Dropout\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.model_selection import train_test_split\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "US4rH48BCKra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se preparan pares positivos y negativos de muestras de datos. Vamos a almacenar los datos en `/content/shapes/`. Se preparan datos para distintas formas, pero con colores iguales:"
      ],
      "metadata": {
        "id": "8lPkkESUmyJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/shapes/'\n",
        "\n",
        "images = []\n",
        "y_col = []\n",
        "\n",
        "for root, dirs, files in os.walk(dir, topdown=False):\n",
        "    for name in files:\n",
        "        fullname = os.path.join(root, name)\n",
        "        if fullname.find(\".png\") != -1 :\n",
        "            images.append(fullname)\n",
        "            if fullname.find(\"red\") != -1 :\n",
        "                y_col.append(0)\n",
        "            elif fullname.find(\"blue\") != -1 :\n",
        "                y_col.append(1)\n",
        "            else :\n",
        "                y_col.append(2)\n",
        "\n",
        "y_col = np.array(y_col)\n",
        "images = np.array(images)\n",
        "\n",
        "# Generación de muestras positivas\n",
        "red_im_all = images[np.where(y_col==0)]\n",
        "green_im_all = images[np.where(y_col==1)]\n",
        "blue_im_all = images[np.where(y_col==2)]\n",
        "\n",
        "# Se leen sólo 20 imágenes de cada clase para el entrenamiento\n",
        "red_im = red_im_all[:20]\n",
        "green_im = green_im_all[:20]\n",
        "blue_im = blue_im_all[:20]\n",
        "\n",
        "# Y definimos las imágenes de prueba\n",
        "test_red_im = red_im_all[20:40]\n",
        "test_green_im = green_im_all[20:40]\n",
        "test_blue_im = blue_im_all[20:40]"
      ],
      "metadata": {
        "id": "FeafKLRgKP0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos muestras de parejas de imágenes rojas, azules y verdes:\n",
        "positive_red = list(itertools.combinations(red_im, 2))\n",
        "positive_blue = list(itertools.combinations(blue_im, 2))\n",
        "positive_green = list(itertools.combinations(green_im, 2))\n",
        "\n",
        "# Y generamos muestras negativas\n",
        "negative1 = itertools.product(red_im,green_im)\n",
        "negative1 = list(negative1)\n",
        "negative2 = itertools.product(green_im,blue_im)\n",
        "negative2 = list(negative2)\n",
        "negative3 = itertools.product(red_im,blue_im)\n",
        "negative3 = list(negative3)\n",
        "\n",
        "# Y repetimos todo para las imágenes de prueba\n",
        "test_positive_red = list(itertools.combinations(test_red_im, 2))\n",
        "test_positive_blue = list(itertools.combinations(test_blue_im, 2))\n",
        "test_positive_green = list(itertools.combinations(test_green_im, 2))\n",
        "test_negative1 = itertools.product(test_red_im,test_green_im)\n",
        "test_negative1 = list(test_negative1)\n",
        "test_negative2 = itertools.product(test_green_im,test_blue_im)\n",
        "test_negative2 = list(test_negative2)\n",
        "test_negative3 = itertools.product(test_red_im,test_blue_im)\n",
        "test_negative3 = list(test_negative3)"
      ],
      "metadata": {
        "id": "fQONQp5MKWG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se establece la etiqueta objetivo para ellas.\n",
        "# La salida objetivo es 1 si el par de imágenes tienen el mismo color,\n",
        "# de lo contrario es 0.\n",
        "\n",
        "color_X1 = []\n",
        "color_X2 = []\n",
        "color_y = []\n",
        "positive_samples = positive_blue + positive_green + positive_red\n",
        "negative_samples = negative1 + negative2 + negative3\n",
        "\n",
        "for fname in positive_samples :\n",
        "    im = cv2.imread(fname[0])\n",
        "    color_X1.append(im)\n",
        "    im = cv2.imread(fname[1])\n",
        "    color_X2.append(im)\n",
        "    color_y.append(1)\n",
        "\n",
        "for fname in negative_samples :\n",
        "    im = cv2.imread(fname[0])\n",
        "    color_X1.append(im)\n",
        "    im = cv2.imread(fname[1])\n",
        "    color_X2.append(im)\n",
        "    color_y.append(0)\n",
        "\n",
        "color_y = np.array(color_y)\n",
        "color_X1 = np.array(color_X1)\n",
        "color_X2 = np.array(color_X2)\n",
        "color_X1 = color_X1.reshape((len(negative_samples) + len(positive_samples), 28, 28, 3))\n",
        "color_X2 = color_X2.reshape((len(negative_samples) + len(positive_samples), 28, 28, 3))\n",
        "\n",
        "color_X1 = 1 - color_X1/255\n",
        "color_X2 = 1 - color_X2/255\n",
        "\n",
        "print(\"Color data : \", color_X1.shape, color_X2.shape, color_y.shape)\n",
        "\n",
        "# Guardar los datos de prueba\n",
        "f = open(os.getcwd()+\"/test_images.pkl\", 'wb')\n",
        "pickle.dump([test_red_im, test_blue_im, test_green_im], f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "9t5GzYg5mSoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y repetimos todo para las imágenes de prueba\n",
        "\n",
        "test_color_X1 = []\n",
        "test_color_X2 = []\n",
        "test_color_y = []\n",
        "test_positive_samples = test_positive_blue + test_positive_green + test_positive_red\n",
        "test_negative_samples = test_negative1 + test_negative2 + test_negative3\n",
        "\n",
        "for fname in test_positive_samples:\n",
        "    im = cv2.imread(fname[0])\n",
        "    test_color_X1.append(im)\n",
        "    im = cv2.imread(fname[1])\n",
        "    test_color_X2.append(im)\n",
        "    test_color_y.append(1)\n",
        "\n",
        "for fname in test_negative_samples:\n",
        "    im = cv2.imread(fname[0])\n",
        "    test_color_X1.append(im)\n",
        "    im = cv2.imread(fname[1])\n",
        "    test_color_X2.append(im)\n",
        "    test_color_y.append(0)\n",
        "\n",
        "test_color_y = np.array(test_color_y)\n",
        "test_color_X1 = np.array(test_color_X1)\n",
        "test_color_X2 = np.array(test_color_X2)\n",
        "test_color_X1 = test_color_X1.reshape((len(test_negative_samples) + len(test_positive_samples), 28, 28, 3))\n",
        "test_color_X2 = test_color_X2.reshape((len(test_negative_samples) + len(test_positive_samples), 28, 28, 3))\n",
        "\n",
        "test_color_X1 = 1 - test_color_X1/255\n",
        "test_color_X2 = 1 - test_color_X2/255\n",
        "\n",
        "print(\"Test Color data : \", test_color_X1.shape, test_color_X2.shape, test_color_y.shape)\n",
        "\n",
        "# Guardar los datos de prueba\n",
        "f = open(os.getcwd()+\"/test_images.pkl\", 'wb')\n",
        "pickle.dump([test_red_im, test_blue_im, test_green_im], f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "xXBWxFL7fQc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos algunos pares de imágenes con su respectivo _label_:"
      ],
      "metadata": {
        "id": "GlcvR4oY3J5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "color_X1.shape[0]"
      ],
      "metadata": {
        "id": "BHuJ_fqG-OWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 2, figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    # Seleccionamos una imagen al azar\n",
        "    idx = np.random.randint(color_X1.shape[0])\n",
        "    ax[i, 0].imshow(color_X1[idx]); ax[i, 0].axis(\"off\")\n",
        "    ax[i, 1].imshow(color_X2[idx]); ax[i, 1].axis(\"off\")\n",
        "    ax[i, 0].set_title(f\"label {color_y[idx]}\")"
      ],
      "metadata": {
        "id": "7H4_lUYlxW4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Crear el modelo**\n",
        "---\n",
        "Vamos a definir una función, `train_color_encoder`, que crea, compila, entrena y guarda un modelo siames entrenado con parejas de imágenes `X1, X2` para predecir su similitud `y` como un valor entre 0 y 1:\n"
      ],
      "metadata": {
        "id": "s5RrgA4NnKru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se entrena el autoencoder y se guarda el modelo del encoder  y las\n",
        "# codificaciones\n",
        "def train_color_encoder(X1, X2, y) :\n",
        "\n",
        "    # Encoder o extractor de características, esta es la rama que se duplica\n",
        "    # luego en el modelo siamés\n",
        "    input_layer = Input((28, 28, 3))\n",
        "    layer1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "    layer2 = MaxPooling2D((2, 2), padding='same')(layer1)\n",
        "    layer3 = Conv2D(8, (3, 3), activation='relu', padding='same')(layer2)\n",
        "    layer4 = MaxPooling2D((2, 2), padding='same')(layer3)\n",
        "    layer5 = Flatten()(layer4)\n",
        "    embeddings = Dense(16, activation=None)(layer5)\n",
        "    class NormalizeLayer(tf.keras.Layer):\n",
        "        def call(self, embeddings):\n",
        "            return tf.nn.l2_normalize(embeddings, axis=1)\n",
        "    norm_embeddings = NormalizeLayer()(embeddings)\n",
        "\n",
        "    # Creación del modelo siames\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=norm_embeddings)\n",
        "    # Creación de un modelo siamés:\n",
        "    input1 = Input((28,28,3))\n",
        "    input2 = Input((28,28,3))\n",
        "    # Se crean modelos gemelos derecho e izquierdo\n",
        "    left_model = model(input1)\n",
        "    right_model = model(input2)\n",
        "    # Capa de producto punto\n",
        "    dot_product = dot([left_model, right_model], axes=1, normalize=False)\n",
        "\n",
        "    siamese_model = Model(inputs=[input1, input2], outputs=dot_product)\n",
        "\n",
        "    # Resumen del modelo\n",
        "    print(siamese_model.summary())\n",
        "\n",
        "    # Se compila el modelo\n",
        "    siamese_model.compile(optimizer='adam', loss= 'mse')\n",
        "\n",
        "    # Diagrama de flujo del modelo\n",
        "    plot_model(siamese_model,\n",
        "               to_file=os.getcwd()+'/siamese_model_mnist.png',\n",
        "               show_shapes=1,\n",
        "               show_layer_names=1)\n",
        "\n",
        "    # Se ajusta el modelo\n",
        "    siamese_model.fit([X1, X2],\n",
        "                      y,\n",
        "                      epochs=10,\n",
        "                      batch_size=32\n",
        "                      )\n",
        "\n",
        "    return model, siamese_model"
      ],
      "metadata": {
        "id": "wHqOoXFjnTy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entendamos el modelo. Primero, la base, o el extractor de características de las imágenes:\n",
        "\n",
        "* En primer lugar, agregamos una capa de entrada. Después, las capas convolucionales y de _pooing_: _Conv2D_ y _MaxPool_, respectivamente.\n",
        "* Después de eso, lo \"aplanamos\" (`flatten`) y añadimos una capa densa (hemos normalizado la capa densa después de eso porque estos actuarán como nuestras _features_ o características para las imágenes). Las _features_ son de longitud 16.\n",
        "\n",
        "Después creamos dos instancias del mismo modelo y les pasamos las entradas. El producto punto será la función de similitud de las dos imágenes. Como ya hemos normalizado las características, estarán entre 0 y 1. Por lo tanto, podemos *compararlas fácilmente* con nuestras etiquetas de destino.\n",
        "\n",
        "* La entrada del modelo siamés es una pareja de imágenes, según las hayamos construido anteriormente: `[X1,X2]`.\n",
        "* La salida del modelo siamés es el producto punto de las representaciones de las imágenes.\n",
        "* Usamos _Mean Squared Error_ como función de pérdida, y _Adam_ como optimizador.\n",
        "* Entrenamos durante 100 _epochs_ con un _batch_size_ de 32.\n",
        "\n",
        "**Nota**: Esto se trata de un ejemplo sencillo, por lo que no será tan bueno para imágenes y tareas complejas. Pero, el objetivo de este ejercicio es demostrar las redes siamesas utilizando un ejemplo elemental.\n",
        "\n",
        "Construyamos y entrenemos el modelo:\n"
      ],
      "metadata": {
        "id": "jXU0fcKx4q8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, siamese_model = train_color_encoder(color_X1, color_X2, color_y)"
      ],
      "metadata": {
        "id": "B9aAjc2B0pCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(siamese_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "rUceAFo9mwkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Evaluar el modelo**\n",
        "---\n",
        "Vamos a cargar el modelo y probarlo con imágenes no vistas. Para comprobar la precisión y la separación entre clases, podemos hacer lo siguiente :\n",
        "\n",
        "* En primer lugar, podemos utilizar un modelo de codificador único para codificar una imagen y obtener características que representar gráficamente. Podemos hacer un diagrama de dispersión de estas características para ver su grado de separación.\n",
        "\n",
        "* En segundo lugar, podemos utilizar la salida de la red siamesa (que predice valores entre 1 y 0) para crear una matriz de confusión.\n",
        "\n",
        "Ambas se muestran a continuación :"
      ],
      "metadata": {
        "id": "aCK-ctHpnbBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Se cargan los modelos\n",
        "#model = load_model(os.getcwd()+\"/color_encoder.h5\")\n",
        "#siamese_model = load_model(os.getcwd()+\"/color_siamese_model.h5\")\n",
        "\n",
        "# Se cargan los datos de prueba\n",
        "f = open(os.getcwd()+\"/test_images.pkl\", 'rb')\n",
        "test_red_im, test_blue_im, test_green_im = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "# Se leen los archivos\n",
        "names = list(test_red_im) + list(test_blue_im) + list(test_green_im)\n",
        "names1 = [x for x in names if 'red' in x]\n",
        "names2 = [x for x in names if 'blue' in x]\n",
        "names3 = [x for x in names if 'green' in x]\n",
        "\n",
        "test_im = []\n",
        "for i in range(len(names)) :\n",
        "    test_im.append(cv2.imread(names[i]))\n",
        "\n",
        "r,c,_ = test_im[0].shape\n",
        "test_im = np.array(test_im)\n",
        "test_im = test_im.reshape((len(test_im), r,c,3))\n",
        "names = [x.split(\"/\")[-1] for x in names]\n",
        "\n",
        "test_im = 1 - test_im/255\n",
        "\n",
        "# Predicción\n",
        "pred = model.predict(test_im)\n",
        "\n",
        "num = int(pred.shape[0]/3)\n",
        "colors = ['red', 'blue', 'green'] # Se definen los colores según las etiquetas\n",
        "\n",
        "# Se establecen las etiquetas de destino\n",
        "y = [colors[0] for i in range(num)]\n",
        "y += [colors[1] for i in range(num)]\n",
        "y += [colors[2] for i in range(num)]\n",
        "\n",
        "# Tomamos las primeras tres dimensiones de cada representación\n",
        "feat1 = pred[:,0]\n",
        "feat2 = pred[:,1]\n",
        "feat3 = pred[:,2]\n",
        "\n",
        "# Gráfico de dispersión 3d\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(feat1, feat2, feat3, c=y, marker='.')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JFcZJ7fGnfSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que la representación aprendida es tal que los elementos de cada clase se agrupan, y hay una marcada separación entre los elementos de clases diferentes. Ahora, calculamos la matriz de confusión para las similitudes entre los colores 1 y 2 con `tf.math.confusion_matrix`:"
      ],
      "metadata": {
        "id": "aFz9WJutoJ7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simil_pred = tf.math.round(\n",
        "    siamese_model.predict([test_color_X1, test_color_X2,]))\n",
        "\n",
        "print(tf.math.confusion_matrix(\n",
        "    test_color_y,\n",
        "    simil_pred)\n",
        ")"
      ],
      "metadata": {
        "id": "4bWXLyt3oqPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La clasificación es perfecta!"
      ],
      "metadata": {
        "id": "rtm_blHyr0So"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Un ejemplo más complejo**\n",
        "---\n",
        "Ahora vamos a construir un modelo siamés con _Tensorflow_ capaz de comparar imágenes y devolver una diferencia entre ellas, identificando cuando las imágenes son del mismo tipo. Usaremos el MNIST Dataset de la Digit Recognizer Competition. Este Datset tiene 42000 imágenes de números escritos a mano.\n",
        "\n",
        "- A continuación unas funciones para mostrar las imágenes :\n"
      ],
      "metadata": {
        "id": "SlOsBawEywJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img_dataset(X, y=None, nrows = 4, ncols=4, firstimg=100, numimg=4):\n",
        "    for i in range(numimg):\n",
        "        sp = plt.subplot(nrows, ncols, i + 1)\n",
        "        sp.axis('Off')\n",
        "        plt.imshow(np.squeeze(X[firstimg+i]), cmap=\"Greys\")\n",
        "        if (y is not None):\n",
        "            plt.title(y[firstimg+i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-cldJjYq1w26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función `show_pairs` sirve para mostrar algunos pares seleccionados, sólo para comprobar si están correctamente clasificados:"
      ],
      "metadata": {
        "id": "yxubyud812BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_pairs(X, y, image):\n",
        "    sp = plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.squeeze(X[image][0]))\n",
        "    sp = plt.subplot(1, 2, 2)\n",
        "    plt.imshow(np.squeeze(X[image][1]))\n",
        "    plt.figtext(0.5, 0.01, str(y[image]), wrap=True, horizontalalignment='center', fontsize=12)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sRKVChy6123b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Preparar los datos**\n",
        "---\n",
        "Estamos utilizando el conjunto de datos del concurso https://www.kaggle.com/competitions/digit-recognizer. Se trata de un sencillo conjunto de datos con imágenes de números, del 0 al 9, escritos a mano:"
      ],
      "metadata": {
        "id": "eEXH9xgJ15qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizamos pandas para leer los archivos csv que contienen los datos\n",
        "\n",
        "!wget = https://drive.google.com/uc?id=1q3aFqOpXluMQLDnU2S5WlYq7j9-YMyNZ\n",
        "train_df = pd.read_csv('/content/uc?id=1q3aFqOpXluMQLDnU2S5WlYq7j9-YMyNZ')\n",
        "\n",
        "!wget = https://drive.google.com/uc?id=1Qhj3e4mfZh99fAVpNLNhy1oycyb7vFBk\n",
        "test_df = pd.read_csv('/content/uc?id=1Qhj3e4mfZh99fAVpNLNhy1oycyb7vFBk')"
      ],
      "metadata": {
        "id": "iwnJhdR_xxWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se obtienen las características y etiquetas.\n",
        "X = train_df.drop('label', axis=1)\n",
        "y_train = train_df['label']\n",
        "\n",
        "X.shape, y_train.shape"
      ],
      "metadata": {
        "id": "L_EMEkaQ18GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping de los datos cargados para que tengan el formato  de una imagen.\n",
        "X_train = np.array(X).reshape((-1, 28, 28, 1))\n",
        "X_test = np.array(test_df).reshape((-1, 28, 28, 1))\n",
        "X.shape, X_test.shape"
      ],
      "metadata": {
        "id": "gLyATFGg25Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Se normalizan los datos\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_text = X_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "ASzy_3ct25KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualicemos una muestra de números en el conjunto con sus etiquetas:"
      ],
      "metadata": {
        "id": "l83AR3FP3Bp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_img_dataset(X_train, y = y_train, firstimg=700, nrows = 2, ncols=4, numimg=8)"
      ],
      "metadata": {
        "id": "wD1W1Vos25Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las funciones ```create_pairs``` crean pares de números a partir del conjunto de datos. Recordemos que en la red siamesa necesitamos pasar un par de objetos y una etiqueta que indique si los objetos son iguales o no.\n",
        "\n",
        "* Si la etiqueta del número es la misma, vamos a pasar un `1` como etiqueta del par, indicando que no hay diferencias.\n",
        "* Si la etiqueta del número es diferente, pasaremos un `0`, indicando que los números son diferentes.\n"
      ],
      "metadata": {
        "id": "nSG4bl7h3PJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# El tercer parámetro: min_equals, indica cuántas parejas de datos similares\n",
        "# (es decir, con etiqueta 1) queremos como mínimo.\n",
        "def create_pairs(X, y, min_equals = 3000):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    equal_items = 0\n",
        "    index = [np.where(y == i)[0] for i in range(10)]\n",
        "    for n_item in range(len(X)):\n",
        "        if equal_items < min_equals:\n",
        "            num_rnd = np.random.randint(len(index[y[n_item]]))\n",
        "            num_item_pair = index[y[n_item]][num_rnd]\n",
        "\n",
        "            equal_items += 1\n",
        "        else:\n",
        "            num_item_pair = np.random.randint(len(X))\n",
        "        labels += [int(y[n_item] == y[num_item_pair])]\n",
        "        pairs += [[X[n_item], X[num_item_pair]]]\n",
        "\n",
        "    return np.array(pairs), np.array(labels).astype('float32')"
      ],
      "metadata": {
        "id": "HcKg-XdG3V3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos conjuntos de entrenamiento y validación:\n",
        "LIMIT_VAL = 2000\n",
        "X_train2 = []\n",
        "y_train2 = []\n",
        "X_val = X_train[:LIMIT_VAL]\n",
        "y_val = y_train[:LIMIT_VAL].reset_index(drop=True)\n",
        "X_train2 = X_train[LIMIT_VAL:]\n",
        "y_train2 = y_train[LIMIT_VAL:].reset_index(drop=True)\n",
        "\n",
        "training_pairs, training_labels = create_pairs(X_train2, y_train2, min_equals=15000)\n",
        "val_pairs, val_labels = create_pairs(X_val, y_val, min_equals=800)"
      ],
      "metadata": {
        "id": "BVvQSeNe3abr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos algunos pares del conjunto de datos de entrenamiento y validación. Los pares con igual número están al principio del conjunto de datos."
      ],
      "metadata": {
        "id": "DQjW-eYL3n_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_pairs(training_pairs, training_labels, 34004)"
      ],
      "metadata": {
        "id": "OoyX3ljI3ofK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_pairs(training_pairs, training_labels, 34)"
      ],
      "metadata": {
        "id": "9oqtN8uZ3sxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_pairs(val_pairs, val_labels, 32)"
      ],
      "metadata": {
        "id": "plSEK5753yM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_pairs(val_pairs, val_labels, 1500)"
      ],
      "metadata": {
        "id": "4_An6x7o3033"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Crear el modelo**\n",
        "---"
      ],
      "metadata": {
        "id": "4aae9slH37Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las siguientes funciones son necesarias para calcular la Distancia Euclídea entre los vectores, y para dar forma a la salida del modelo.\n",
        "\n",
        "* Ambas funciones se utilizarán en la capa de salida del modelo, que es una capa _lambda_ que llama a euclidean_distance con los vectores.\n",
        "\n",
        "* La función `eucl_dist_output_shapes` se pasa al parámetro `output_shape` de la capa, sólo para dar formato a la salida."
      ],
      "metadata": {
        "id": "MgKAOgxN3-Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "metadata": {
        "id": "_NwR_wCb4JzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.1 Función de pérdida**\n",
        "---\n",
        "La función de pérdida que se muestra a continuación es una implementación de la pérdida contrastiva, que toma la salida de la red para un ejemplo positivo y calcula su distancia a un ejemplo de la misma clase y la contrasta con la distancia a los ejemplos negativos.\n",
        "\n",
        "* **Recuerde**: la pérdida es baja si las muestras positivas se codifican en representaciones similares (más cercanas) y los ejemplos negativos se codifican en representaciones diferentes (más lejanas)."
      ],
      "metadata": {
        "id": "qk9BjL2S4SCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss_with_margin(margin):\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        square_pred = K.square(y_pred)\n",
        "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "GiKsNFhs4Sz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.2 Parte compartida**\n",
        "---\n",
        "La siguiente función define la parte común del modelo: el extractor de características. Está compuesto por tres capas densas de 128 neuronas cada una, intercaladas por capas de _Dropout_, que tienen un efecto regularizador. El modelo es simple dado que no se busca obtener una puntuación fantástica, es sólo un ejercicio para entender cómo funcionan las redes siamesas. A pesar de ello, el modelo funciona muy bien."
      ],
      "metadata": {
        "id": "2SE-hcbO4jON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_base_branch():\n",
        "    input = Input(shape=(28,28,), name=\"base_input\")\n",
        "    x = Flatten(name=\"flatten_input\")(input)\n",
        "    x = Dense(128, activation='relu', name=\"first_base_dense\")(x)\n",
        "    x = Dropout(0.3, name=\"first_dropout\")(x)\n",
        "    x = Dense(128, activation='relu', name=\"second_base_dense\")(x)\n",
        "    x = Dropout(0.3, name=\"second_dropout\")(x)\n",
        "    x = Dense(128, activation='relu', name=\"third_base_dense\")(x)\n",
        "\n",
        "    #Returning a Model, with input and outputs, not just a group of layers.\n",
        "    return Model(inputs=input, outputs=x)\n",
        "\n",
        "base_model = initialize_base_branch()"
      ],
      "metadata": {
        "id": "pZK1l_b64tM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2.3 Modelo siamés**\n",
        "---\n",
        "Esta es la parte del modelo siamés. Definimos dos entradas diferentes y una capa de salida _lambda_ que utiliza las funciones `euclidean_distance` y `eucl_dist_output_shape`:"
      ],
      "metadata": {
        "id": "z2omyc1_5ASy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrada para la parte izquierda del par. Vamos a pasar training_pairs[:,0]\n",
        "# por esta entrada.\n",
        "input_l = Input(shape=(28, 28,), name='left_input')\n",
        "# base_model es el modelo base y estamos añadiendo nuestra capa de entrada.\n",
        "vect_output_l = base_model(input_l)\n",
        "# Capa de entrada para la parte derecha del modelo siames.\n",
        "# Recibirá: training_pairs[:,1]\n",
        "input_r = Input(shape=(28, 28,), name='right_input')\n",
        "vect_output_r = base_model(input_r)\n",
        "# La capa de salida lambda llama a las distancias euclidianas,\n",
        "# devolverá la diferencia entre ambos vectores\n",
        "output = Lambda(euclidean_distance,\n",
        "                name='output_layer',\n",
        "                output_shape=eucl_dist_output_shape)([vect_output_l, vect_output_r])\n",
        "\n",
        "# Nuestro modelo tiene dos entradas y una salida.\n",
        "# Cada una de las entradas contiene el modelo común.\n",
        "model = Model([input_l, input_r], output)"
      ],
      "metadata": {
        "id": "wLTf_sbN5DBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo quedó el modelo:"
      ],
      "metadata": {
        "id": "twrqf3klw_ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "tf.keras.utils.plot_model(model, to_file='siamese_model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "Af9gksOq5HWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3 Entrenamiento**\n",
        "---\n",
        "Ahora vamos a entrenar. Utilizamos la función de pérdida que definimos antes: `contrastive_loss_with_margin`, que nos permite definir el margen. Recuerde que el margen permite mantener el equilibrio entre el valor asignado cuando hay similitudes o no. Con un valor grande las disimilitudes tienen más peso que las similitudes. Puede probar diferentes valores. Aquí lo hacemos con un margen de 1.\n",
        "\n",
        "Usamos `RMSprop` como optimizador, y entrenamos durante 20 _epochs_:\n"
      ],
      "metadata": {
        "id": "E-0UmK0P5JLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=contrastive_loss_with_margin(margin=1),\n",
        "              optimizer=RMSprop())\n",
        "history = model.fit(\n",
        "    [training_pairs[:,0], training_pairs[:,1]],\n",
        "    training_labels, epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data = ([val_pairs[:, 0], val_pairs[:, 1]], val_labels))"
      ],
      "metadata": {
        "id": "825VI09h5Qml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4 Evaluación**\n",
        "---\n",
        "Igual que en el ejemplo anterior, calculamos las predicciones del modelo y binarizamos los resultados: si la distancia predicha por el modelo es menor a $0.5$ definimos que son de la misma clase:"
      ],
      "metadata": {
        "id": "2P5Fa5UB5UrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(y_true, y_pred):\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)"
      ],
      "metadata": {
        "id": "hBscg4Ur5XkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = model.predict([training_pairs[:,0], training_pairs[:,1]])\n",
        "train_accuracy = compute_accuracy(training_labels, y_pred_train)\n",
        "\n",
        "y_pred_val = model.predict([val_pairs[:,0], val_pairs[:,1]])\n",
        "val_accuracy = compute_accuracy(val_labels, y_pred_val)\n",
        "\n",
        "print(\"Train Accuracy = {} Val accuracy = {}\".format(train_accuracy, val_accuracy))"
      ],
      "metadata": {
        "id": "NdnFG1Mf5b_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para terminar, tenemos dos funciones para mostrar las imágenes en pares, con la etiqueta predicha por la red siamesa. Si la etiqueta está en rojo las imágenes son diferentes y si la etiqueta está en negro las imágenes son del mismo tipo. El número de la etiqueta indica la diferencia. Cuanto mayor sea el número, más diferentes serán las imágenes."
      ],
      "metadata": {
        "id": "9ykxFVgw5iO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_images():\n",
        "    plt.rc('image', cmap='gray_r')\n",
        "    plt.rc('grid', linewidth=0)\n",
        "    plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "    plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "    plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "    plt.rc('text', color='a8151a')\n",
        "    plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_images(left, right, predictions, labels, title, n):\n",
        "    plt.figure(figsize=(17,3))\n",
        "    plt.title(title)\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "    plt.grid(None)\n",
        "    left = np.reshape(left, [n, 28, 28])\n",
        "    left = np.swapaxes(left, 0, 1)\n",
        "    left = np.reshape(left, [28, 28*n])\n",
        "    plt.imshow(left)\n",
        "    plt.figure(figsize=(17,3))\n",
        "    plt.yticks([])\n",
        "    plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "    for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "        if predictions[i] > 0.5: t.set_color('red') # bad predictions in red\n",
        "    plt.grid(None)\n",
        "    right = np.reshape(right, [n, 28, 28])\n",
        "    right = np.swapaxes(right, 0, 1)\n",
        "    right = np.reshape(right, [28, 28*n])\n",
        "    plt.imshow(right)"
      ],
      "metadata": {
        "id": "NVBa47kq5hjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = np.random.choice(len(y_pred_train), size=8)\n",
        "display_images(training_pairs[:, 0][indexes],\n",
        "               training_pairs[:, 1][indexes],\n",
        "               y_pred_train[indexes],\n",
        "               training_labels[indexes],\n",
        "               \"Pairs of images with distance\", 8)"
      ],
      "metadata": {
        "id": "HJVhHFdY5pJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puede ver que las clasificaciones son correctas en casi todos los casos. Pero puede obtener resultados diferentes cada vez que ejecute la función `display_images`, porque muestra pares aleatorios."
      ],
      "metadata": {
        "id": "1tts3Wgd4V47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = np.random.choice(len(y_pred_train), size=8)\n",
        "display_images(training_pairs[:, 0][indexes],\n",
        "               training_pairs[:, 1][indexes],\n",
        "               y_pred_train[indexes],\n",
        "               training_labels[indexes],\n",
        "               \"Pairs of images with distance\", 8)"
      ],
      "metadata": {
        "id": "x-0UdVus5svw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = np.random.choice(len(y_pred_train), size=8)\n",
        "display_images(training_pairs[:, 0][indexes],\n",
        "               training_pairs[:, 1][indexes],\n",
        "               y_pred_train[indexes],\n",
        "               training_labels[indexes],\n",
        "               \"Pairs of images with distance\", 8)"
      ],
      "metadata": {
        "id": "feogJYh_56ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Recursos adicionales**\n",
        "---\n",
        "Los siguientes enlaces corresponden a sitios en donde encontrará información muy útil para profundizar en los temas vistos :\n",
        "\n",
        "\n",
        "- [*How to create a Siamese Network to compare images*](https://www.kaggle.com/code/peremartramanonellas/how-to-create-a-siamese-network-to-compare-images#Check-the-results)\n",
        "\n",
        "- [*Siamese Networks Introduction and Implementation*](https://towardsdatascience.com/siamese-networks-introduction-and-implementation-2140e3443dee)\n"
      ],
      "metadata": {
        "id": "P6H2mjam5_EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n",
        "* **Asistentes docentes :**\n",
        "  * [Santiago Toledo Cortés](https://sites.google.com/unal.edu.co/santiagotoledo-cortes/)\n",
        "* **Diseño de imágenes:**\n",
        "    - [Mario Andres Rodriguez Triana](https://www.linkedin.com/in/mario-andres-rodriguez-triana-394806145/).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ],
      "metadata": {
        "id": "LsQ_vElRNK_k"
      }
    }
  ]
}