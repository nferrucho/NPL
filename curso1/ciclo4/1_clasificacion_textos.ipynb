{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso1/ciclo4/1_clasificacion_textos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ea67ec",
      "metadata": {
        "id": "62ea67ec"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Q6vQcIWFPY27isBepABpJ7nroUNKox_Z\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1142f27b",
      "metadata": {
        "id": "1142f27b"
      },
      "source": [
        "# **Clasificación de Textos**\n",
        "---\n",
        "\n",
        "En este notebook presentaremos los conceptos del análisis supervisado de textos junto con un ejemplo práctico de clasificación.\n",
        "\n",
        "Comenzamos importando las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a28a476",
      "metadata": {
        "id": "4a28a476"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bce4692",
      "metadata": {
        "id": "5bce4692"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from unidecode import unidecode\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0489a53",
      "metadata": {
        "id": "e0489a53"
      },
      "source": [
        "## **1. Análisis Supervisado**\n",
        "---\n",
        "\n",
        "El análisis supervisado de textos es una tarea donde se implementan modelos para replicar el comportamiento de un humano en una tarea específica. Actualmente esta tarea va muy de la mano con el aprendizaje supervisado en _machine learning_.\n",
        "\n",
        "Existen distintas tareas en procesamiento de lenguaje natural que se pueden abordar como un enfoque supervisado, entre ellas: clasificación de tokens, clasificación de textos, traductores, llenado de máscaras, análisis de sentimientos, entre otras. En la siguiente figura podemos ver el proceso general del análisis supervisado de textos:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1P7wvAsHTCWAfZZeci9WKmtJWK-0u_-Ci\" width=\"100%\">\n",
        "\n",
        "Este proceso consiste en cuatro etapas:\n",
        "\n",
        "1. **Preprocesamiento**: consiste en la preparación de los textos para simplificar el entrenamiento de un modelo, generalmente esta etapa involucra tareas como normalización, tokenización, eliminación de stopwords, y otras tareas tal y como se presentó en la unidad 2.\n",
        "2. **Extracción de características**: en este caso se extrae una representación numérica o características con las que se pueda modelar el texto, tal y como se presentó en la unidad 3.\n",
        "3. **Construcción del modelo**: en esta etapa se entrena un modelo supervisado de _machine learning_ para cumplir una tarea en específico (por ejemplo, clasificación, regresión, modelos secuencia a secuencia)\n",
        "4. **Evaluación del modelo**: en esta última parte se evalúa el desempeño del modelo para evaluar la generalización del mismo en la tarea en cuestión.\n",
        "\n",
        "En NLP, el enfoque supervisado más común es la tarea de clasificación, en especial, ya que una palabra puede ser vista como una categoría y un vocabulario como todas las categorías posibles. De esta forma funcionan modelos para reconocimiento de entidades nombradas, part-of-speech, llenado de máscaras, autocompletadores, entre otras. Varias de estas aplicaciones las profundizaremos en los otros notebooks de esta unidad. Por el momento, nos enfocaremos en una aplicación relacionada con la clasificación de documentos: el análisis de sentimientos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d40818",
      "metadata": {
        "id": "e4d40818"
      },
      "source": [
        "## **2. Análisis de Sentimientos**\n",
        "---\n",
        "\n",
        "El análisis de sentimientos, o minería de opinión, es un campo del procesamiento de lenguaje natural que busca identificar y extraer opiniones de un texto dado. Su propósito principal es identificar actitudes, sentimientos, evaluaciones y emociones de algún orador o escritor por medio de análisis computacional. Por ejemplo, en la siguiente figura podemos ver un caso de análisis de sentimientos aplicado en la identificación del sentimiento en reviews sobre la película [Fragmentado](https://es.wikipedia.org/wiki/Split_(pel%C3%ADcula)):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QCEsPK7ganFQ0SEt8Cn9B3gi2diQwx-F\" width=\"100%\">\n",
        "\n",
        "El análisis de sentimientos se utiliza en diversas aplicaciones:\n",
        "\n",
        "- **Comercio**: las empresas utilizan el análisis de sentimientos para desarrollar sus estrategias y entender la respuesta emocional de los usuarios ante determinado producto o marca. De igual forma, permite evaluar cómo la gente reacciona a determinada campaña para comprender por qué algunos productos no son comprados.\n",
        "- **Política**: en este ámbito se puede utilizar para dar un seguimiento a campañas políticas, detectar las acciones y las propuestas del gobierno, evaluar la favorabilidad de un candidato en específico, predecir resultados electorales, entre otros.\n",
        "- **Acciones públicas**: se usa para monitorear y analizar fenómenos sociales, en especial, permite identificar eventos específicos que puedan estar relacionados con situaciones peligrosas o fuera de la ley.\n",
        "- **Salud**: puede usarse para estudiar e identificar trastornos clínicos como depresión, ansiedad, autolesiones, autismo, entre otras.\n",
        "\n",
        "Normalmente, el análisis de sentimientos se aborda como clasificación de documentos en una o varias categorías (sentimientos o emociones).\n",
        "\n",
        "Para este caso, usaremos el conjunto de datos [Twitter Sentiment Analysis](https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis) de Kaggle. Comenzamos cargándolo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5902754",
      "metadata": {
        "id": "b5902754"
      },
      "outputs": [],
      "source": [
        "data = pd.read_parquet(\"https://raw.githubusercontent.com/mindlab-unal/mlds4-datasets/main/u4/twitter_sentiment.parquet\")\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940b2e0a",
      "metadata": {
        "id": "940b2e0a"
      },
      "source": [
        "Como podemos ver, es un corpus que contiene dos columnas:\n",
        "\n",
        "- `category`: tipo de sentimiento asociado al texto.\n",
        "- `text`: texto del documento.\n",
        "\n",
        "Se trata de textos extraídos de Twitter y etiquetados en 3 categorías:\n",
        "\n",
        "- `Negative`: sentimiento negativo.\n",
        "- `Positive`: sentimiento positivo.\n",
        "- `Neutral`: sentimiento neutral.\n",
        "\n",
        "Veamos la distribución de las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1cd790",
      "metadata": {
        "id": "2b1cd790"
      },
      "outputs": [],
      "source": [
        "counts = (\n",
        "        data\n",
        "        .category\n",
        "        .value_counts()\n",
        "        .reset_index()\n",
        "        )\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(data=counts, x=\"category\", y=\"count\", ax=ax, hue=\"category\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63424b1d",
      "metadata": {
        "id": "63424b1d"
      },
      "source": [
        "Para este ejemplo, usaremos el siguiente *pipeline* de `spacy` para tokenización y eliminación de stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2cf542b",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "b2cf542b"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "display(nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2848102b",
      "metadata": {
        "id": "2848102b"
      },
      "source": [
        "Ahora, definimos una función de preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f46535d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "7f46535d"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    doc = nlp(text) # creamos documento de spacy\n",
        "    filtered_tokens = \" \".join(\n",
        "            token.text\n",
        "            for token in doc\n",
        "            if not token.is_stop and\n",
        "            len(token) > 3 and len(token) < 24\n",
        "            ) # filtramos stopwords y palabras por longitud\n",
        "    lower_text = filtered_tokens.lower() # texto en minúscula\n",
        "    norm_text = unidecode(lower_text) # texto normalizado\n",
        "    clean_text = re.sub(r\"[^a-z ]\", \" \", norm_text) # eliminamos caracteres especiales\n",
        "    spaces_text = re.sub(r\"\\s+\", \" \", clean_text) # eliminamos espacios repetidos\n",
        "    strip_text = spaces_text.strip() # eliminamos espacios de inicio y final\n",
        "    if not len(strip_text): # validamos si el documento tiene longitud\n",
        "        return None\n",
        "    else:\n",
        "        return strip_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b327a9e",
      "metadata": {
        "id": "8b327a9e"
      },
      "source": [
        "Aplicamos la función de preprocesamiento sobre todo el corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be545ae",
      "metadata": {
        "id": "2be545ae"
      },
      "outputs": [],
      "source": [
        "data_na = data.dropna()\n",
        "data_prep = (\n",
        "        data_na\n",
        "        .assign(text=data_na.text.apply(preprocess))\n",
        "        .dropna()\n",
        "        )\n",
        "display(data_prep.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d9ed29",
      "metadata": {
        "id": "81d9ed29"
      },
      "source": [
        "## **3. Clasificación con Bolsas de Palabras**\n",
        "---\n",
        "\n",
        "Primero veremos un ejemplo de clasificación de sentimientos usando una representación basada en bolsa de palabras como técnica de extracción de características."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43efcf2",
      "metadata": {
        "id": "b43efcf2"
      },
      "source": [
        "### **3.1. Extracción de Características**\n",
        "---\n",
        "\n",
        "Comenzamos importando el vectorizador de `sklearn`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91202855",
      "metadata": {
        "id": "91202855"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f03a46d0",
      "metadata": {
        "id": "f03a46d0"
      },
      "source": [
        "Obtenemos una representación de bolsa de palabras del corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3790d0f3",
      "metadata": {
        "id": "3790d0f3"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer(max_features=5000).fit(data_prep.text)\n",
        "display(vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a0eb44",
      "metadata": {
        "id": "75a0eb44"
      },
      "source": [
        "Podemos obtener la matriz de características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2928afe",
      "metadata": {
        "id": "a2928afe"
      },
      "outputs": [],
      "source": [
        "features = vect.transform(data_prep.text).toarray()\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38764ca0",
      "metadata": {
        "id": "38764ca0"
      },
      "source": [
        "Como podemos ver, tenemos un total de 5993 documentos y un vocabulario de tamaño 5000."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de7fc946",
      "metadata": {
        "id": "de7fc946"
      },
      "source": [
        "### **3.2. Modelamiento**\n",
        "---\n",
        "\n",
        "Uno de los conceptos claves relacionados al entrenamiento de modelos supervisados es la **validación cruzada**, se trata de una estrategia para validar qué tan generalizable es un modelo.\n",
        "\n",
        "En este caso usaremos una estrategia de validación cruzada conocida como K-fold cross-validation:\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1gta4-p20xuFQq3gTqKN6MeATY624M1ML\" width=\"80%\">\n",
        "\n",
        "Esto nos permite evaluar distintas configuraciones de un modelo (hiper-parámetros) y evaluar una métrica $K$ veces para obtener un buen estimador de alguna métrica de desempeño.\n",
        "\n",
        "> **Nota**: el detalle de la metodología de validación cruzada y de los modelos se estudia con mayor profundidad en el **módulo 2 de introducción a machine learning**. En este notebook veremos de forma práctica la metodología enfocándonos más en su aplicación en el procesamiento de lenguaje natural.\n",
        "\n",
        "Comenzamos importando `LabelEncoder` de `sklearn` para codificar los sentimientos de una forma compatible con un modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f252c91b",
      "metadata": {
        "id": "f252c91b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f6ff5d",
      "metadata": {
        "id": "69f6ff5d"
      },
      "source": [
        "Obtenemos las etiquetas codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6bb8a53",
      "metadata": {
        "id": "c6bb8a53"
      },
      "outputs": [],
      "source": [
        "labeler = LabelEncoder().fit(data_prep.category)\n",
        "display(labeler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2691d735",
      "metadata": {
        "id": "2691d735"
      },
      "source": [
        "Ahora, codificamos las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "158d2b27",
      "metadata": {
        "id": "158d2b27"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_prep.category)\n",
        "display(np.unique(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81f84d0",
      "metadata": {
        "id": "c81f84d0"
      },
      "source": [
        "Como podemos ver, las etiquetas fueron codificadas como números enteros, podemos ver la correspondencia entre cada categoría y cada número (dada por el orden de las categorías en el siguiente arreglo):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee284d4",
      "metadata": {
        "id": "dee284d4"
      },
      "outputs": [],
      "source": [
        "display(labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f42399c",
      "metadata": {
        "id": "4f42399c"
      },
      "source": [
        "Ahora importamos la función `train_test_split` para dividir el conjunto de datos en entrenamiento (ajuste del modelo) y prueba (evaluación del desempeño sobre datos no vistos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10f7c4b",
      "metadata": {
        "id": "f10f7c4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc16480",
      "metadata": {
        "id": "cdc16480"
      },
      "source": [
        "Particionamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c69c859a",
      "metadata": {
        "id": "c69c859a"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=0.4, # tamaño del conjunto de prueba\n",
        "    random_state=13, # semilla de números aleatorios\n",
        "    stratify=labels, # mantenemos distribución de etiquetas\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70040551",
      "metadata": {
        "id": "70040551"
      },
      "source": [
        "Veamos el tamaño de las matrices de entrenamiento y prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0d80c7",
      "metadata": {
        "id": "0f0d80c7"
      },
      "outputs": [],
      "source": [
        "display(features_train.shape)\n",
        "display(features_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b32fa4d",
      "metadata": {
        "id": "4b32fa4d"
      },
      "source": [
        "Ahora podemos entrenar un modelo. Es posible usar cualquier tipo de modelo de clasificación como:\n",
        "- bosques aleatorios\n",
        "- máquinas de soporte vectorial\n",
        "- redes neuronales\n",
        "- entre otros\n",
        "\n",
        "En este caso utilizaremos un clasificador **Bayesiano ingenuo multinomial** (*multinomial Naive Bayes*), el cual es un algoritmo de aprendizaje automático utilizado para clasificar documentos de texto basados en bolsas de palabras. El algoritmo funciona asumiendo que cada característica (palabra) en el texto es independiente de las demás características y tiene una distribución multinomial como verosimilitud, y que la probabilidad de una característica dada una clase es proporcional a la frecuencia de esa característica en el texto de esa clase. Utiliza la probabilidad _a priori_ de cada clase para calcular la probabilidad a posteriori de cada clase dado el texto, y finalmente, asigna la clase con la probabilidad _a posteriori_ más alta al texto, como se muestra en la siguiente ecuación:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1FPZiKYUZ1tLieT1g7XyKAltDj90FcAig\" width=\"80%\">\n",
        "\n",
        "Es un modelo ampliamente utilizado en problemas de clasificación de texto como el análisis de sentimientos y la clasificación de correo no deseado. Veamos cómo importar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05639e7c",
      "metadata": {
        "id": "05639e7c"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982488fa",
      "metadata": {
        "id": "982488fa"
      },
      "source": [
        "Este modelo utiliza internamente probabilidades junto con la regla de Bayes para dar la probabilidad de que un documento pertenezca a una categoría. Para esto, hace uso de un hiper-parámetro `alpha` que permite controlar qué tan suave se realiza la asignación de un documento en una categoría; se trata de un número que debe ser explorado entre 0 y el número de documentos.\n",
        "\n",
        "Definimos un rango para el hiper-parámetro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9c4e42b",
      "metadata": {
        "id": "c9c4e42b"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"alpha\": 10 ** np.arange(5)}\n",
        "display(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a6922a",
      "metadata": {
        "id": "95a6922a"
      },
      "source": [
        "Ahora importamos la clase `GridSearchCV` para implementar la estrategia de K-fold cross-validation y encontrar el mejor valor de `alpha`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "767113cd",
      "metadata": {
        "id": "767113cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7d55d2",
      "metadata": {
        "id": "4b7d55d2"
      },
      "source": [
        "Realizamos el entrenamiento y la exploración:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0610db19",
      "metadata": {
        "id": "0610db19"
      },
      "outputs": [],
      "source": [
        "gsearch = GridSearchCV(\n",
        "    MultinomialNB(),\n",
        "    param_grid=param_grid,\n",
        "    cv=3\n",
        "    ).fit(features_train, labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fed11dce",
      "metadata": {
        "id": "fed11dce"
      },
      "source": [
        "Veamos la exactitud del modelo en la clasificación de sentimientos para los distintos valores de `alpha`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302406db",
      "metadata": {
        "id": "302406db"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(gsearch.cv_results_)\n",
        "display(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce46d28",
      "metadata": {
        "id": "4ce46d28"
      },
      "source": [
        "Extraemos el modelo que mejor funciona:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bbf82e1",
      "metadata": {
        "id": "1bbf82e1"
      },
      "outputs": [],
      "source": [
        "model = gsearch.best_estimator_\n",
        "display(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357b3a88",
      "metadata": {
        "id": "357b3a88"
      },
      "source": [
        "### **3.3. Evaluación**\n",
        "---\n",
        "\n",
        "Veamos el desempeño del modelo sobre datos no vistos (conjunto de evaluación o *test*) usando métricas de desempeño para clasificación.\n",
        "\n",
        "`sklearn` nos permite evaluar las métricas más importantes usando la función `classification_report`. La podemos importar así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66582a4",
      "metadata": {
        "id": "f66582a4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2742a7a0",
      "metadata": {
        "id": "2742a7a0"
      },
      "source": [
        "Obtenemos las predicciones sobre el conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1033df3b",
      "metadata": {
        "id": "1033df3b"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(features_test)\n",
        "print(classification_report(labels_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b661fdc5",
      "metadata": {
        "id": "b661fdc5"
      },
      "source": [
        "Como podemos ver, el modelo tiene un accuracy de 0.84 en la clasificación de los 3 sentimientos.\n",
        "\n",
        "También podemos calcular una matriz de confusión para ver errores específicos en la clasificación, para esto importamos `confusion_matrix`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532e8696",
      "metadata": {
        "id": "532e8696"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44bf811",
      "metadata": {
        "id": "c44bf811"
      },
      "source": [
        "Calculamos la matriz:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a4d1cf",
      "metadata": {
        "id": "e6a4d1cf"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cad411de",
      "metadata": {
        "id": "cad411de"
      },
      "source": [
        "Veamos una visualización de la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197bb106",
      "metadata": {
        "id": "197bb106"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicción\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a81e269",
      "metadata": {
        "id": "3a81e269"
      },
      "source": [
        "Por último, veamos un ejemplo de clasificación de sentimientos para un texto arbitrario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1fc316",
      "metadata": {
        "id": "3c1fc316"
      },
      "outputs": [],
      "source": [
        "text = \"this game is trash\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb659007",
      "metadata": {
        "id": "eb659007"
      },
      "source": [
        "Veamos el flujo completo:\n",
        "\n",
        "- Preprocesamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a769f38",
      "metadata": {
        "id": "7a769f38"
      },
      "outputs": [],
      "source": [
        "prep_text = preprocess(text)\n",
        "display(prep_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9585c5f",
      "metadata": {
        "id": "b9585c5f"
      },
      "source": [
        "- Extracción de características:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75449f30",
      "metadata": {
        "id": "75449f30"
      },
      "outputs": [],
      "source": [
        "features = vect.transform([prep_text])\n",
        "display(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9942d1c",
      "metadata": {
        "id": "b9942d1c"
      },
      "source": [
        "- Modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2a09c1",
      "metadata": {
        "id": "1d2a09c1"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(features)\n",
        "display(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d163e09",
      "metadata": {
        "id": "7d163e09"
      },
      "source": [
        "Por último, decodificamos la predicción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2fe1a7",
      "metadata": {
        "id": "3c2fe1a7"
      },
      "outputs": [],
      "source": [
        "display(labeler.inverse_transform(prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d45eca4",
      "metadata": {
        "id": "6d45eca4"
      },
      "source": [
        "Con esto tenemos un modelo personalizado para análisis de sentimientos basado en bolsas de palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b57dad",
      "metadata": {
        "id": "b8b57dad"
      },
      "source": [
        "## **4. Clasificación con Embeddings**\n",
        "---\n",
        "\n",
        "También podemos utilizar otros tipos de representaciones para manejar los documentos. Como en este caso buscamos clasificar documentos completos, y no palabras, vamos a usar un embedding **Doc2Vec**.\n",
        "\n",
        "> **Nota**: si se busca clasificar tokens, puede utilizar representaciones como bolsas de N-grams a nivel de caracteres, Word2Vec o FastText."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffdfba92",
      "metadata": {
        "id": "ffdfba92"
      },
      "source": [
        "### **4.1. Extracción de Características**\n",
        "---\n",
        "\n",
        "Para la extracción de características importamos el modelo `Doc2Vec` de `gensim`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7d2891",
      "metadata": {
        "id": "bc7d2891"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69de0691",
      "metadata": {
        "id": "69de0691"
      },
      "source": [
        "Creamos el corpus anotado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08872a76",
      "metadata": {
        "id": "08872a76"
      },
      "outputs": [],
      "source": [
        "tagged_corpus = [\n",
        "        TaggedDocument(doc.split(), [i])\n",
        "        for i, doc in enumerate(data_prep.text.to_list())\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc2deb4",
      "metadata": {
        "id": "8bc2deb4"
      },
      "source": [
        "Ahora entrenamos el embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99dd72bd",
      "metadata": {
        "id": "99dd72bd"
      },
      "outputs": [],
      "source": [
        "embedding = Doc2Vec(\n",
        "        tagged_corpus,\n",
        "        vector_size=500,\n",
        "        alpha=1e-3,\n",
        "        epochs=1000,\n",
        "        workers=-1\n",
        "        )\n",
        "display(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4faa8b2",
      "metadata": {
        "id": "b4faa8b2"
      },
      "source": [
        "Obtenemos una matriz de características basada en este embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603d917c",
      "metadata": {
        "id": "603d917c"
      },
      "outputs": [],
      "source": [
        "features = list(map(lambda doc: embedding.infer_vector(doc.words), tagged_corpus))\n",
        "features = np.vstack(features)\n",
        "display(features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d7edd50",
      "metadata": {
        "id": "0d7edd50"
      },
      "source": [
        "También debemos codificar las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2cb9e9",
      "metadata": {
        "id": "bf2cb9e9"
      },
      "outputs": [],
      "source": [
        "labeler = LabelEncoder().fit(data_prep.category)\n",
        "display(labeler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7247075",
      "metadata": {
        "id": "f7247075"
      },
      "source": [
        "Obtenemos las etiquetas codificadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b17e04",
      "metadata": {
        "id": "43b17e04"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_prep.category)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29dd160",
      "metadata": {
        "id": "f29dd160"
      },
      "source": [
        "### **4.2. Modelamiento**\n",
        "---\n",
        "\n",
        "Al igual que en el caso anterior, vamos a seguir una metodología de validación cruzada para determinar la generalización del modelo y seleccionar hiper-parámetros. Comenzamos particionando el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876155d5",
      "metadata": {
        "id": "876155d5"
      },
      "outputs": [],
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features,\n",
        "    labels,\n",
        "    test_size=0.4, # tamaño del conjunto de prueba\n",
        "    random_state=13, # semilla de números aleatorios\n",
        "    stratify=labels, # mantenemos distribución de etiquetas\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6e665",
      "metadata": {
        "id": "5fe6e665"
      },
      "source": [
        "Veamos el tamaño de las matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfac2c81",
      "metadata": {
        "id": "cfac2c81"
      },
      "outputs": [],
      "source": [
        "display(features_train.shape)\n",
        "display(features_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867389ee",
      "metadata": {
        "id": "867389ee"
      },
      "source": [
        "En este caso utilizaremos un clasificador **Bayesiano ingenuo Gaussiano** (*Gaussian Naive Bayes*), el cual es un algoritmo de aprendizaje automático que se utiliza para clasificar documentos de texto basados en embeddings. En lugar de tratar con características discretas como las palabras individuales, se emplean embeddings para representar cada documento de texto como un vector continuo en un espacio de características de alta dimensión. El algoritmo asume que los embeddings de los documentos de una clase determinada se distribuyen de manera gaussiana en el espacio de características, y usa la media y la varianza de esta distribución para calcular la probabilidad de que un nuevo documento pertenezca a esa clase. Utiliza la probabilidad _a priori_ de cada clase para calcular la probabilidad _a posteriori_ de cada clase dado el texto, y finalmente, asigna la clase con la probabilidad _a posteriori_ más alta al texto, como se muestra en la siguiente ecuación:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1QxbbA9_zfIwteHX2lrG04zRZbvQxbDMK\" width=\"80%\">\n",
        "\n",
        "Veamos cómo importar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75af56b3",
      "metadata": {
        "id": "75af56b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596478de",
      "metadata": {
        "id": "596478de"
      },
      "source": [
        "Este modelo tiene como hiper-parámetro `var_smoothing`, el cual funciona de una forma equivalente al parámetro `alpha` en la versión multinomial. Definimos el rango de valores a explorar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "796d97f8",
      "metadata": {
        "id": "796d97f8"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"var_smoothing\": 10. ** np.arange(-9, -3)}\n",
        "display(param_grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830e7c2c",
      "metadata": {
        "id": "830e7c2c"
      },
      "source": [
        "Ahora entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291467fe",
      "metadata": {
        "id": "291467fe"
      },
      "outputs": [],
      "source": [
        "gsearch = GridSearchCV(\n",
        "    GaussianNB(),\n",
        "    param_grid=param_grid,\n",
        "    cv=3\n",
        "    ).fit(features_train, labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846c352c",
      "metadata": {
        "id": "846c352c"
      },
      "source": [
        "Veamos los resultados de la exploración de hiper-parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d5e3a2",
      "metadata": {
        "id": "64d5e3a2"
      },
      "outputs": [],
      "source": [
        "display(pd.DataFrame(gsearch.cv_results_))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "410af161",
      "metadata": {
        "id": "410af161"
      },
      "source": [
        "Extraemos el mejor modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd163344",
      "metadata": {
        "id": "bd163344"
      },
      "outputs": [],
      "source": [
        "model = gsearch.best_estimator_\n",
        "display(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db149cb0",
      "metadata": {
        "id": "db149cb0"
      },
      "source": [
        "### **4.3. Evaluación**\n",
        "---\n",
        "\n",
        "Extraemos las predicciones del modelo sobre el conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f93523e",
      "metadata": {
        "id": "4f93523e"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(features_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d4f6a8",
      "metadata": {
        "id": "45d4f6a8"
      },
      "source": [
        "Veamos el reporte de clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba215562",
      "metadata": {
        "id": "ba215562"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d343f52",
      "metadata": {
        "id": "5d343f52"
      },
      "source": [
        "También podemos ver la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a76832",
      "metadata": {
        "id": "a5a76832"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels_test, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b17cfe59",
      "metadata": {
        "id": "b17cfe59"
      },
      "source": [
        "Veamos una visualización de la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eeb64ee",
      "metadata": {
        "id": "5eeb64ee"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicción\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6355f2c3",
      "metadata": {
        "id": "6355f2c3"
      },
      "source": [
        "Como podemos ver, el desempeño con **Doc2Vec** no es tan bueno. Recuerde que los _embeddings_ requieren una gran cantidad de datos y mucho tiempo de entrenamiento para llegar a representar de forma correcta un corpus. Para que este enfoque funcione mejor, necesitamos más datos o utilizar un modelo pre-entrenado en un corpus similar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d850017d",
      "metadata": {
        "id": "d850017d"
      },
      "source": [
        "## **5. Clasificación con Vader**\n",
        "\n",
        "Una alternativa para análisis de sentimientos es con modelos pre-entrenados o librerías diseñadas para ello. Un ejemplo de esto es [VADER](https://github.com/cjhutto/vaderSentiment) (*Valence Aware Dictionary and sEntiment Reasoner*). Se trata de una librería basada en reglas que usa léxicos para el análisis de sentimientos. Es una herramienta de uso libre que está enfocada en el análisis de datos en redes sociales y provee información acerca de los sentimientos en un texto (qué tan positivo o negativo es).\n",
        "\n",
        "Algunas de las ventajas de VADER son:\n",
        "\n",
        "- Funciona bien en datos de redes sociales, sin embargo, se puede generalizar en otros dominios.\n",
        "- No requiere datos para el entrenamiento.\n",
        "- Es lo suficientemente rápido como para ser usado con datos en streaming.\n",
        "\n",
        "Comenzamos instalando la librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd8c72b",
      "metadata": {
        "id": "efd8c72b"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e367f8",
      "metadata": {
        "id": "49e367f8"
      },
      "source": [
        "Para usar `vader` debemos importar la clase `SentimentIntensityAnalyzer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac283f82",
      "metadata": {
        "id": "ac283f82"
      },
      "outputs": [],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7027a727",
      "metadata": {
        "id": "7027a727"
      },
      "source": [
        "Instanciamos el analizador de sentimientos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28557cda",
      "metadata": {
        "id": "28557cda"
      },
      "outputs": [],
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0d6b7a4",
      "metadata": {
        "id": "f0d6b7a4"
      },
      "source": [
        "Veamos un ejemplo de cómo podemos usar el analizador con un texto con sentimientos positivos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4a0a83",
      "metadata": {
        "id": "5a4a0a83"
      },
      "outputs": [],
      "source": [
        "res = analyzer.polarity_scores(\n",
        "        \"I am happy today, because, it is my birthday.\"\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4fbbade",
      "metadata": {
        "id": "b4fbbade"
      },
      "source": [
        "También podemos hacerlo con un texto negativo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e7f9a8",
      "metadata": {
        "id": "c4e7f9a8"
      },
      "outputs": [],
      "source": [
        "res = analyzer.polarity_scores(\n",
        "        \"I think I won't go, my grandma is ill.\"\n",
        "        )\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ec8a907",
      "metadata": {
        "id": "4ec8a907"
      },
      "source": [
        "El analizador nos da cuatro métricas:\n",
        "\n",
        "- _neg, neu, pos_: son la proporción de expresiones negativas, neutrales y positivas encontradas en el texto.\n",
        "- _compound_: se trata de una calificación que toma valores entre -1 y 1. Puede verse como el sentimiento del texto dado.\n",
        "\n",
        "Así mismo, podemos clasificar el sentimiento del texto de acuerdo con la siguiente convención según los desarrolladores de la librería:\n",
        "\n",
        "| Sentimiento | Compound |\n",
        "| --- | --- |\n",
        "| Negativo | $\\text{compound}\\leq -0.05$ |\n",
        "| Neutral | $-0.05 < \\text{compound} < 0.05$|\n",
        "| Positivo | $\\text{compound}\\geq 0.05$ |\n",
        "\n",
        "Además de analizar el léxico de las palabras, **VADER** incluye algunas reglas adicionales:\n",
        "\n",
        "- **Puntuación**: el uso del signo de exclamación significa una mayor intensidad, sucesiones de signos de exclamación alteran el score total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ec04ac",
      "metadata": {
        "id": "b7ec04ac"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10fb422",
      "metadata": {
        "id": "c10fb422"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfaee29e",
      "metadata": {
        "id": "dfaee29e"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!!\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065fff93",
      "metadata": {
        "id": "065fff93"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"That restaurant is really bad!!!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ada7fb",
      "metadata": {
        "id": "d4ada7fb"
      },
      "source": [
        "- **Mayúsculas**: palabras relevantes que estén en mayúsculas enfatizan el sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a02451fa",
      "metadata": {
        "id": "a02451fa"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was nice to me.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332ec0c2",
      "metadata": {
        "id": "332ec0c2"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was NICE to me\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d757a7d",
      "metadata": {
        "id": "0d757a7d"
      },
      "source": [
        "- **Modificadores de grado**: el uso de palabras para enfatizar un mayor grado también modifica el score final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5857af05",
      "metadata": {
        "id": "5857af05"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was partially nice to me.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4867454",
      "metadata": {
        "id": "f4867454"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"She was extremely nice to me.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d01614",
      "metadata": {
        "id": "62d01614"
      },
      "source": [
        "- **Conjunciones**: algunas palabras pueden cambiar el sentimiento de una oración; **VADER** también tiene en cuenta estas conjunciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2ecbc0",
      "metadata": {
        "id": "ba2ecbc0"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"The zoo was ok\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5441f0f8",
      "metadata": {
        "id": "5441f0f8"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"The zoo was ok, but I'm sad for the animals\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "739f86ca",
      "metadata": {
        "id": "739f86ca"
      },
      "source": [
        "- **Lenguaje informal**: como **VADER** está especializado en el análisis de datos de redes sociales, funciona bien cuando se utilizan coloquialismos y emojis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befd8eb5",
      "metadata": {
        "id": "befd8eb5"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"I'm feeling 😀 this evening.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d02d563",
      "metadata": {
        "id": "3d02d563"
      },
      "outputs": [],
      "source": [
        "display(analyzer.polarity_scores(\"😚\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9877d93f",
      "metadata": {
        "id": "9877d93f"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"😭\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a7a892",
      "metadata": {
        "id": "e5a7a892"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"😓\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01b9b31",
      "metadata": {
        "id": "d01b9b31"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"LOL, that joke was fun.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf48cd4",
      "metadata": {
        "id": "bdf48cd4"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"This sux\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c322630e",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "c322630e"
      },
      "outputs": [],
      "source": [
        "analyzer.polarity_scores(\"You seem so :) when I was like :D\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bf1876",
      "metadata": {
        "id": "58bf1876"
      },
      "source": [
        "Veamos el desempeño de `vader` sobre el conjunto de datos que estamos manejando. Para esto definimos la siguiente función para extraer una categoría de acuerdo al clasificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829fb988",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "829fb988"
      },
      "outputs": [],
      "source": [
        "def vader_prediction(text):\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    compound = scores[\"compound\"]\n",
        "    if compound < -0.05:\n",
        "        return \"Negative\"\n",
        "    elif compound < 0.05:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Positive\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb2a9a7",
      "metadata": {
        "id": "7eb2a9a7"
      },
      "source": [
        "Obtenemos las predicciones de `vader` para cada documento del corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99165066",
      "metadata": {
        "id": "99165066"
      },
      "outputs": [],
      "source": [
        "data_vader = data.assign(prediction = data.text.apply(vader_prediction))\n",
        "display(data_vader.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc0c5fa",
      "metadata": {
        "id": "1dc0c5fa"
      },
      "source": [
        "Veamos el desempeño del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627611dd",
      "metadata": {
        "id": "627611dd"
      },
      "outputs": [],
      "source": [
        "labels = labeler.transform(data_vader.category)\n",
        "predictions = labeler.transform(data_vader.prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85c7e3a",
      "metadata": {
        "id": "e85c7e3a"
      },
      "source": [
        "Veamos el reporte de clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93de89b",
      "metadata": {
        "id": "f93de89b"
      },
      "outputs": [],
      "source": [
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae173d2",
      "metadata": {
        "id": "bae173d2"
      },
      "source": [
        "También podemos ver la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81252280",
      "metadata": {
        "id": "81252280"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(labels, predictions)\n",
        "cm = pd.DataFrame(data=cm, columns=labeler.classes_, index=labeler.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae83287f",
      "metadata": {
        "id": "ae83287f"
      },
      "source": [
        "Veamos una visualización de la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8068323b",
      "metadata": {
        "id": "8068323b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", ax=ax)\n",
        "ax.set_xlabel(\"Predicción\")\n",
        "ax.set_ylabel(\"Real\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4cae43",
      "metadata": {
        "id": "be4cae43"
      },
      "source": [
        "Como se puede ver, el desempeño no es tan bueno como el modelo basado en bolsas de palabras. No obstante, `vader` nos da un resultado aceptable sin la necesidad de entrenar un modelo.\n",
        "\n",
        "En este caso mostramos un ejemplo de análisis de sentimientos en inglés, ya que librerías importantes como `vader` funcionan en este idioma. Tenga en cuenta que puede entrenar modelos en español siempre que disponga de un corpus etiquetado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3831bc96",
      "metadata": {
        "id": "3831bc96"
      },
      "source": [
        "## Recursos Adicionales\n",
        "---\n",
        "\n",
        "Los siguientes enlaces corresponden a sitios donde encontrará información muy útil para profundizar en los temas vistos en este notebook:\n",
        "\n",
        "- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment).\n",
        "- [Sentiment Analysis using Python](https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/).\n",
        "- _Fuente de los íconos_\n",
        "     - Flaticon. Document free icon [PNG]. https://www.flaticon.com/free-icon/document_888071\n",
        "     - Flaticon. Happy face free icon [PNG]. https://www.flaticon.com/free-icon/happy-face_5624232\n",
        "     - Flaticon. Review free icon [PNG]. https://www.flaticon.com/free-icon/review_5624236\n",
        "     - Flaticon. Neutral free icon [PNG]. https://www.flaticon.com/free-icon/neutral_3688054"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a394dd7a",
      "metadata": {
        "id": "a394dd7a"
      },
      "source": [
        "## Créditos\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "    - [Juan Sebastián Lara Ramírez](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/).\n",
        "* **Diseño de imágenes:**\n",
        "    - [Rosa Alejandra Superlano Esquibel](mailto:rsuperlano@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}