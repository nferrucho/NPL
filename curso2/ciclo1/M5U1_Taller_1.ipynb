{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nferrucho/NPL/blob/main/curso2/M5U1_Taller_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLlSr7BaKSLF"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1QqjbbEZ1w7xoawV020Jj_R46PKRi6A_e\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEewD2N0RkMc"
      },
      "source": [
        "# **Taller 1: Clasificación lineal con *Tensorflow***\n",
        "---\n",
        "\n",
        "En este taller deberá entrenar modelos de clasificación con regresión logística para el [conjunto de datos de vinos Wine](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data) del repositorio de la *UCI* usando *Tensorflow*.\n",
        "\n",
        "Ejecute las siguientes celdas para conectarse a UNCode:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nZiCjQpPdYC"
      },
      "outputs": [],
      "source": [
        "!pip install rlxcrypt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAqkL4giPflw"
      },
      "outputs": [],
      "source": [
        "!wget --no-cache -O session.pye -q https://raw.githubusercontent.com/JuezUN/INGInious/master/external%20libs/session.pye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKNgJYjHPhtr"
      },
      "outputs": [],
      "source": [
        "import rlxcrypt\n",
        "import session\n",
        "\n",
        "grader = session.LoginSequence('DLIAAPCP-GroupMLDS-5-2024-2@c5537983-7643-4080-8bd1-dcb22bcd53be')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ocd--frFi7"
      },
      "source": [
        "Ejecute la siguiente celda para importar y configurar las librerías usadas :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIB7qeOuVkfh"
      },
      "outputs": [],
      "source": [
        "# Librerías de utilidad para manipulación y visualización de datos.\n",
        "!pip install -U scikit-learn\n",
        "from numbers import Number\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "# Ignorar warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUMP_2CPqwRY"
      },
      "outputs": [],
      "source": [
        "# Versiones de las librerías usadas.\n",
        "!python --version\n",
        "print('Tensorflow', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxNzX3sfq3gZ"
      },
      "source": [
        "Esta actividad se realizó con las siguientes versiones:\n",
        "*  Python 3.9.16\n",
        "*  Tensorflow 2.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjXal-trVEJf"
      },
      "source": [
        "## **Cargar los datos**\n",
        "---\n",
        "En el conjunto *Wine* las características de entrada corresponden a diferentes atributos del vino. El conjunto de datos contiene 178 ejemplos sobre los que se tiene la siguiente información :\n",
        "\n",
        "* Alcohol\n",
        "* Malic acid\n",
        "* Ash\n",
        "* Alcalinity of ash\n",
        "* Magnesium\n",
        "* Total phenols\n",
        "* Flavanoids\n",
        "* Nonflavanoid phenols\n",
        "* Proanthocyanins\n",
        "* Color intensity\n",
        "* Hue\n",
        "* OD280/OD315 of diluted wines\n",
        "* Proline\n",
        "\n",
        "Hay tres clases de vinos diferentes. `class_0` el cual tiene 59 muestras, `class_1` el cual tiene 71 muestras y `class_2` el cual tiene 48 muestras.\n",
        "\n",
        "Como en cualquier experimento de _machine learning_, vamos a empezar cargando el conjunto de datos, haciendo particiones de entrenamiento y prueba, y para efectos de esta tarea, nos vamos a quedar solo con dos clases (`class_1` y `class_2`) para hacer clasificación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv04gQUd1lmN"
      },
      "outputs": [],
      "source": [
        "!wget --no-cache -O wine.data -q  https://raw.githubusercontent.com/mindlab-unal/mlds5-datasets/main/u1/taller/wine.data?raw=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJnzTFXwT5vv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Leer el archivo que contiene los datos:\n",
        "data =  pd.read_csv('wine.data', sep=\",\", header=None)\n",
        "# La etiqueta está consignada en la primera columna:\n",
        "X_all = np.array(data.iloc[:,1:])\n",
        "y_all = np.array(data.iloc[:,0])\n",
        "# Nos quedamos con la clase 2 y 3, y ajustamos las etiquetas para que queden\n",
        "# como 0 y 1:\n",
        "X = X_all[np.where((y_all==2)|(y_all==3))]\n",
        "y = y_all[np.where((y_all==2)|(y_all==3))]-2\n",
        "# Re-escalamos los datos\n",
        "scaler = preprocessing.MinMaxScaler((0, 1))\n",
        "X = scaler.fit_transform(X)\n",
        "# Y hacemos partición en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RojJZC5RZEAX"
      },
      "source": [
        "Verifiquemos el tamaño de las particiones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL6IP3EjZJbH"
      },
      "outputs": [],
      "source": [
        "print(\"Número de muestras de entrenamiento =\", X_train.shape[0])\n",
        "print(\"Número de muestras de prueba =\", X_test.shape[0])\n",
        "print(\"Número de características del conjunto de datos =\", X_train.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvU714ETaBCW"
      },
      "source": [
        "**Salida esperada**\n",
        "\n",
        "```\n",
        "Número de muestras de entrenamiento = 83\n",
        "Número de muestras de prueba = 36\n",
        "Número de características del conjunto de datos = 13\n",
        "```\n",
        "\n",
        "Tenemos entonces 122 muestras con 13 _features_ para trabajar. Ahora veamos cuántas muestras hay por cada clase:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3KjHa9ta1j1"
      },
      "outputs": [],
      "source": [
        "print(\"Número de muestras de la clase 2 en entrenamiento =\", X_train[np.where(y_train==0)].shape[0])\n",
        "print(\"Número de muestras de la clase 3 en entrenamiento =\", X_train[np.where(y_train==1)].shape[0])\n",
        "print(\"Número de muestras de la clase 2 en prueba =\", X_test[np.where(y_test==0)].shape[0])\n",
        "print(\"Número de muestras de la clase 3 en prueba =\", X_test[np.where(y_test==1)].shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4TrnwBrZuRi"
      },
      "source": [
        "**Salida esperada**\n",
        "```\n",
        "Número de muestras de la clase 2 en entrenamiento = 50\n",
        "Número de muestras de la clase 3 en entrenamiento = 33\n",
        "Número de muestras de la clase 2 en prueba = 21\n",
        "Número de muestras de la clase 3 en prueba = 15\n",
        "```\n",
        "\n",
        "Como puede ver, el conjunto de datos está desbalanceado. Vamos entonces a implementar un modelo que compense este desbalance desde la función de pérdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lgEUZq_Icve"
      },
      "source": [
        "## **Modelo de regresión logística con _class_weight_**\n",
        "---\n",
        "Una vez se dispone de un conjunto de datos preparado para el entrenamiento, se declara el algoritmo de aprendizaje computacional. En nuestro caso queremos predecir el valor de una variable categórica, es decir, realizar un modelo para **clasificación**.\n",
        "\n",
        "Sin embargo, el conjunto de datos no está balanceado. Cuando esto sucede, podemos compensar el desbalance dándole más importancia a la clase menos presente. Darle más importancia a una clase se logra asignando un peso por cada clase dentro de la función de pérdida del modelo.\n",
        "\n",
        "Supongamo que tenemos un problema desbalanceado de clasificación binario con etiquetas $0$ y $1$. Supongamos que $n_0$ es el número de elementos de la clase $0$ y $n_1$ es el número de elementos de la clase $1$. Una elección convencional sobre los pesos que se le deben asignar a cada clase es :\n",
        "\n",
        "$$w_0=\\dfrac{n_0+n_1}{2n_0},$$\n",
        "\n",
        "$$w_1=\\dfrac{n_0+n_1}{2n_1}.$$\n",
        "\n",
        "Y estos pesos se incorporan a la función de pérdida de la siguiente forma :\n",
        "\n",
        "$$\\mathcal{L}(\\vec{w})=-\\frac{1}{N}\\sum_{i=1}^{N}[w_1 y_i\\log(\\tilde{y}_i)+w_0(1-y_i)\\log(1-\\tilde{y}_i)],$$\n",
        "\n",
        "¿Cómo funciona? Supongamos que hay 100 muestras de la clase $0$ y 50 de la clase $1$. Es decir, $n_0=100$ y $n_1=50$. Entonces $w_0=0.75$ y $w_1=1.5$. Así, el peso de la clase $1$ es el doble del peso de la clase $0$. Cuando el modelo no clasifica bien una muestra de la clase $1$, la penalidad se multiplica por $w_1$. Es decir, el modelo entiende que es más grave equivocarse con los datos de la clase $1$, y de esa manera compensa el que sean menos muestras que las de la clase $0$, tratanto de previnir cualquier tipo de sesgo en el modelo final.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7NJO2HQ7q5p"
      },
      "source": [
        "> **La tarea es incremental, por lo tanto es recomendable resolver los puntos en orden**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvlFb8xffeRb"
      },
      "source": [
        "## **1. Calcular el peso de cada clase**\n",
        "---\n",
        "\n",
        "Complete la función **`class_weights`** para que calcule los pesos que el modelo tiene que darle a cada clase según el desbalance de los datos.\n",
        "\n",
        "**Entrada** :\n",
        "\n",
        "* **`y`**: un `numpy.ndarray` de tamaño `(m,)`; es decir, el vector de etiquetas de los datos de entrenamiento. $m$ el número de muestras del conjunto de entrenamiento.\n",
        "\n",
        "**Salida** :\n",
        "\n",
        "* **`weights_list`** : `list`, una lista con los pesos (tipo `float`) de cada clase, en orden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvZuMzfkO_O3"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA class_weights:\n",
        "\n",
        "def class_weights(y):\n",
        "    # Reemplazar con respuesta\n",
        "    w_0 = -1\n",
        "    w_1 = -1\n",
        "    weights_list = -1\n",
        "    return weights_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQIvYJSkh46h"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "\n",
        "class_weights_list = class_weights(y_train)\n",
        "print(np.round(class_weights_list, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RES78V1iY6-"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "```python\n",
        "[0.83    1.25758]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmbnzYIg1tdL"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qlllA02arba"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 1_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoUpAKKd1yxG"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 1_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRFqDDgtU0n"
      },
      "source": [
        "## **2. Binary cross-entropy**\n",
        "---\n",
        "Usaremos el siguente modelo de regresión logística (ejecute la siguiente celda de código para continuar):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLbYwyKXtXD4"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo de regresión logística\n",
        "def log_reg(w, b, X):\n",
        "    return 1/(1+tf.math.exp(-(tf.matmul(X, w) + b)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p02aXXHHfUuD"
      },
      "source": [
        "Ahora, complete la función **`weighted_bce`** para que retorne el valor de la entropia cruzada, teniendo en cuenta los pesos de cada clase.\n",
        "\n",
        "**Entrada**:\n",
        "\n",
        "* **`y_true`** : `tf.Tensor`, un tensor  de tamaño `(m,1)` con las etiquetas reales de los datos.\n",
        "* **`y_pred`** : `tf.Tensor`, un tensor  de tamaño `(m,1)` con las etiquetas predichas por el modelo.\n",
        "* **`class_weights`** : `list`, una lista con los pesos asociados a cada clase.\n",
        "\n",
        "**Salida**:\n",
        "\n",
        "* **`w_bce`** : `tf.Tensor`, un escalar de tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ADXyyYP29Jd"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA weighted_bce:\n",
        "def weighted_bce(y_true, y_pred, class_weights):\n",
        "    # Reemplazar con respuesta\n",
        "    w_bce = -1\n",
        "    return w_bce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqDJqyV6JvXm"
      },
      "source": [
        "Use las siguientes celdas para probar su modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj9SHxQe4qZ7"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "\n",
        "class_weights_example = class_weights(y_train)\n",
        "w_test=np.array([[1.0],[-1.0],[1.0],[1.0],[-1.0],[1.0],[1.0],[-1.0],[-1.0],[1.0],[1.0],[-1.0],[1.0]])\n",
        "b_test= 0.5\n",
        "X_t = tf.constant(X_train, dtype=tf.float32)\n",
        "Y_t = tf.constant(y_train, dtype=tf.float32)\n",
        "Y_t = tf.expand_dims(Y_t, axis=-1, name=None)\n",
        "y_true = Y_t\n",
        "y_pred = log_reg(w_test, b_test, X_t)\n",
        "print(\"weighted_bce =\", weighted_bce(y_true,y_pred,class_weights_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAaWVvBpJymI"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "```python\n",
        "weighted_bce = 1.0332682\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T6GxmiX9kP-"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n",
        "</summary>\n",
        "\n",
        "\n",
        "* Utilice la función [**`tf.math.reduce_mean`**](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean) de la guia de _Tensorflow_ **`tf.math`** tal como se vio en el taller guiado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGER6Lv_9ujt"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n",
        "</summary>\n",
        "\n",
        "\n",
        "* El uso de una función de pérdida de entropía cruzada ponderada implica el uso de los pesos de cada clase para hallar su valor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQyHcZAK1xp7"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFwSYxcyjevU"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 2_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8P3GP-SheOO"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 2_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxYTFmehumJg"
      },
      "source": [
        "## **3. Función de pérdida**\n",
        "---\n",
        "Complete la función **`loss_fun`** para que calcule el valor de la función de pérdida. Esta es la función que optimizaremos.\n",
        "\n",
        "**Entrada** :\n",
        "\n",
        "* **`X_t`**: `tf.Tensor`, tensor de tamaño `(m,n)`, correspondiente a la matriz de datos de entrenamiento.\n",
        "* **`Y_t`**: `tf.Tensor`, tensor de tamaño `(m,1)`, correspondiente a las etiquetas de los datos entrenamiento.\n",
        "* **`w`**: `tf.Variable`, tensor de parámetros del modelo, de tamaño `(n,1)`.\n",
        "* **`b`**: `tf.Variable`, escalar de _bias_ del modelo.\n",
        "* **`class_weights_list`**: `list`, lista de pesos de cada clase.\n",
        "\n",
        "**Salida** :\n",
        "\n",
        "* **`bce`**: `tf.Variable`, escalar con el valor de la función de pérdida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u-8ySUn3MiF"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA create_loss_fun:\n",
        "def loss_fun(X_t, Y_t, w, b, class_weights_list):\n",
        "    # Reemplazar con respuesta\n",
        "    y_pred = -1\n",
        "    bce = -1\n",
        "    return bce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do-BvHWHvfy3"
      },
      "source": [
        "Use las siguientes celdas para probar su modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSafoW0vvCX6"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "class_weights_list = class_weights(y_train)\n",
        "w = tf.Variable([[1.0],[-1.0],[1.0],[1.0],[-1.0],[1.0],[1.0],[-1.0],[-1.0],[1.0],[1.0],[-1.0],[1.0]])\n",
        "b = tf.Variable(0.5)\n",
        "X_t = tf.constant(X_train, dtype=tf.float32)\n",
        "Y_t = tf.constant(y_train, dtype=tf.float32)\n",
        "Y_t = tf.expand_dims(Y_t, axis=-1, name=None)\n",
        "print(\"init_loss =\",loss_fun(X_t, Y_t, w, b,class_weights_list).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpyKl-9Pg8uy"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "```python\n",
        "init_loss = 1.0332682\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF0kjuw-3IyO"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flxDuPlR0IUj"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 3_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKpNi1axrOsG"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 3_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVV8ok4yxsZ-"
      },
      "source": [
        "## **4. Optimizador**\n",
        "---\n",
        "Complete la función **`optimizer`** para que devuelva un optimizador válido. Deberá específicar el tipo de optimizador y la tasa de aprendizaje que usaremos en el entrenamiento.\n",
        "\n",
        "**Entrada** :\n",
        "\n",
        "* **`type_opt`** : `str`, que puede tomar valores entre: **`SGD`**, **`Adam`**, **`RMSprop`**.\n",
        "* **`learning_rate`** : `float`, correspondiente a la tasa de aprendizaje.\n",
        "\n",
        "**Salida** :\n",
        "\n",
        "* **`opt`** : El optimizador con tasa de aprendizaje definida, un objeto tipo `keras.optimizers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_KDo5bJ4h2l"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA optimizer:\n",
        "def optimizer(type_opt, learning_rate):\n",
        "\n",
        "    # Reemplazar con respuesta\n",
        "    opt = -1\n",
        "    return opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR4Awzb5ztOD"
      },
      "source": [
        "Use las siguientes celdas para probar su modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfjU0JJaztrL"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "\n",
        "type_opt_test = 'Adam'\n",
        "learning_rate_test = 0.5\n",
        "optimizer(type_opt_test,learning_rate_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtl2uZVAhBL6"
      },
      "source": [
        "**Salida esperada**\n",
        "> Nota: los últimos números de la salida pueden variar.\n",
        "\n",
        "```\n",
        "<keras.optimizers.adam.Adam at 0x7f53eddd39d0>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ibs4n_F4qUG"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzRD9UibvZMF"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 4_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsEivFN30Pmo"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 4_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF6QMy_fzIM5"
      },
      "source": [
        "## **5. Entrenamiento del modelo**\n",
        "---\n",
        "Una vez definido, podemos entrenar el modelo. Complete la función **`train_model`** para que retorne los pesos **`w`**, **`b`**, del modelo entrenado sobre los arreglos **`X_t`** y **`Y_t`**.\n",
        "\n",
        "**Entrada** :\n",
        "\n",
        "* **`epochs`** : `int`, el número de iteraciones durante las cuales se realizará el entrenamiento del modelo.\n",
        "* **`optimizer`** : `keras.optimizers`, el optimizador definido que se usará para minimizar la función de pérdida **`loss_fun`**\n",
        "* **`X_t`**: `tf.Tensor`, tensor de tamaño `(m,n)`, correspondiente a la matriz de datos de entrenamiento.\n",
        "* **`Y_t`**: `tf.Tensor`, tensor de tamaño `(m,1)`, correspondiente a las etiquetas de los datos entrenamiento.\n",
        "* **`class_weights_list`**: `list`, lista de pesos de cada clase.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Salida** :\n",
        "\n",
        "* **`losses`** : `list` Una lista con los valores de **`loss_fun`** en cada iteración.\n",
        "* **`w`**: `tf.Variable`, tensor de parámetros óptimos del modelo, de tamaño `(n,1)`.\n",
        "* **`b`**: `tf.Variable`, escalar de _bias_ óptimo del modelo.\n",
        "\n",
        "> **Nota 1**: los valores iniciales de `w` y `b` ya están definidos dentro de la celda de código que debe completar.\n",
        "\n",
        "> **Nota 2**: Tal como se hizo en la guía, defina una función `create_model(X_t, Y_t)`, que retorna `w, b, loss_fun`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8X2i0zW4uWW"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA train_model:\n",
        "def train_model(epochs, optimizer, X_t, Y_t, class_weights_list):\n",
        "    def create_model(X_t, Y_t):\n",
        "        w = tf.Variable(tf.ones(shape=(13,1)))\n",
        "        b = tf.Variable(0.5)\n",
        "        def loss_fun():\n",
        "        # Reemplazar con respuesta\n",
        "            y_pred = -1\n",
        "            return -1\n",
        "        return w, b, loss_fun\n",
        "    # Reemplazar con respuesta\n",
        "    w, b, loss_fun = -1\n",
        "    losses = -1\n",
        "    # Reemplazar con respuesta\n",
        "    return losses, w, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6UF9RQvHfji"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "losses, w, b = train_model(epochs=2,optimizer=optimizer('RMSprop',0.5),X_t = X_t, Y_t = Y_t, class_weights_list= class_weights_list)\n",
        "print('Epoch', 0, 'loss =', losses[0])\n",
        "print('Epoch', 1, 'loss =', losses[1])\n",
        "print(\"w[0] =\", w[:1][0,0].numpy())\n",
        "print(\"b =\",b.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bn6B1jk-JR8"
      },
      "source": [
        "**Salida esperada**:\n",
        "\n",
        "```\n",
        "Epoch 0 loss = 2.0266452\n",
        "Epoch 1 loss = 1.0402095\n",
        "w[0] = 0.78892064\n",
        "b = 0.049995422\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR11W-tJ6oCq"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AxVtfwt0Tye"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 5_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8wDiDu634cB"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 5_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJ0lz3uXVmx"
      },
      "source": [
        "## **6. Predicciones del modelo**\n",
        "---\n",
        "Finalmente, podemos utilizar los datos reservados de la partición de prueba para calcular predicciones y hacer evaluaciones.\n",
        "\n",
        "Complete la función **`model_predict`** para que retorne las predicciones del modelo entrenado sobre un conjunto de prueba.\n",
        "\n",
        "**Entrada** :\n",
        "\n",
        "* **`log_reg`**: función del modelo de regresión logística previamente definido.\n",
        "* **`w`**: `tf.Variable`, tensor de parámetros óptimos del modelo, de tamaño `(n,1)`.\n",
        "* **`b`**: `tf.Variable`, escalar de _bias_ óptimo del modelo.\n",
        "* **`X_test`** : `tf.Tensor`, tensor de tamaño `(l,n)`, correspondiente a la matriz de datos de prueba.\n",
        "\n",
        "**Salida** :\n",
        "\n",
        "* **`y_pred`** : Tensor de tamaño `(l,1)`, con las predicciones de **model** para el conjunto de prueba **`X_test`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vThH4MZR5b2c"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN CALIFICADA model_predict:\n",
        "def model_predict(log_reg, b, w, X_test):\n",
        "    # Reemplazar con respuesta\n",
        "    y_pred = -1\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8YzTaJEuTDc"
      },
      "source": [
        "Use la siguiente celda para probar su función:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfBXPZfAWiyG"
      },
      "outputs": [],
      "source": [
        "#TEST_CELL\n",
        "losses, w, b = train_model(epochs=10,optimizer=optimizer('RMSprop',0.5),X_t = X_t, Y_t = Y_t, class_weights_list= class_weights_list)\n",
        "X_te = tf.constant(X_test, dtype=tf.float32)\n",
        "Y_te = tf.constant(y_test, dtype=tf.float32)\n",
        "Y_te = tf.expand_dims(Y_te, axis=-1, name=None)\n",
        "y_pred = model_predict(log_reg, b, w, X_te)\n",
        "print(\"Primeras dos predicciones:\\n\", y_pred[:2].numpy())\n",
        "m = tf.keras.metrics.Accuracy()\n",
        "m.update_state(Y_te, tf.math.round(y_pred))\n",
        "print(\"Accuracy sobre X_test después de 10 epochs:\", m.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2rSY7ZRu0yK"
      },
      "source": [
        "**Salida esperada:**\n",
        "\n",
        "```\n",
        "Primeras dos predicciones:\n",
        " [[0.92283654]\n",
        " [0.06457148]]\n",
        "Accuracy sobre X_test después de 10 epochs: 0.9166667\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hdrtdcqq6px9"
      },
      "source": [
        "### **Evaluar código**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK5uTI570Zld"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 6_1\", globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHydhY0hClH_"
      },
      "outputs": [],
      "source": [
        "grader.run_test(\"Test 6_2\", globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08eh8HTknUDd"
      },
      "source": [
        "# **Evaluación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb0DP1bWwRll"
      },
      "outputs": [],
      "source": [
        "grader.submit_task(globals())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Zv4dF3ieMk"
      },
      "source": [
        "# **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n",
        "* **Asistentes docentes :**\n",
        "  * [Santiago Toledo Cortés](https://sites.google.com/unal.edu.co/santiagotoledo-cortes/)\n",
        "* **Diseño de imágenes:**\n",
        "    - [Mario Andres Rodriguez Triana](mailto:mrodrigueztr@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}